<!DOCTYPE html>

<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en">

<head>

<meta charset="utf-8">
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="generator" content="pandoc" />



<meta name="progressive" content="true" />
<meta name="allow-skip" content="true" />
<meta name="learnr-version-prerender" content="0.11.5" />

<title>Statistical Modeling of Epidemic Data</title>

<!-- header-includes START -->
<!-- HEAD_CONTENT -->
<!-- header-includes END -->
<!-- HEAD_CONTENT -->

<!-- highlightjs -->
<style type="text/css">code{white-space: pre;}</style>
<style type="text/css">
  pre:not([class]) {
    background-color: white;
  }
</style>
<script type="text/javascript">
if (window.hljs) {
  hljs.configure({languages: []});
  hljs.initHighlightingOnLoad();
  if (document.readyState && document.readyState === "complete") {
    window.setTimeout(function() { hljs.initHighlighting(); }, 0);
  }
}
</script>


<!-- taken from https://github.com/rstudio/rmarkdown/blob/de8a9c38618903627ca509f5401d50a0876079f7/inst/rmd/h/default.html#L293-L343 -->
<!-- tabsets -->
<style type="text/css">
.tabset-dropdown > .nav-tabs {
  display: inline-table;
  max-height: 500px;
  min-height: 44px;
  overflow-y: auto;
  border: 1px solid #ddd;
  border-radius: 4px;
}

.tabset-dropdown > .nav-tabs > li.active:before {
  content: "";
  font-family: 'Glyphicons Halflings';
  display: inline-block;
  padding: 10px;
  border-right: 1px solid #ddd;
}

.tabset-dropdown > .nav-tabs.nav-tabs-open > li.active:before {
  content: "&#xe258;";
  border: none;
}

.tabset-dropdown > .nav-tabs.nav-tabs-open:before {
  content: "";
  font-family: 'Glyphicons Halflings';
  display: inline-block;
  padding: 10px;
  border-right: 1px solid #ddd;
}

.tabset-dropdown > .nav-tabs > li.active {
  display: block;
}

.tabset-dropdown > .nav-tabs > li > a,
.tabset-dropdown > .nav-tabs > li > a:focus,
.tabset-dropdown > .nav-tabs > li > a:hover {
  border: none;
  display: inline-block;
  border-radius: 4px;
  background-color: transparent;
}

.tabset-dropdown > .nav-tabs.nav-tabs-open > li {
  display: block;
  float: none;
}

.tabset-dropdown > .nav-tabs > li {
  display: none;
}
</style>
<!-- end tabsets -->


</head>

<body>
<a class='sr-only sr-only-focusable visually-hidden-focusable' href='#learnr-tutorial-content'>Skip to Tutorial Content</a>



<div class="pageContent band">
<main class="bandContent page">

<article class="topics" id="learnr-tutorial-content">

<div id="section-welcome" class="section level2">
<h2>Welcome</h2>
<p>This course will introduce you the theory and art of mathematical and
statistical modeling of data from of contagious diseases epidemics using
the statistical analysis package R.</p>
<p>The recent COVID pandemic illustrates the value of modeling
epidemics. Generative (statistical) models that both describe and
forecast the dynamics of an epidemic outbreak are useful for</p>
<ul>
<li>Forecasting for the spatial-temporal spread of contageous disease
<ul>
<li>Evaluate/quantify the health threat to population</li>
<li>Inform decision makers by forecasting future resource needs, e.g.,
the number of new infections and hospital beds needed</li>
</ul></li>
<li>Evaluate effectiveness of interventions
<ul>
<li>Benefits of vaccination</li>
<li>Value of non-pharmaceutical interventions, e.g., distancing,
masking, restricted mobility</li>
</ul></li>
</ul>
</div>
<div id="section-set-up" class="section level2">
<h2>Set-up</h2>
<p>This short course will combine formal lectures with real time
tutorial on how to analyze data using the statistical analysis] language
R. This requires that you install</p>
<ul>
<li><p>install R: Download the latest version of R from the CRAN: <a
href="https://cran.r-project.org/"
class="uri">https://cran.r-project.org/</a></p></li>
<li><p>install Rstudio: Download the latest version of Rstudio from
POSIT: <a href="https://posit.co/download/rstudio-desktop/"
class="uri">https://posit.co/download/rstudio-desktop/</a></p></li>
<li><p>install R-packages from the Tool -&gt; Install Packages menu in
Rstudio.<br />
R will take care of installing all required dependencies.</p>
<ul>
<li>learnr, tidyverse, tinytex, MASS, zoo</li>
<li>bayesplot, rstantools</li>
<li>deSolve</li>
</ul></li>
</ul>
<!-- ### Stan -->
<!-- We propose a Bayesian approach to inference, which we will do using STAN -->
<!-- https://mc-stan.org/users/interfaces/. -->
<!-- We will use that program using its interface with R. -->
<div id="section-data-and-code" class="section level3">
<h3>Data and code</h3>
<p>To demonstrate and practice our analysis skills, we will use a
collection epidemic data sets, scripts and examples. To access them,
update the path in first chunk of code. Search for ‘PATH’</p>
<p>When you are ready to begin, click on!</p>
</div>
</div>
<div id="section-part-1-introduction-to-bayesian-analysis"
class="section level2">
<h2>Part 1: Introduction to Bayesian Analysis</h2>
<ol style="list-style-type: decimal">
<li><p>Introduction to Bayesian Inference</p></li>
<li><p>Example 1: Estimation of an infection probability.</p>
<ol style="list-style-type: decimal">
<li><p>Sampling from the posterior</p></li>
<li><p>A first algorithm: Importance sampling</p></li>
</ol></li>
<li><p>Example 2: Estimation of within household infection
probability</p>
<ol style="list-style-type: decimal">
<li><p>Brute force sampling of bivariate parameters</p></li>
<li><p>Limitations of importance sampling</p></li>
<li><p>Introduction to Gibbs sampler</p></li>
<li><p>A first example of data augmentation</p></li>
</ol></li>
<li><p>Example 3: Estimation of the basic reproductive number from total
infections</p>
<ol style="list-style-type: decimal">
<li><p>Bayesian analysis for transformed Metropolis-Hasting
algorithm.</p></li>
<li><p>Basic diagnostics</p></li>
<li><p>Posterior predictive distribution</p></li>
</ol></li>
</ol>
</div>
<div id="section-bayesian-inference" class="section level2">
<h2>Bayesian inference</h2>
<p>In this course we will present a Bayesian approach to parameter
estimation and uncertainty quantification.</p>
<div id="section-bayesian-paradim" class="section level3">
<h3>Bayesian paradim</h3>
<p>The Bayesian paradigm provides a principled framework to make
inference for the unknown parameters from data and make forecast of
future incidence (with associated uncertainties).</p>
<p>Bayesian inference is particularly useful because</p>
<ul>
<li><p>Bayesian inference is conditional on the actual observations (via
the likelihood) and not impacted by possible other outcome. That is, you
model and make inference using the observed data.<br />
<!-- [See Birmbaum's likelihood principle].  As such, it sidesteps the previous observational bias discussion --></p></li>
<li><p>It intrinsically quantifies the uncertainty due to finite samples
(limited data issue)</p></li>
<li><p>Leverages the generative mechanism of the observed
observations</p></li>
<li><p>Provides a natural framework to model missing data</p></li>
</ul>
<p>For these reasons, we will in this course rely on a Bayesian approach
to model epidemic data.</p>
</div>
<div id="section-basic-elements-of-bayesian-inference"
class="section level3">
<h3>Basic elements of Bayesian inference</h3>
<div id="section-notation" class="section level4">
<h4>Notation</h4>
<p>It is useful for me to introduce the following notation:</p>
<ul>
<li><p><span class="math inline">\(Z=(Z_1,\ldots,Z_n) \in {\mathbb
R}^n\)</span> vector of observations (data).<br />
For example, the number of new infections (incidence) for each
day.</p></li>
<li><p><span class="math inline">\(\theta \in \Theta\)</span> denotes
unknown model parameters that we want to estimate from data.</p></li>
<li><p><span class="math inline">\(\Theta\)</span> parameter
set.</p></li>
<li><p>A likelihood <span class="math inline">\(L(\theta) = {\mathbb
P}(Z=z|\theta)\)</span>, the probability density of the data <span
class="math inline">\(Z=z\)</span> given the parameter The distribution
of the data given the parameter depends on the generative model for the
data. The reason we call this a likelihood and not a probability, is
that we treat the outcome <span class="math inline">\(Z=z\)</span>
fixed, and consider that quantity as a function of the parameter <span
class="math inline">\(\theta\)</span>.</p></li>
<li><p>A prior distribution <span class="math inline">\({\mathbb
P}(\theta)\)</span> for the unknown parameter. Its probability density
(when applicable) will be denoted by <span
class="math inline">\(\pi(\theta) = {\mathbb P}(d\theta)\)</span>. The
prior embodies the <em>a priori</em> knowledge about the parameter. That
knowledge may come from expert opinions, past experiments, or a
convenient description of our lack of knowledge about the
parameters.</p></li>
</ul>
</div>
</div>
<div id="section-example" class="section level3">
<h3>Example</h3>
<p>A negative binomial <span class="math inline">\(Z\)</span> is the
random variable that counts the number of trials of a biased coin
(probability <span class="math inline">\(p\)</span> for heads) that are
required until <span class="math inline">\(s\)</span> heads are
observed.</p>
<p>If <span class="math inline">\(s=3\)</span>, then</p>
<ul>
<li><p>HTTHTTTH: Z=8</p></li>
<li><p>TTHHTH: Z=6</p></li>
</ul>
<p>The probability distrtibtuion for <span
class="math inline">\(Z\)</span> is <span class="math display">\[
{\mathbb P}[Z=k|p] = {k-1 \choose s-1} (1-p)^{z-s}p^s.
\]</span></p>
<p>If we observe <span class="math inline">\(Z=7\)</span>, then the
likelihood is <span class="math display">\[
L(p) = {6 \choose 2} (1-p)^4 p^3
\]</span></p>
<div class="tutorial-exercise" data-label="negative-binomial"
data-completion="1" data-diagnostics="1" data-startover="1"
data-lines="0" data-pipe="|&gt;">
<pre class="text"><code># set value for random variable Z and size s=3
# in R, you assign values to variables with the &lt;- or -&gt;
Z &lt;- 7
s &lt;- 3

# build vector of values for p, ranging from 0 to 1
dp &lt;- 0.001  # set increment size
p &lt;- seq( from=dp/2, to=1,by=dp)  # generates a sequence

# use dnbinom to calculate probability 
loglik &lt;- dnbinom(Z,s,p,log = TRUE)  # log useful when we have small numbers

# plot the loglikelihood 
plot(p, loglik,  type=&quot;l&quot;, lwd=3, # type=&quot;l&quot; draws lines, lwd= line width
     xlab=&quot;p&quot;,ylab=&quot;loglikelihood&quot;)</code></pre>
<script type="application/json" data-ui-opts="1">{"engine":"r","has_checker":false,"caption":"<span data-i18n=\"text.enginecap\" data-i18n-opts=\"{&quot;engine&quot;:&quot;R&quot;}\">R Code<\/span>"}</script>
</div>
</div>
<div id="section-example-of-prior" class="section level3">
<h3>Example of prior</h3>
<p>The parameter for the negative binomial is <span
class="math inline">\(p\)</span>. A number in <span
class="math inline">\([0,1]\)</span>. A prior will be any density on
that interval. A conveniant choice is the Beta<span
class="math inline">\((a,b)\)</span> density that has density</p>
<p><span class="math display">\[
f(p) = \frac{\Gamma(a+b)}{\Gamma(a)\Gamma(b)} p^{a-1}(1-p)^{b-1}.
\]</span></p>
<p>The function <span class="math inline">\(\Gamma(a) = \int_0^\infty
x^{a-1}e^{-x} dx\)</span> is the Gamma function.</p>
<p>The ration <span class="math display">\[
\frac{\Gamma(a+b)}{\Gamma(a)\Gamma(b)}
\]</span> is the normalizing constant that ensures that <span
class="math display">\[
\int_0^1 f(p)dp = 1.
\]</span></p>
<p>Any probability distribution on <span
class="math inline">\([0,1]\)</span> can be a prior.</p>
<ul>
<li><p>What does it mean if the prior is <span
class="math inline">\({\mathbb P}[p=0]=1\)</span>?</p></li>
<li><p>Is there a prior that says “we don’t know anything about <span
class="math inline">\(p\)</span>”?</p></li>
</ul>
</div>
<div id="section-bayes-rule" class="section level3">
<h3>Bayes rule</h3>
<p>The <em>big idea</em> of Bayesian analysis, is to take our prior
knowledge (prior distribution), combined it with what we have observed
(likelihood) to update our knowledge (posterior). Logically, we use the
<em>posterior distribution</em>, the conditional distribution of the
unknown parameter given the data, as our updated knlowledge.</p>
<p>Computationally, this is done via <em>Bayes rule</em> that can be
writen in deceptively simple form: <span class="math display">\[
{\mathbb P}(\theta|Z) = \frac{{\mathbb P}(Z|\theta) {\mathbb
P}(\theta)}{{\mathbb P}(Z)}
\]</span></p>
<p>The marginal distribution <span class="math inline">\({\mathbb
P}(Z)\)</span> of the data serves as a normalizing constant for the
posterior distribution. Mathematically, iy is obtained by integrating
<span class="math display">\[
    {\mathbb P}(Z) = \int_\Theta {\mathbb P}[Z|\theta] \pi(\theta)
d\theta.
    \]</span> Computing that constant is often challenging.</p>
</div>
<div id="section-bayesian-inference-1" class="section level3">
<h3>Bayesian Inference</h3>
<ul>
<li><p>The prior embodies the knowledge about the unknown parameter
<em>before</em> observing the data</p></li>
<li><p>The posterior embodies the knowledge about the unknown parameter
<em>after</em> observing the data</p></li>
<li><p>Inference are made using the posterior. The whole distribution is
more informative than any summary. Yet, one can summarize attributes of
the posterior distribution:</p>
<ul>
<li><p>Point estimation: Mean, median, mode of the posterior
distribution</p></li>
<li><p>Estimate uncertainty: can use variance or IQR, but better to
provide the whole posterior.</p></li>
<li><p>Credibility intervals: use quantiles of posterior, or threshold
posterior density to identify high density regions.</p></li>
</ul></li>
<li><p>Predictions: We can calculate prediction for observations given
the observations by <span class="math display">\[
{\mathbb P}[X=x|Data] = \int_{\theta \in \Theta} {\mathbb P}[X=x|\theta]
{\mathbb P}[d\theta|Data]
\]</span> That is, we integrate out the unknown parameter using its
posterior distribution</p></li>
</ul>
</div>
</div>
<div id="section-example-1-estimating-the-probability-of-infection"
class="section level2">
<h2>Example 1: Estimating the probability of infection</h2>
<div id="section-problem" class="section level3">
<h3>Problem</h3>
<p>Assume that in a population of <span
class="math inline">\(N+m\)</span> individuals, there are <span
class="math inline">\(m\)</span> infected individuals. Each day, each
infected individual infects independently each susceptible individual
with probability <span class="math inline">\(p\)</span>.</p>
<ul>
<li><p>Given <span class="math inline">\(m=1\)</span> infected
individual, what is the probability of infection <span
class="math inline">\(p\)</span> if we observe <span
class="math inline">\(Z\)</span> new infections on the first
day?</p></li>
<li><p>Given <span class="math inline">\(m\)</span> infected
individuals, what is the probability of infection <span
class="math inline">\(p\)</span> if we observe <span
class="math inline">\(Z\)</span> new infections on the first
day?</p></li>
</ul>
</div>
<div id="section-likelihood." class="section level3">
<h3>Likelihood.</h3>
<div id="section-binomial-distribution" class="section level4">
<h4>Binomial distribution</h4>
<p>Let <span class="math inline">\(Z\)</span> denote the number of
successes (heads) in <span class="math inline">\(n\)</span> independent
toss of a biased coin showing heads with probability <span
class="math inline">\(p\)</span>.</p>
<ul>
<li><p>Each possible sequence of <span class="math inline">\(N\)</span>
tosses with <span class="math inline">\(Z=z\)</span> heads occurs with
probability <span class="math inline">\(p^z
(1-p)^{n-z}\)</span></p></li>
<li><p>There are <span class="math inline">\({N \choose z}\)</span>
distinct sequences of heads and tails</p></li>
<li><p>Example: <span class="math inline">\(N=3, Z=1\)</span></p>
<ul>
<li><p>HTT</p></li>
<li><p>THT</p></li>
<li><p>TTH</p></li>
</ul></li>
</ul>
<p>The probability that <span class="math inline">\(Z=z\)</span> is
<span class="math display">\[
{\mathbb P}[Z=z|p] = {N \choose z} p^z (1-p)^{N-z}.
\]</span></p>
</div>
<div id="section-escape-probability" class="section level4">
<h4>Escape probability</h4>
<p>If there are <span class="math inline">\(m\)</span> infectious
individuals infecting <em>independently</em> each susceptible
individual, the probability that a given susceptible individual
<em>escapes</em> infection is</p>
<p><span class="math display">\[
(1-p)^m.
\]</span></p>
<p>Thus, the probability that a susceptible individual gets infected
is</p>
<p><span class="math display">\[
r(p) = 1 - (1-p)^m.
\]</span></p>
</div>
<div id="section-distribution-of-the-number-of-new-infections"
class="section level4">
<h4>Distribution of the number of new infections</h4>
<p>The number of new infections <span class="math inline">\(Z\)</span>
is a binomial distribution with parameters <span
class="math inline">\(N\)</span> and <span
class="math inline">\(r(p)\)</span>.<br />
and the number of infected individuals Z$ is a binomial <span
class="math inline">\(B(N,r)\)</span>: <span class="math display">\[
{\mathbb P}(Z=z|p) = {N \choose z} r(p)^z (1-r(p))^{N-z}
\]</span></p>
</div>
<div id="section-likelihood" class="section level4">
<h4>Likelihood</h4>
<p>Given <span class="math inline">\(Z=z\)</span> new infections, the
likelihood is <span class="math display">\[
L(p) = {N \choose z} r(p)^z (1-r(p))^{N-z}
\]</span></p>
<p>What is the difference between the binomial probability and the
likelihood?</p>
</div>
</div>
<div id="section-prior" class="section level3">
<h3>prior</h3>
<ul>
<li><p>The parameter <span class="math inline">\(p\)</span> is on <span
class="math inline">\([0,1]\)</span>. Any probability distribution on
that interval can be a prior distribution</p>
<ul>
<li><p>Pick a prior that captures our state of knowledge about the the
infection probability</p></li>
<li><p>Pick a prior for which it is easy to calculate the posterior
distribution</p></li>
</ul></li>
<li><p>The Beta<span class="math inline">\((a,b)\)</span> is an example
of a convenient family of prior distributions. They have probability
density <span class="math display">\[
\pi(p) = \frac{\Gamma(a)\Gamma(b)}{\Gamma(a+b)} p^{a-1} (1-p)^{b-1},
\]</span> where <span class="math inline">\(a,b&gt;0\)</span> and <span
class="math inline">\(\Gamma(a) = \int_0^\infty u^{a-1}e^{-u}du\)</span>
is the Gamma function.</p></li>
</ul>
<p>Calculate <span class="math display">\[
\mbox{mean} = \frac{1}{a+b} \qquad \mbox{var} = \frac{ab}{(a+b)(a+b+1)}.
\]</span></p>
<p>Special case:</p>
<ul>
<li><p><span class="math inline">\(a=b=1\)</span> is the uniform density
on <span class="math inline">\([0,1]\)</span></p></li>
<li><p><span class="math inline">\(a=b=1/2\)</span> <em>Jeffey</em>’s
prior (“not informative”)</p></li>
</ul>
</div>
<div id="section-posterior" class="section level3">
<h3>posterior</h3>
<p>Why is the Beta distribution convenient? For <span
class="math inline">\(m=1\)</span>, the product of prior and
<em>binomial</em> likelihood is</p>
<p><span class="math display">\[\begin{eqnarray*}
L(p) \times \pi(p) &amp; = &amp; {N \choose z} p^z(1-p)^{N-z} \times
\frac{\Gamma(a)\Gamma(b)}{\Gamma(a+b)} p^{a-1} (1-p)^{b-1}\\
&amp; \propto &amp; p^{z+a-1} (1-p)^{N-z+b-1}
\end{eqnarray*}\]</span></p>
<ul>
<li><p>Same functional form as the prior</p></li>
<li><p>Do not need to keep tract of constants. We know that the
normalizing constant will be <span class="math display">\[
{\mathbb P}[Z=z] = \frac{\Gamma(z+a)\Gamma(N-z+b)}{\Gamma(N+a+b)}
\]</span></p></li>
</ul>
<p>Why?</p>
<ul>
<li><p>Prior distributions that lead to posterior distribtuions in the
same family are called <em>conjugate priors</em>: Start with prior
Beta<span class="math inline">\((a,b)\)</span> and get posterior
Beta<span class="math inline">\((A,B)\)</span> with</p>
<ul>
<li><p><span class="math inline">\(A=a+z\)</span></p></li>
<li><p><span class="math inline">\(B=b+N-z\)</span></p></li>
</ul></li>
<li><p>Posterior distribution is <span class="math display">\[
{\mathbb P}[p|Z=z] = \frac{\Gamma(N+a+b)}{\Gamma(a+z)\Gamma(N-z+b)}
p^{z+a-1}(1-p)^{N-z+b-1}.
\]</span></p></li>
</ul>
</div>
<div id="section-numerical-example" class="section level3">
<h3>Numerical example</h3>
<p>As an numerical example, consider observing <span
class="math inline">\(Z=6\)</span>, when <span
class="math inline">\(N=50\)</span>. Our prior is a Beta distribution
with parameters <span class="math inline">\(a=2\)</span> and <span
class="math inline">\(b=3\)</span>.</p>
<p>See <code>[x]beta</code> functions to evaluate densities,
distribution and draw samples from a Beta distribution.</p>
<div class="tutorial-exercise" data-label="binomial" data-completion="1"
data-diagnostics="1" data-startover="1" data-lines="0"
data-pipe="|&gt;">
<pre class="text"><code># set up a grid a the probability of success
pp &lt;- seq( 0, 1, by = 0.001 )

# Data
# number of trials
N &lt;- 50 # In R, you can use = or &lt;- to assign values to variables

Z &lt;- 6

# parameter of prior
a &lt;- 2
b &lt;- 3

# dbeta is a function that calculates the density of a beta distribution
# evaluated at values pp (can be a vector), and parameters a and b

Prior &lt;- dbeta(pp,a,b)

# To get help about functions in R, use either
# help(&quot;dbeta&quot;) 
# ?dbeta

# beta is conjugate prior for binomial.  So we *KNOW* that
# the posterior is a beta with parameters a+z, b+N-z
# again, I evaluate density on a grid of values of p
Posterior &lt;- dbeta(pp,a+Z,b+N-Z)

# Now I want to make a plot
# Useful to calculate the maximum to set axis...
mmax &lt;- max(Prior,Posterior)

plot(c(0,1), c(0,mmax), type=&quot;n&quot;,       # type=&quot;n&quot; just sets up thje axis
          xlab=&quot;prob&quot;, ylab=&quot;density&quot;)  # xlab, ylab used for the labels

lines(pp,Prior,col=1,lwd=2)
lines(pp,Posterior,col=2,lwd=2)

#. calculate confidence interval

CI &lt;- function(p,posterior,L){
  idx &lt;- posterior &gt; L
  coverage &lt;- mean( posterior*idx )
  CI &lt;- range( p[idx] )
  return( list( interval=CI, coverage=coverage ) )
}

abline(h=1,lty=3)
CI(pp,Posterior,1)</code></pre>
<script type="application/json" data-ui-opts="1">{"engine":"r","has_checker":false,"caption":"<span data-i18n=\"text.enginecap\" data-i18n-opts=\"{&quot;engine&quot;:&quot;R&quot;}\">R Code<\/span>"}</script>
</div>
<div id="section-exercise." class="section level4">
<h4>Exercise.</h4>
<p>Moddify the code to compute the posterior distribution for <span
class="math inline">\(p\)</span> when <span
class="math inline">\(Z=10\)</span>, <span
class="math inline">\(N=100\)</span>. Compute condidtional mean,
conditional variance, and a <span class="math inline">\(0.95\)</span>
confidence interval for <span class="math inline">\(p\)</span>. For the
latter, you need to guess a reasonable value for <span
class="math inline">\(L\)</span> in the above code.</p>
</div>
</div>
<div id="section-another-academic-example" class="section level3">
<h3>Another academic example</h3>
<p>Suppose that <span class="math inline">\(Z\)</span> has a Poisson
distribution with mean <span class="math inline">\(\theta\)</span>.
Poisson distributions are useful to model count data.</p>
<p>Then <span class="math display">\[
{\mathbb P}[Z=z|\theta] = \frac{\theta^z}{z!} e^{-\theta}, \quad
z=0,1,2,\ldots
\]</span> The likelihood of <span class="math inline">\(\theta\)</span>
given the observation <span class="math inline">\(Z=z\)</span> is <span
class="math display">\[
L(\theta) = \frac{\theta^z}{z!} e^{-\theta}
\]</span></p>
<p>A prior of convenience (conjugate prior, as we shall see) is the
gamma distribution with rate <span class="math inline">\(\tau\)</span>
and shape <span class="math inline">\(s\)</span>. The prior density is
<span class="math display">\[
\pi(\theta) = \frac{\tau^s \theta^{s-1}}{\Gamma(s)} e^{-\tau \theta}.
\]</span></p>
<p>The posterior is proportional to <span class="math display">\[
L(\theta) \pi(\theta) \propto \theta^{z+s-1} e^{-(\tau+1)\theta}
\]</span> which we recognize as a gamma density with rate <span
class="math inline">\(\tau+1\)</span> and shape <span
class="math inline">\(s+z\)</span>. Hence the posterior density is</p>
<p><span class="math display">\[
P(\theta|z) = \frac{(1+\tau)^{z+s}}{\Gamma(z+s)}
\theta^{z+s-1}e^{-(1+\tau)\theta}.
\]</span></p>
</div>
<div id="section-example-continued." class="section level3">
<h3>Example, continued.</h3>
<p>Now suppose that <span class="math inline">\(m=3\)</span>. As
discussed, the escape probability is <span
class="math inline">\(r(p)=(1-p)^3\)</span>, and the probability of
observing <span class="math inline">\(Z=z\)</span> new infections is
<span class="math display">\[
{\mathbb P}[Z=z|p] = {N \choose z} (1-(1-p)^3)^z (1-p)^{3(N-z)}.
\]</span></p>
<div id="section-likelihood-1" class="section level4">
<h4>Likelihood</h4>
<p>If we observe <span class="math inline">\(Z=z\)</span>, the
likelihood is <span class="math display">\[
L(p) = {\mathbb P}(Z=z|p) = {N \choose z} (1-(1-p)^3)^z (1-p)^{3(N-z)}.
\]</span></p>
</div>
<div id="section-prior-1" class="section level4">
<h4>Prior</h4>
<p>As before, let us assume that <span class="math inline">\(p\)</span>
has a Beta<span class="math inline">\((a,b)\)</span> prior. That is
<span class="math display">\[
\pi(p) = \frac{\Gamma(a+b)}{\Gamma(a)\Gamma(b)} p^{a-1} (1-p)^{b-1}.
\]</span></p>
</div>
<div id="section-posterior-1" class="section level4">
<h4>Posterior</h4>
<p>The posterior is proportional to <span
class="math display">\[\begin{eqnarray*}
{\mathbb P}[p|Z=z] &amp;\propto&amp; (1-(1-p)^3)^z (1-p)^{3(N-z)} \times
p^{a-1}(1-p)^{b-1}\\
&amp; \propto &amp; p^{z+a-1}(1-p)^{3(N-z)+b-1} \times \left ( 3 - 3p +
p^2 \right )^z.
\end{eqnarray*}\]</span></p>
</div>
<div id="section-not-a-conjugate-prior" class="section level4">
<h4>Not a conjugate prior</h4>
<p>The posterior distribution is <em>not</em> a Beta distribution. This
means that we need to calculate the integral</p>
<p><span class="math display">\[
\frac{1}{{\mathbb P}[Z=z]} = \int_0^1
p^{z+a-1}(1-p)^{3(N-z)+b-1} \times \left ( 3 - 3p + p^2 \right )^z dp
\]</span></p>
<p>to normalize our expression for the posterior.</p>
</div>
</div>
<div id="section-alternative-to-calculation-of-the-normalizing-constant"
class="section level3">
<h3>Alternative to calculation of the normalizing constant</h3>
<div id="section-brute-force-approach" class="section level4">
<h4>Brute force approach</h4>
<p>Analytic evaluation of the normalizing constant <span
class="math display">\[
\int_0^1 p^{z+a-1}(1-p)^{3(N-z)+b-1} \times \left ( 3 - 3p + p^2 \right
)^z dp
\]</span> possible, but tedious.</p>
<p>Numerical integration is also possible.</p>
</div>
<div id="section-alternative-approach" class="section level4">
<h4>Alternative approach</h4>
<p>Imagine getting a sample <span
class="math inline">\(p_1,\ldots,p_n\)</span> from the posterior
distribution. Almost as good as computing the posterior distribution</p>
<ul>
<li>Calculate estimates</li>
<li>Obtain confidence intervals</li>
<li>Make inference</li>
</ul>
<p>Central theme of today’s lectures.</p>
<p><strong>Getting a sample from the posterior is almost as good as
direct evaluation of the posterior</strong></p>
</div>
</div>
<div id="section-sampling-from-a-univariate-distribution"
class="section level3">
<h3>Sampling from a univariate distribution</h3>
<p>Let us digress and discuss how to sample from a univariate
probability distribution.</p>
<div id="section-a-theorem" class="section level4">
<h4>A theorem</h4>
<p>If <span class="math inline">\(X \sim F\)</span> a continuous
univariate cumulative probability distribution, then <span
class="math display">\[
F(X) \stackrel{d}{=} U \sim \mbox{Uniform}(0,1).
\]</span></p>
<p>The converse is true even more generally: Given a cumulative
probability distribution <span class="math inline">\(F\)</span>, <span
class="math display">\[
X = F^{-1}(U) \equiv \sup \{x : F(x) \leq U \} \sim F.
\]</span></p>
</div>
<div id="section-sampling-algorithm" class="section level4">
<h4>Sampling algorithm</h4>
<ol style="list-style-type: decimal">
<li><p>Draw <span class="math inline">\(U\)</span> from a uniform
distribution</p></li>
<li><p>Calculate <span class="math inline">\(X = \sup\{ x : F(x) \leq U
\}\)</span></p></li>
</ol>
</div>
</div>
<div id="section-academic-example" class="section level3">
<h3>Academic Example</h3>
<p>As a first example, suppose we want to sample from an exponential
distribution that has cumulative probability distribution</p>
<p><span class="math display">\[
F(x) = 1 - e^{-x}
\]</span></p>
<p>The inverse of this distribtuion is <span class="math display">\[
F^{-1}(u) = -log(1-u)
\]</span></p>
<pre class="r"><code># number of samples
n.smp &lt;- 10000

# create a vector of random uniform
U &lt;- runif(n.smp) 

# calculate inverse
X &lt;- -log(1-U)

# make histogram
hist(X,xlab=&quot;x&quot;, nclass=100, freq=FALSE, # freq=FALSE makes density
     main=&quot;histogram of exponental&quot;)

# add expected density
x &lt;- seq(0,10,by=0.1) # sequence of x values
y &lt;- exp(-x)          # density at x
lines(x,y,lwd=3,col=&#39;red&#39;) # lwd width of line, col=&#39;red&#39; sets color of line</code></pre>
<p><img src="lecture_files/figure-html/example-exponential-1.png" width="624" /></p>
</div>
<div id="section-example-continued" class="section level3">
<h3>Example, continued</h3>
<p>Let us demonstrate how we can apply this method to (numerically) a
sample from an (approximate) distribution in the previous problem.<br />
The approximation arises because we need to discretize <span
class="math inline">\(p\)</span>.</p>
<div class="tutorial-exercise" data-label="inverse-sampling"
data-completion="1" data-diagnostics="1" data-startover="1"
data-lines="0" data-pipe="|&gt;">
<pre class="text"><code># data
N &lt;- 50
Z &lt;- 8
m &lt;- 3

# parameters for the prior
a &lt;- 2
b &lt;- 4

# set-up the numerical approximation by creating a grid of 
# values p
dp &lt;- 0.05 # grid size
p &lt;- seq(dp/2, by=dp)

# calculate the probability (up to numerical integration)
P &lt;- c(0, exp( (Z+a-1)*log(p) + (3*(N-Z)+b-1)*log(1-p) + Z*log(3-3*p+p*p) ) )

# calculate the approcimate CDF
cdf &lt;- cumsum(P)/sum(P)

# sample from that distribution using the inverse probability transform
# You can define custom functions with the function(...) command
# The ... are the input variables (locally defined)

Finv &lt;- function(x,cdf,u){
  idx &lt;- cdf &lt; u                # generate a vector of T-F of the same length as cdf
  x.smp &lt;- max( x[ cdf &lt; u ] )  # select entries with T, and take the max  
  return(x.smp)                 # return result
}

n.smp &lt;- 5000       # number of samples to be drawn
X &lt;- rep(0,n.smp)   # create vector of zeros of length n.smp

# loop to generate random samples 
for ( k in 1:n.smp ){
  X[k] &lt;- Finv( p,cdf,runif(1) ) # [] are used to address component of vector
                                 # () used for functions
}

# make a histogram of the results
# nclass = number of bins
hist(X,nclass=100,
     main=&quot;histogram of posterior&quot;,
     xlim=c(0,0.3)) # set range of x-axis</code></pre>
<script type="application/json" data-ui-opts="1">{"engine":"r","has_checker":false,"caption":"<span data-i18n=\"text.enginecap\" data-i18n-opts=\"{&quot;engine&quot;:&quot;R&quot;}\">R Code<\/span>"}</script>
</div>
<div id="section-exercise" class="section level4">
<h4>Exercise</h4>
<p>Change the grid size in the above code and see how the posterior
distribution changes</p>
<p>How do we select the grid size?</p>
</div>
</div>
<div id="section-discussion" class="section level3">
<h3>Discussion</h3>
<p>What are possible shortcomings for this algorithm?</p>
<ul>
<li><p>Only works in one dimension</p></li>
<li><p>Depends on numerical approximations.</p></li>
</ul>
</div>
<div id="section-importance-sampling" class="section level3">
<h3>Importance sampling</h3>
<p>The inverse probability method works well when we can readily sample
(compute) the inverse cdf of the posterior. Otherwise we need, as we
have done, numerically approximate the cdf.</p>
<p>An alternative to that scheme is importance sampling. Assume that we
can “easily” sample from a distribution <span
class="math inline">\(f\)</span>. But we want to get a sample from a
distribution <span class="math inline">\(g\)</span>.</p>
<p>Algorithm:</p>
<ul>
<li><p>draw <span class="math inline">\(Z \sim f\)</span></p></li>
<li><p>calculate weight <span
class="math inline">\(w(Z)=g(Z)/f(Z)\)</span></p></li>
<li><p><span class="math inline">\((w(Z_i),Z_i),i=1,\ldots,n\)</span>
form a weighted sample from <span
class="math inline">\(g\)</span>.</p></li>
</ul>
<div id="section-justification" class="section level4">
<h4>Justification</h4>
<p>Calculate <span class="math display">\[\begin{eqnarray*}
{\mathbb E}_g(H(Z)) &amp;=&amp; \int H(z) g(z) dz \\
&amp;=&amp; \int H(z) \frac{g(z)}{f(z)} f(z) dz\\
&amp;=&amp; \int H(z) w(z) f(z) dz = {\mathbb E}_f[H(Z)w(Z)].
\end{eqnarray*}\]</span></p>
<p>A weighted sample is useful to estimate integrals.</p>
</div>
</div>
<div id="section-graphical-example" class="section level3">
<h3>Graphical example</h3>
<p>Suppose that I want to draw from a density that is proportional to
<span class="math display">\[
g(z) \propto \frac{1}{1+\sqrt{z}+z} e^{-z}
\]</span> We know how to sample from an exponential distribution that
has density (see previous example) <span class="math display">\[
f(z)=e^{-z}.
\]</span> To get a weighted sample for <span
class="math inline">\(g(z)\)</span>, we can sample form the exponential
and assign weights <span class="math display">\[
w(z) = \frac{g(z)}{f(z)} \propto 1+\sqrt{z}+z
\]</span></p>
<pre class="r"><code># number of samples
n.smp &lt;- 10000

# create a vector of random uniform
U &lt;- runif(n.smp) 

# calculate inverse
Z &lt;- -log(1-U)

# calculate weights
W &lt;- 1 + sqrt(Z) + Z

# normalize the weights
W &lt;- W/sum(W)

# lets calculate a histogram using these weight
histogram.breaks &lt;- seq(0,10,by=0.1) # breaks of the histogram
iidx &lt;- cut(Z, histogram.breaks)     # indicates in which bin each element of Z belongs
wgt.by.bin &lt;- split(W, iidx)         # split weights into associated bin
wgt.sum &lt;- sapply( wgt.by.bin, sum ) # make sum of weights in each bin

# normalize by bin size
wgt.sum &lt;- wgt.sum/0.1

# make barplot
plot(histogram.breaks[-1], wgt.sum, 
     type=&quot;h&quot;,ylim=c(0,0.6),  # type=&quot;h&quot; used to create bars
     xlab=&quot;z&quot;,ylab=&quot;density&quot;)
lines(x,y,lwd=3,col=2)</code></pre>
<p><img src="lecture_files/figure-html/example-importance-1-1.png" width="624" /></p>
<p>The red line is the exponential density, and the barplot is the
histogram of the desired density.</p>
</div>
<div id="section-numerical-example-1" class="section level3">
<h3>Numerical Example</h3>
<p>We want to draw a weighted samples from the posterior <span
class="math display">\[
{\mathbb P}(p|Z)  \propto  p^{z+a-1}(1-p)^{3(N-z)+b-1} \times \left ( 3
- 3p + p^2 \right )^z.
\]</span> Recognize that <span
class="math inline">\(p^{z+a-1}(1-p)^{3(N-z)+b-1}\)</span> is
proportional to a Beta<span
class="math inline">\((z+a,3(N-z)+b)\)</span> density.</p>
<p>Sampling weights are <span class="math display">\[
w(p) \propto \frac{g(p)}{f(p)} = C (3-3p+p^2)^z.
\]</span></p>
The following R code computes an importance sample when <span
class="math inline">\(m=3\)</span>, <span
class="math inline">\(N=50\)</span> and <span
class="math inline">\(Z=8\)</span>.
<div class="tutorial-exercise" data-label="importance_example"
data-completion="1" data-diagnostics="1" data-startover="1"
data-lines="0" data-pipe="|&gt;">
<pre class="text"><code># data
N &lt;- 50
Z &lt;- 8
m &lt;- 3

# parameter of prior
a &lt;- 2
b &lt;- 3

# number of samples
n.smp &lt;- 10000

# get a sample from a Beta distribution
pp &lt;- rbeta(n.smp, Z+a, m*(N-Z)+b)

# calculate the logarithm of the weights
ww.log &lt;-  Z*( log(1-(1-pp)^m ) - log( pp ) )
ww.log &lt;- ww.log - mean( ww.log ) - log(n.smp)  # get better numerical stability is values do not explode

# normalize weights
ww.normalized &lt;- exp( ww.log - log( sum( exp( ww.log ) ) ) )

# plot weights
plot(ww.normalized, xlab=&quot;index&quot;, ylab=&quot;weight&quot;, pch=20, cex=0.5)
abline(h=0.001, lty=1, lwd=3)

#. Lets calculate the histogram
nbins &lt;- 200 # number of bins
histogram.breaks &lt;- seq(0,0.5,length=nbins+1)
iidx &lt;- cut( pp, histogram.breaks )
split( ww.normalized, iidx ) %&gt;%
  sapply(., sum) -&gt; histogram.hight 
histogram.hight &lt;- histogram.hight * nbins  # normalization 

plot(histogram.breaks[-(nbins+1)],histogram.hight,type=&quot;s&quot;,
     xlab=&quot;probability&quot;,ylab=&quot;histogram&quot;,
     sub=&quot;histogram of posterior distribution&quot;)</code></pre>
<script type="application/json" data-ui-opts="1">{"engine":"r","has_checker":false,"caption":"<span data-i18n=\"text.enginecap\" data-i18n-opts=\"{&quot;engine&quot;:&quot;R&quot;}\">R Code<\/span>"}</script>
</div>
</div>
<div id="section-inference" class="section level3">
<h3>Inference</h3>
<p>We can readily use the weighted samples to calculate summary
statistics of the posterior distribution.</p>
<div class="tutorial-exercise" data-label="importance_sampling_summary"
data-completion="1" data-diagnostics="1" data-startover="1"
data-lines="0" data-pipe="|&gt;">
<pre class="text"><code># sort sampled values
idx &lt;- sort.list(pp)
pp.sort &lt;- pp[idx]
ww.normalized.sort &lt;- ww.normalized[idx]

# cumulative distribution
pp.cdf &lt;- cumsum(ww.normalized.sort) 

# summary statistics of the posterior
sum.stat &lt;- list(
  mean=sum(ww.normalized.sort*pp.sort), # mean
  q10=max( pp.sort[ pp.cdf &lt; 0.1] ),  # lower 10% quantile
  q50=max( pp.sort[ pp.cdf &lt; 0.5] ),  # median
  q90=max( pp.sort[ pp.cdf &lt; 0.9] ) ) # upper 10% quantile

sapply(sum.stat, round,4)</code></pre>
<script type="application/json" data-ui-opts="1">{"engine":"r","has_checker":false,"caption":"<span data-i18n=\"text.enginecap\" data-i18n-opts=\"{&quot;engine&quot;:&quot;R&quot;}\">R Code<\/span>"}</script>
</div>
</div>
<div id="section-exercise-1" class="section level3">
<h3>Exercise</h3>
<ul>
<li><p>Use the previous code and explore sampling the posterior when
<span class="math inline">\(m=30\)</span>, <span
class="math inline">\(Z=80\)</span> and <span
class="math inline">\(N=500\)</span>. What is happening with the
weights?</p></li>
<li><p>Consider the problem of estimating the posterior distribution
when <span class="math inline">\(m=1\)</span> (one infected
individuals), <span class="math inline">\(Z=6\)</span> and <span
class="math inline">\(N=50\)</span>. But assume that the prior is
proportional to a Gaussian with mean <span
class="math inline">\(2/5\)</span> and variance <span
class="math inline">\(1/5\)</span>, restricted to the unit
interval.</p></li>
</ul>
</div>
<div id="section-guided-exercise" class="section level3">
<h3>Guided Exercise</h3>
<p>Crimea Congo Hemorrhagic Virus (CCHV) is a tick-born virus that has
up to 50% mortality in humans infections. Limited resources encourages,
and relatively low prevalence in ticks, encourages batch detection of
viruses by using PCR on a small number of ticks instead of individual
ticks. Apply the methods discussed in this section to estimate the
prevalence CCHV in ticks on the ground.</p>
<div id="section-define-random-variables" class="section level4">
<h4>Define random variables</h4>
<ul>
<li><p><span class="math inline">\(Z_i = 1\)</span> is ticks on <span
class="math inline">\(i^{th}\)</span> cow test positive</p></li>
<li><p><span class="math inline">\(m_i\)</span> the number of ticks test
on the cow</p></li>
<li><p>Data from each cow are independent</p></li>
</ul>
</div>
<div id="section-probability" class="section level4">
<h4>Probability</h4>
<p>The probability of a positive test is: <span class="math display">\[
{\mathbb P}[Z_i=1|m_i,p] = 1 - (1-p)^{m_i} \qquad {\mathbb
P}[Z_i|m_i,p]=(1-p)^{m_i}
\]</span></p>
</div>
<div id="section-likelihood-2" class="section level4">
<h4>Likelihood</h4>
<p>The likelihood of the data is <span
class="math display">\[\begin{eqnarray*}
L(p) &amp;=&amp; \prod_{i=1}^n ( 1 - (1-p)^m_i )^{Z_i}
(1-p)^{m_i(1-Z_i)}\\
&amp;=&amp; \prod_{i \in M_1} p^{Z_i}(1-p)^{Z_i} \times \prod_{i \in
M_2} (1-(1-p)^2)^{Z_i} (1-p)^{2(1-Z_i)} \\
&amp;=&amp; p^{\sum_{i=1}^n Z_i} (1-p)^{m_i(1-Z_i)} \times
  (2-p)^{\sum_{i \in M_2} Z_i}.
\end{eqnarray*}\]</span> Here <span class="math inline">\(M_1\)</span>
and <span class="math inline">\(M_2\)</span> are the set of indices for
which <span class="math inline">\(m_i=1\)</span>, <span
class="math inline">\(m_i=2\)</span>, respectively.</p>
</div>
<div id="section-importance-sampling-from-posterior"
class="section level4">
<h4>Importance sampling from posterior</h4>
<p>Use a uniform prior for <span class="math inline">\(p\)</span>.</p>
<p>Set <span class="math inline">\(T_1 = \sum_{i=1}^n Z_i\)</span>,
<span class="math inline">\(T_2=\sum_{i=1}^n m_i(1-Z_i)\)</span> and
<span class="math inline">\(T_3=\sum_{i \in M_2} Z_i\)</span>. Then the
posterior is proportional to <span class="math display">\[
{\mathbb P}[p|Data] \propto p^{T_1} (1-p)^{T_2} \times (2-p)^{T_3}.
\]</span> We can sample from a Beta<span
class="math inline">\((T_1+1,T_2+1)\)</span>, and weight the samples
with weights proportional to <span class="math display">\[
W_i = W(p_i) \propto (2-p_i)^{T_3}.
\]</span></p>
<p>If you need help, load the file <code>tickAnalysis.R</code> and
complete analysis.</p>
</div>
<div id="section-using-a-different-prior" class="section level4">
<h4>Using a different prior?</h4>
<p>Suppose that you are told that they expect between 10% and 30% of the
ticks to be infected. How would you use this information to select a
prior?</p>
</div>
</div>
<div id="section-answer" class="section level3">
<h3>Answer</h3>
<p>We calsulate the posterior distribution to be:</p>
<p><img src="lecture_files/figure-html/importance-ticks-1.png" width="624" /></p>
</div>
<div id="section-importance-sampling.-summary" class="section level3">
<h3>Importance sampling. Summary</h3>
<p>Importance sampling is a useful tool to generated weighted
independent samples from a posterior distribution. This approach is
useful when</p>
<ul>
<li><p>One can identify a distribution to sample from, whose density
<span class="math inline">\(f\)</span> is close to the posterior density
<span class="math inline">\(g\)</span></p></li>
<li><p>The calculated weights should not be dominated by a few large
outliers</p></li>
<li><p>Weighted samples useful to compute expected values, including
histograms.</p></li>
<li><p>Generally speaking, works for univariate problems.</p></li>
</ul>
</div>
</div>
<div
id="section-example-2-estimating-the-probability-of-transmission-in-households"
class="section level2">
<h2>Example 2: Estimating the probability of transmission in
households</h2>
<div id="section-problem-1" class="section level3">
<h3>Problem</h3>
<p>Contacts leading to infection can be heterogeneous. For example, we
may believe that the risk of infection from a random encounter on the
street is less than getting infected by a sick household member.
Household infection studies provide an opportunity to study disease
transmission in a more homogeneous setting.</p>
<p>Consider the following household study: We sample <span
class="math inline">\(n\)</span> households, for which we record the
pair <span class="math inline">\((N_i,Z_i)\)</span> of household size
and number of infections. Our analysis will make the following
assumptions:</p>
<ul>
<li><p>Infections within the household occur independently with
probability <span class="math inline">\(p\)</span>.</p></li>
<li><p>The household is observed during a short period of time that
practically eliminates secondary infections</p></li>
<li><p>An attempt is made to creat an index case in each household by
attempting to infect a particular individual in that hlusehold. The
probability of that infection is q.</p></li>
<li><p>The number of secondary infections within the household</p></li>
</ul>
<p>Our aim is to estimate <span class="math inline">\(p\)</span>. The
fraction <span class="math inline">\(q\)</span> of households with an
initial infection is an unknown “nuissance” parameter that we also need
to estimate.</p>
</div>
<div id="section-modeling" class="section level3">
<h3>Modeling</h3>
<div id="section-distribution-of-the-data" class="section level4">
<h4>Distribution of the data</h4>
<p>To model the number of infections <span
class="math inline">\(Z\)</span> in a given household, decompose the
probability into two steps:</p>
<ol style="list-style-type: decimal">
<li><p>Infect the index case in a household. Lets call that random
variable <span class="math inline">\(A\)</span>, with <span
class="math inline">\(A=1\)</span> when an infection is successful. By
assumption, <span class="math inline">\({\mathbb
P}[A=1]=q\)</span></p></li>
<li><p>If <span class="math inline">\(A=0\)</span>, there can be no
infections, and so <span class="math inline">\(Z=0\)</span></p></li>
<li><p>If <span class="math inline">\(A=1\)</span>, then the number of
infections in the household is a binomial with parameter <span
class="math inline">\(p,N\)</span>.</p></li>
</ol>
<p>Using the total probability rule, we have that <span
class="math display">\[\begin{eqnarray*}
{\mathbb P}[Z=z|N=n,p,q] &amp;=&amp; {\mathbb P}[Z=z|A=1,N=n,p,q]
{\mathbb P}[A=1|q]\\
&amp;&amp; \qquad
+ {\mathbb P}[Z=z|A=0,N=n,p,q] {\mathbb P}[A=0|q]\\
&amp;=&amp; \left \{
\begin{array}{ll}
(1-q) + q(1-p)^{n-1} &amp; k = 0 \\
q {n-1 \choose k} p^k (1-p)^{n-1-k} &amp; k =1,2,\ldots,n-1
\end{array} \right .
\end{eqnarray*}\]</span></p>
<p>That distribution is called a ‘zero inflated binomial’ distribution,
and such random variables arise sometimes in epidemiology. It is called
zero inflated because it has more zero’s than we would expect under the
standard binomial model.</p>
</div>
</div>
<div id="section-likelihood-3" class="section level3">
<h3>Likelihood</h3>
<p>Assuming households are independent, the likelihood is the product of
the probabilities <span class="math display">\[\begin{eqnarray*}
L(p,q) &amp;\propto&amp; \prod_{i: z_i=0} \left ( (1-q) +
q(1-p)^{N_i-1}\right ) \times \prod_{i : z_i &gt; 0} q
p^{z_i}(1-p)^{N_i-z_i-1}
\end{eqnarray*}\]</span> If we denote by <span
class="math inline">\(\xi_i=\{Z_i=0\}\)</span> the indicator that <span
class="math inline">\(Z_i=0\)</span>, then we rewrite the likelihood as
<span class="math display">\[\begin{eqnarray} \label{eq:A}
L(p,q) &amp;\propto&amp; \prod_{i=1}^n q^{1-\xi_i}
\left ( (1-q) + q(1-p)^{N_i-1}\right )^{\xi_i}
\times \prod_{i=1}^n p^{z_i(1-\xi_i)}(1-p)^{(N_i-z_i-1)(1-\xi_i)}
\end{eqnarray}\]</span></p>
<div id="section-prior-2" class="section level4">
<h4>prior</h4>
<p>We will assume that our prior knowledge for the fraction <span
class="math inline">\(q\)</span> of household infected is independent of
the prior for the probability of secondary infections <span
class="math inline">\(p\)</span>. For convenience, I assume these prior
distributions are Beta with parameters <span
class="math inline">\((a_q,b_q)\)</span> and <span
class="math inline">\((a_p,b_p)\)</span>, respectively. The choice <span
class="math inline">\(a_p=b_p=1\)</span> corresponds to a uniform
density on the unit interval, but other more informed choices are
possible.</p>
</div>
</div>
<div id="section-sampling-from-the-posterior-distribution"
class="section level3">
<h3>sampling from the posterior distribution</h3>
<p>Formally, the posterior distribution is proportional to the product
of the likelihood and the prior. Sampling from a multivariate
distribution is only slightly more complicated than sampling from a
univariate distribution. If we write the joint density using the chain
rule <span class="math display">\[
f(p,q) = f(q|p) f(p)
\]</span> we realize that we can simulate from the joint distribution as
follows:</p>
<ol style="list-style-type: decimal">
<li><p>Draw <span class="math inline">\(p \sim f(p)\)</span></p></li>
<li><p>Given <span class="math inline">\(p\)</span>, draw <span
class="math inline">\(q\)</span></p></li>
</ol>
</div>
<div id="section-pedagogical-example" class="section level3">
<h3>Pedagogical example</h3>
<p>Let us consider the following example: We are told that <span
class="math inline">\(X\)</span> has a Poisson distribution with
parameter <span class="math inline">\(\mu=50\)</span> and, <span
class="math inline">\(Y|X\)</span> is a Binomial with parameter <span
class="math inline">\(X\)</span> and <span
class="math inline">\(p=1/2\)</span>. We want to sample from the joint
distribution of <span class="math inline">\((X,Y)\)</span>.</p>
<p>This problem is already set-up as we need.</p>
<div class="tutorial-exercise" data-label="example-bivariate"
data-completion="1" data-diagnostics="1" data-startover="1"
data-lines="0" data-pipe="|&gt;">
<pre class="text"><code># sample size
n.smp &lt;- 50000

# draw X from the desired Poisson
mu &lt;- 50
X &lt;- rpois(n.smp, mu)

# draw Y form the conditional distribtuion
p &lt;- 1/2
Y &lt;- rbinom(n.smp,X,p)

# get joint contingency table
T &lt;- table(X,Y)

# make a heatplot
image(as.numeric(rownames(T)), as.numeric(colnames(T)), T,
      xlab=&quot;X&quot;, ylab=&quot;Y&quot;)</code></pre>
<script type="application/json" data-ui-opts="1">{"engine":"r","has_checker":false,"caption":"<span data-i18n=\"text.enginecap\" data-i18n-opts=\"{&quot;engine&quot;:&quot;R&quot;}\">R Code<\/span>"}</script>
</div>
</div>
<div id="section-example-continued-1" class="section level3">
<h3>Example, continued</h3>
<p>This strategy works well if we can readily decompose the likelihood
into a marginal and conditional. In our example, this requires a little
bit of work…</p>
<p>Let us write <span class="math inline">\(T_1 = \sum_{i=1}^n
Z_i(1-\xi_i)\)</span> and <span class="math inline">\(T_2= \sum_{i=1}^n
(N_i-1-Z_i)(1-\xi_i)\)</span>. Then the the posterior is proportional to
<span class="math display">\[\begin{eqnarray*}
{\mathbb P}[p,q|Data] &amp;\propto&amp;  \prod_{i=1}^n q^{1-\xi_i} \left
( q (1-p)^{N_i-1} + (1-q) \right )^{\xi_i} \times
p^{T_1} (1-p)^{T_2}.
\end{eqnarray*}\]</span> Let us denote by <span class="math display">\[
f(q|p) = C(p) \prod_{i=1}^n q^{1-\xi_i} \left ( q (1-p)^{N_i-1} + (1-q)
\right )^{\xi_i}
\]</span> the conditional density of <span
class="math inline">\(q\)</span> given <span
class="math inline">\(p\)</span>. The normalizing constant is <span
class="math display">\[
C(p)^{-1} = \int_0^1 \prod_{i=1}^n q^{1-\xi_i} \left ( q (1-p)^{N_i-1} +
(1-q) \right )^{\xi_i} dq,
\]</span> so that the marginal density for <span
class="math inline">\(p\)</span> is <span class="math display">\[
f(p) \propto \frac{ p^{T_1} (1-p)^{T_2}.
}{C(p)}.
\]</span></p>
<div id="section-remark" class="section level4">
<h4>Remark</h4>
<p>We see that the marginal was <em>not</em> <span
class="math inline">\(p^{T_1}(1-p)^{T_2}\)</span>, as it also includes
the normalizing constant <span class="math inline">\(C(p)\)</span> that
was not obvious when we started out. So be careful!</p>
</div>
</div>
<div id="section-importance-sampling-from-the-postrior"
class="section level3">
<h3>Importance sampling from the postrior</h3>
<p>To sample from the posterior, we can use importance sampling to
sample from the posterior distribution of <span
class="math inline">\(p\)</span> and sample from the conditional
distribution of <span class="math inline">\(q\)</span> given <span
class="math inline">\(p\)</span> using “inverse probability sampling”.
The latter requires numerical evaluation of the normalizing constant
that is needed for the weights for the prior.</p>
<p>Just to be explicit, we sample <span class="math inline">\(p\)</span>
from a Beta with parameter <span class="math inline">\(T_1+1\)</span>
and <span class="math inline">\(T_2+1\)</span>, and weight the sample
according to the integral <span class="math display">\[
w(p) = \int_0^1 \prod_{i=1}^n q^{1-\xi_i} \left ( q (1-p)^{N_i-1} +
(1-q) \right )^{\xi_i} dq.
\]</span> Samples for <span class="math inline">\(q\)</span> are drawn
<span class="math inline">\(f(q|p)\)</span>.</p>
<pre class="r"><code># generate synthetic data

# set the parameters for simulating the data
p &lt;- 0.15
q &lt;- 0.4
n &lt;- 40

# generate the sample, using the auxiliary variables A
N &lt;- sample(seq(2,6,by=1),n,replace=TRUE)
A &lt;- rbinom(n,1,q)
Z &lt;- rep(0,n)
for ( k in 1:n ){
  if ( A[k] == 1 ) Z[k] &lt;- rbinom(1,N[k]-1,p)
}

# sample size
n.smp &lt;- 1000

# summary statistics
xi &lt;- Z == 0
T1 &lt;- sum(Z*(1-xi))
T2 &lt;- sum((N-1-Z)*(1-xi))

# assume a uniform prior

# draw from the marginal distribution of p: A beta T1+1,T2+1
# see help for how Beta parameters are specified
pp &lt;- rbeta(n.smp, T1+1,T2+1)
qq &lt;- rep(0,n.smp)
wgt &lt;- rep(0,n.smp)

# make grid to evaluate (log) probability for q given p
qx &lt;- seq(0.0005,1,by=0.001)

# calculate 
for ( j in 1:length(pp) ){
  vv &lt;- exp( (N-1) * log( 1-pp[j] ) )
  lq &lt;- rep( 0, length(qx) )
  for ( k in 1:n ){
    lq &lt;- lq + (1-xi[k])*log(qx) + xi[k]*log( qx * vv[k] + (1-qx) )
  }

  # calculate the weights
  Cp &lt;- sum( exp(lq ) )
  q.dist &lt;- cumsum( exp(lq) )/Cp
  qq[j] &lt;- qx[ max( which( q.dist &lt; runif(1) ) ) ]
  wgt[j] &lt;- Cp
}

wgt &lt;- wgt/sum(wgt)

# plot(wgt,xlab=&quot;index&quot;,ylab=&quot;weight&quot;,log=&quot;y&quot;)
ww &lt;- wgt/max(wgt)
plot(pp,qq,pch=20,cex=sqrt(ww),xlab=&quot;p&quot;,ylab=&quot;q&quot;)
abline(v=p,lty=3)
abline(h=q,lty=3)</code></pre>
<p><img src="lecture_files/figure-html/importance-2-1.png" width="624" /></p>
<p>This sampling approach is problematic.</p>
<p>Why?</p>
<p>Only a few samples have larger weights, and these observations
dominate the sample.</p>
<p>Question: Why did I plot cex=sqrt(wgt)?</p>
<p>Why?</p>
</div>
<div id="section-summary" class="section level3">
<h3>Summary</h3>
<ul>
<li><p>Sampling from multivariate using the chain rule is possible but
can be challenging.</p>
<ul>
<li>Computation of marginals and conditionals not always easy</li>
</ul></li>
<li><p>Likelihood not always easy to compute</p></li>
<li><p>Importance sampling only works if we can easily sample from a
distribution that is close from the target</p>
<ul>
<li>Heterogeneous weights, with a few large ones dominating, is a sign
that the importance sample is problematic.</li>
</ul></li>
</ul>
<p><strong>We need additional sampling tools to resolve these
issues</strong></p>
</div>
</div>
<div id="section-introduction-to-markov-chains" class="section level2">
<h2>Introduction to Markov Chains</h2>
<p>Let us pause to present a primer on Markov chains.</p>
<p>Markov chains provide a useful model to describe stochastic
processes, i.e., sequence of random variable that evolve in time. The
chain rule in probability theory says that the joint distribtuion of a
sequence of random variables <span
class="math inline">\(Z_1,Z_2,Z_3,\ldots,Z_n\)</span> is <span
class="math display">\[\begin{eqnarray*}
{\mathbb P}[Z_1,\ldots,Z_n] &amp;=&amp; {\mathbb P}[Z_1]{\mathbb
P}[Z_2|Z_1]
{\mathbb P}[Z_3|Z_1,Z_2] \dots P[Z_n|Z_1,Z_2,\ldots,Z_{n-1}].
\end{eqnarray*}\]</span> A Markov chain simplifies the above to <span
class="math display">\[
{\mathbb P}[Z_k|Z_{k-1},Z_{k-2},\ldots,Z_1] = {\mathbb P}[Z_k|Z_{k-1}].
\]</span> Then <span class="math display">\[
{\mathbb P}[Z_1,\ldots,Z_n] = {\mathbb P}[Z_1]{\mathbb P}[Z_2|Z_1] \dots
{\mathbb P}[Z_n|Z_{n-1}].
\]</span></p>
<p>In words: The current state of the process given its full past only
depends on the last state.</p>
<div id="section-fancy-way-to-state-markov-property"
class="section level4">
<h4>Fancy way to state Markov property</h4>
<p>The past and the future are conditionally independent given the
present.</p>
</div>
<div id="section-examples-of-markov-chains" class="section level3">
<h3>Examples of Markov chains</h3>
<ul>
<li><p>Card shuffling</p></li>
<li><p>Random walks (stock market?)</p></li>
<li><p>Some stochastic epidemic models</p></li>
<li><p>Birth-Death process</p></li>
<li><p>Gambler’s ruin</p></li>
<li><p>Other examples ….</p></li>
</ul>
</div>
<div id="section-useful-properties-of-markov-chains"
class="section level3">
<h3>Useful properties of Markov chains</h3>
<ul>
<li>Simplest description of dependent random variables evolving in
time</li>
</ul>
<div id="section-assumptions" class="section level4">
<h4>Assumptions</h4>
<ul>
<li><p>The you can reach every state regardless of where you
started</p></li>
<li><p>There are no periodic cycles</p></li>
</ul>
</div>
<div id="section-important-properties" class="section level4">
<h4>Important properties:</h4>
<ul>
<li><p>The distribution of <span class="math inline">\(Z_n\)</span>
converges to the same distribution (as <span
class="math inline">\(n\)</span> grows to infinity) regardless of the
initial state</p></li>
<li><p>The strength of the dependence between <span
class="math inline">\(Z_{n+k}\)</span> and <span
class="math inline">\(Z_n\)</span> decreases as <span
class="math inline">\(k\)</span> increases</p></li>
</ul>
<p><strong>We say that the chain converges</strong> to mean that
<strong>the distribution of <span class="math inline">\(Z_n\)</span>
converges</strong></p>
</div>
</div>
<div id="section-academic-example-1" class="section level3">
<h3>Academic example</h3>
<p>Consider a Markov chain with transition probability matrix <span
class="math display">\[
P_{ij} = \left ( {\mathbb P}[Z_2=j|Z_1=i ] \right )
= \left (
\begin{array}{cccccc}
&amp; 1 &amp; 2 &amp; 3 &amp; 4 &amp; 5 \\
1 &amp; 0.1 &amp; 0.8 &amp; 0.1 &amp; 0.0 &amp; 0.0 \\
2 &amp; 0.1 &amp; 0.2 &amp; 0.5 &amp; 0.2 &amp; 0.0 \\
3 &amp; 0.0 &amp; 0.1 &amp; 0.2 &amp; 0.4 &amp; 0.3 \\
4 &amp; 0.0 &amp; 0.0 &amp; 0.2 &amp; 0.3 &amp; 0.5 \\
5 &amp; 0.2 &amp; 0.0 &amp; 0.1 &amp; 0.7 &amp; 0.0
\end{array}
\right )
\]</span></p>
<div id="section-note" class="section level4">
<h4>Note</h4>
<ul>
<li><p>each row sums to one. Why?</p></li>
<li><p>the chain has no periodic cycles</p></li>
<li><p>every state can be reached from any starting value</p></li>
</ul>
<div class="tutorial-exercise" data-label="example-markov"
data-completion="1" data-diagnostics="1" data-startover="1"
data-lines="0" data-pipe="|&gt;">
<pre class="text"><code># build transition matrix
P &lt;- matrix( c(.1,.8,.1,0,0,.1,.2,.5,.2,0,0,.1,.2,.4,.3,0,0,.2,.3,.5,.2,0,.1,.7,0),
             5,5,byrow=TRUE)

states &lt;- as.character(1:5)
colnames(P) &lt;- states
rownames(P) &lt;- states
P

# each row sums to one
apply(P,1,sum)

# example of realizations 
n.smp &lt;- 10000

Z    &lt;- rep(&quot;&quot;,n.smp)

# initialize the chain.  Start in state 3
Z[1] &lt;- &quot;3&quot;

for ( k in 2:n.smp ){
  Z[k] &lt;- sample(states,1,prob=P[Z[k-1],]) # sample function 
}

# long run frequency
table(Z)/n.smp

plot( as.numeric(Z)[1:100],  # select a subset of the chain (first 100 elements)
      xlab=&quot;index&quot;, ylab=&quot;state&quot;, 
      pch=20, cex=0.5, type=&quot;b&quot;) # type=&quot;b&quot; plots both points and lines</code></pre>
<script type="application/json" data-ui-opts="1">{"engine":"r","has_checker":false,"caption":"<span data-i18n=\"text.enginecap\" data-i18n-opts=\"{&quot;engine&quot;:&quot;R&quot;}\">R Code<\/span>"}</script>
</div>
<p>Use the above code to change the initial value. Comment out lines
that show P and the rowsum of P.</p>
<p>Comment on the relative frequencies.</p>
</div>
</div>
<div id="section-academic-example-gamblers-ruin" class="section level3">
<h3>Academic example: Gambler’s ruin</h3>
<p>Two players play repeatedly a game. Player 1 wins with probability
<span class="math inline">\(p\)</span> each game, Player 2 wins with
probability <span class="math inline">\(1-p\)</span>.<br />
They bet a dollar each game. Player 1 starts with A dollars, Player 2
has B dollars. The game ends when either player runs out of money.</p>
<div class="tutorial-exercise" data-label="example-mcmc-2"
data-completion="1" data-diagnostics="1" data-startover="1"
data-lines="0" data-pipe="|&gt;">
<pre class="text"><code># example of gambler&#39;s ruin
n.smp &lt;- 150
Z &lt;- rep(0,n.smp)

Z[1] &lt;- 10 # initial value
Tot &lt;- 20  # total wealth of both players
p &lt;- 0.5   # prob that player 1 wins

# random walk with biased coin.  Stop when either 
# player runs out of money

for ( k in 2:n.smp ){
  if ( Z[k-1] == 0 ) {
    Z[k] &lt;- 0
  } else {
    if ( Z[k-1] == Tot ){
      Z[k] &lt;- Tot
    } else {
    Z[k] &lt;- Z[k-1] + 2*((runif(1) &lt; p )-0.5)
    }
  }
}

Z</code></pre>
<script type="application/json" data-ui-opts="1">{"engine":"r","has_checker":false,"caption":"<span data-i18n=\"text.enginecap\" data-i18n-opts=\"{&quot;engine&quot;:&quot;R&quot;}\">R Code<\/span>"}</script>
</div>
<p>Run the example a few times.</p>
<div id="section-question" class="section level4">
<h4>Question:</h4>
<ol style="list-style-type: decimal">
<li>Is this a Markov chain?</li>
<li>What is the long term behavior of this process? Discuss
convergence.</li>
</ol>
</div>
</div>
<div id="section-convergence-of-markov-chains" class="section level3">
<h3>Convergence of Markov chains</h3>
<p>Lets modify the chain in our first example by mixing it with the
identity <span class="math display">\[
P_2 = (1-a) P + a I
\]</span> where <span class="math inline">\(a \in (0,1)\)</span>. What
do you think is the effect of that mixture?</p>
<div class="tutorial-exercise" data-label="example-mcmc-3"
data-completion="1" data-diagnostics="1" data-startover="1"
data-lines="0" data-pipe="|&gt;">
<pre class="text"><code># build transition matrix
P &lt;- matrix( c(.1,.8,.1,0,0,.1,.2,.5,.2,0,0,.1,.2,.4,.3,0,0,.2,.3,.5,.2,0,.1,.7,0),
             5,5,byrow=TRUE)

states &lt;- as.character(1:5)
colnames(P) &lt;- states
rownames(P) &lt;- states

aa &lt;- 0.5 # mixture fraction

P2 &lt;- (1-aa)*P + aa*diag(5) # diag(5) is the identity matrix

# example of realizations 
n.smp &lt;- 10000

Z    &lt;- rep(&quot;&quot;,n.smp)

# initialize the chain.  Start in state 3
Z[1] &lt;- &quot;3&quot;

for ( k in 2:n.smp ){
  Z[k] &lt;- sample(states,1,prob=P2[Z[k-1],]) # sample function 
}

plot( as.numeric(Z)[1:300],  # select a subset of the chain (first 100 elements)
      xlab=&quot;index&quot;, ylab=&quot;state&quot;, 
      pch=20, cex=0.5, type=&quot;b&quot;) # type=&quot;b&quot; plots both points and lines

# long run frequency
table(Z)/n.smp</code></pre>
<script type="application/json" data-ui-opts="1">{"engine":"r","has_checker":false,"caption":"<span data-i18n=\"text.enginecap\" data-i18n-opts=\"{&quot;engine&quot;:&quot;R&quot;}\">R Code<\/span>"}</script>
</div>
<div id="section-questions" class="section level4">
<h4>Questions:</h4>
<ul>
<li><p>Does the chain converge?</p></li>
<li><p>If so, to what distribution? Is it the same distribtuion
regardless of <span class="math inline">\(a\)</span>?</p></li>
<li><p>Is convergence slower? Discussion.</p></li>
</ul>
</div>
</div>
<div id="section-example-a-stochastic-sis-model" class="section level3">
<h3>Example: A stochastic SIS model</h3>
<p>Susceptible-Infected-Susceptible models are useful to understanding
endemic persistent diseases. We can write a simple SIS model as follows:
Let <span class="math inline">\(N\)</span> denote the population size,
which will remain constant. <span class="math inline">\(Z_k\)</span>
will denote the number of infected individuals in time period <span
class="math inline">\(k\)</span>. In each time step, each infected
individual can infect susceptible individuals with common probability of
infection <span class="math inline">\(p\)</span>, and each infected
individual recovers independently in each time step with
probability.</p>
<p>This model is readily described using two auxilliary random
variables: <span class="math display">\[\begin{eqnarray*}
V_k|Z_k &amp;=&amp; Bin(Z_k,q)\\
U_k|Z_k &amp;=&amp; Bin(N-Z_k,1-(1-p)^{Z_k})\\
Z_{k+1} &amp;=&amp; Z_k + U_k - V_k.
\end{eqnarray*}\]</span></p>
<p>The sequence <span class="math inline">\(Z_1,Z_2,\ldots\)</span>
forms a Markov chain.</p>
<ul>
<li><p>Why?</p></li>
<li><p>What is the stationary distribution?</p></li>
</ul>
<div class="tutorial-exercise" data-label="example-sis"
data-completion="1" data-diagnostics="1" data-startover="1"
data-lines="0" data-pipe="|&gt;">
<pre class="text"><code># set-up
Npop &lt;- 100     # population size
p0 &lt;- 0.003      # infection probability
q &lt;- 0.2        # recovery probability

n.times &lt;- 1000 # length of simulation
Z &lt;- rep(0,n.times)
Z[1] &lt;- 10      # initial number of infections

# run markov chain
for ( k in 2:n.times ){
  pp &lt;- 1 - exp( Z[k-1]*log(1-p0))
  U &lt;- rbinom(1,Npop-Z[k-1],pp)
  V &lt;- rbinom(1,Z[k-1],q)
  Z[k] &lt;- Z[k-1] + U - V
}

plot(Z,xlab=&quot;time&quot;,ylab=&quot;# infected&quot;,sub=&quot;SIS&quot;,
     pch=20,cex=0.75)</code></pre>
<script type="application/json" data-ui-opts="1">{"engine":"r","has_checker":false,"caption":"<span data-i18n=\"text.enginecap\" data-i18n-opts=\"{&quot;engine&quot;:&quot;R&quot;}\">R Code<\/span>"}</script>
</div>
<div id="section-exercise-2" class="section level4">
<h4>Exercise</h4>
<p>Modify the code to gain insight into the impact of changing the
probability of infection ’‘’p0’‘, the probability of recovery ’q’, and
the populatiuon size ‘Npop’.</p>
<p>Discuss how the behavior of the chain depensd on these
quantities.</p>
</div>
</div>
</div>
<div id="section-gibbs-sampler" class="section level2">
<h2>Gibbs sampler</h2>
<p><img src="Gibbs.jpg" width="50%" style="display: block; margin: auto 0 auto auto;" /></p>
<p>Gibbs was a physicist (at Yale), late 1800. He developed a method to
sample from spin glass models. His approach generalizes for sampling
from joint distribtuions of random variables.</p>
<div id="section-algorithm" class="section level3">
<h3>Algorithm</h3>
<p>Let <span class="math inline">\(f(x_1,x_2)\)</span> denote the joint
density of two random variables <span
class="math inline">\((X_1,X_2)\)</span>. Let <span
class="math inline">\(f_{12}(x_1|x_2)\)</span> and <span
class="math inline">\(f_{21}(x_2|x_1)\)</span> denote the conditional
densities of <span class="math inline">\(X_1\)</span> given <span
class="math inline">\(X_2\)</span>, and of <span
class="math inline">\(X_2\)</span> given <span
class="math inline">\(X_1\)</span>. And denote by <span
class="math inline">\(f_1(x_1)\)</span> and <span
class="math inline">\(f_2(x_2)\)</span> the marginal densities of <span
class="math inline">\(X_1\)</span> and <span
class="math inline">\(X_2\)</span>, respectively.</p>
<div id="section-algorithm-1" class="section level4">
<h4>Algorithm</h4>
<ul>
<li><p>Initialize <span
class="math inline">\((x_1^{(0)},x_2^{(0)})\)</span>.</p></li>
<li><p>For <span class="math inline">\(k=1,2,\ldots\)</span></p>
<ul>
<li><p>Draw <span class="math inline">\(x_1^{(k)} \sim f_{12}(\cdot |
x_2^{(k-1)})\)</span></p></li>
<li><p>Draw <span class="math inline">\(x_2^{(k)} \sim f_{21}(\cdot|
x_1^{(k)})\)</span></p></li>
</ul></li>
<li><p>For <span class="math inline">\(k\)</span> large enough, the
sampled pair <span class="math inline">\((x_1^{(k)},x_2^{(k)})\)</span>
have (approximate) joint distribution <span
class="math inline">\(f(x_1,x_2)\)</span>.</p></li>
</ul>
</div>
<div id="section-remarks" class="section level4">
<h4>Remarks</h4>
<ul>
<li><p>The algorithm constructs a Markov chain <span
class="math inline">\((X_1^{(k)},X_2^{(k)})\)</span></p></li>
<li><p>Algorithm readily extends to any multivariate
distribution</p></li>
<li><p>If it is asy to sample from <span
class="math inline">\(f_1(x_1)\)</span> and <span
class="math inline">\(f_{21}(x_2|x_1)\)</span>, then can directly sample
from joint distribution — no need for Gibbs sampler</p></li>
<li><p>The Gibbs sampler is useful if the conditional
densities/conditional distributions are easy to calculate and sample
from.</p></li>
</ul>
</div>
</div>
<div id="section-a-little-theory" class="section level3">
<h3>A little theory</h3>
<p>The sequence <span class="math inline">\(\{(X_1^{(k)},X_2^{(k)}),
k=1,2,\ldots\}\)</span> forms a Markov chain with transition probability
to go from <span class="math inline">\(x=(x_1,x_2)\)</span> to <span
class="math inline">\(y=(y_1,y_2)\)</span> given by <span
class="math display">\[
k(y|x) = f_{21}(y_2|y_1)f_{12}(y_1|x_2).
\]</span></p>
<p>The join density <span class="math inline">\(f(x_1,x_2)\)</span> is a
stationary distribution for that transition.</p>
<div id="section-heuristic-proof" class="section level4">
<h4>Heuristic proof</h4>
<p>All we need to show is that <span class="math display">\[
I = \int_{{\mathbb R}^2} k((y_1,y_2)|(x_1,x_2)) f(x_1,x_2) dx_1dx_2 =
f(y_1,y_2).
\]</span> We have that <span class="math display">\[\begin{eqnarray*}
I &amp;=&amp; f_{21}(y_2|y_1) \int_{x_2} f_{12}(y_1|x_2) \int_{x_1}
f(x_1,x_2) dx_1 dx_2\\
&amp;=&amp; f_{21}(y_2|y_1) \int_{x_2} f_{12}(y_1|x_2) f_2(x_2) dx_2 \\
&amp;=&amp; f_{21}(y_2|y_1)  f_{1}(y_1)\\
&amp;=&amp; f(y_1,y_2).
\end{eqnarray*}\]</span></p>
<p>A more formal proof puts assumptions that ensures that the Markov
chain is such that every possible state is reachable from any initial
state.</p>
</div>
</div>
<div id="section-academic-example-ising-model" class="section level3">
<h3>Academic example: Ising model</h3>
<p>We have particles placed on a regular <span class="math inline">\(N
\times N\)</span> grid. Each particle points up or down. That is, at
each grid point, we have random variables <span
class="math inline">\(Z_{ij} \in \{-1,+1\}\)</span>. The distribution of
these random variables are determined by the conditional distributions [
{P}[Z_{ij}=1 | Z_{-(i,j)}] ( <em>{(k,) (i,j)} Z</em>{k} ) {P}[Z_{ij}=-1
| Z_{-(i,j)}] ( - <em>{(k,) (i,j)} Z</em>{k} )</p>
<p>] where <span class="math inline">\((k,\ell) \sim (i,j)\)</span> if
they are neighbors on grid. To avoid edge effects, we will connect the
top and bottom, and the left and right edges.</p>
<pre><code>## Error in dim(robj) &lt;- c(dX, dY): attempt to set an attribute on NULL</code></pre>
<p><img src="lecture_files/figure-html/figure-1.png" width="624" /></p>
<p>This is the problem that Gibbs considered</p>
<div class="tutorial-exercise" data-label="gibbs-ising"
data-completion="1" data-diagnostics="1" data-startover="1"
data-lines="0" data-pipe="|&gt;">
<pre class="text"><code>N &lt;- 20 # size of grid

Z &lt;- matrix(1,N,N) # grid of random variables, initalized to one

index.p1 &lt;- c(2:N,1) # index shifted to the right
index.n1 &lt;- c(N,1:(N-1)) # index shfted to the left 

n.sim &lt;- 500 # number of steps in the Gibbs sampler

theta &lt;- 0.75

# sampling from the conditionals
for ( K in 1:n.sim ){
  for ( k in 1:N ){
    for ( j in 1:N ){
      S &lt;- sum( Z[k,c(index.p1[j],index.n1[j])] ) +
        sum( Z[c(index.n1[k],index.p1[k]),j])
      P &lt;- exp(theta*S)/(1+exp(theta*S))
      Z[k,j] &lt;- 2*((runif(1) &lt; P)-0.5)
    }
  }
}

image(1:N, 1:N, Z)</code></pre>
<script type="application/json" data-ui-opts="1">{"engine":"r","has_checker":false,"caption":"<span data-i18n=\"text.enginecap\" data-i18n-opts=\"{&quot;engine&quot;:&quot;R&quot;}\">R Code<\/span>"}</script>
</div>
<p>If you set <span class="math inline">\(\theta=0\)</span>, then each
random variable <span class="math inline">\(Z_{ij}\)</span> is
independent, with probability <span class="math inline">\({\mathbb
P}[Z_{ij}=1]=0.5\)</span>. A positive value of <span
class="math inline">\(\theta\)</span> encourages positive dependence, a
negative value leads to negative dependence.</p>
<p>This model can be used to describe the spatial distribution of
plants.</p>
</div>
<div id="section-example-2-continued" class="section level3">
<h3>Example 2, continued</h3>
<div id="section-conditional-densities" class="section level4">
<h4>conditional densities</h4>
<p>We can apply the Gibbs sampler to build a Markov chain to generate
draws from the posterior distribution. Let me denote by <span
class="math inline">\(\xi_i = {\mathbb I}(Z_i=0)\)</span>, the indicator
that we observe zero secondary infections. Then conditional distribution
of <span class="math inline">\(q\)</span> given <span
class="math inline">\(p\)</span> and the data is <span
class="math display">\[
h(q|p) \propto
\prod_{i=1}^n q^{1-\xi_i} \left ( q (1-p)^{N_i-1} + (1-q) \right
)^{\xi_i},
\]</span> and the conditional density of <span
class="math inline">\(p\)</span> given <span
class="math inline">\(q\)</span> and the data is <span
class="math display">\[
g(p|q) \propto \prod_{i=1}^n \left ( q (1-p)^{N_i-1} + (1-q) \right
)^{\xi_i} \times p^{T_1} (1-p)^{T_2}.
\]</span></p>
<p>We can sample from both of these conditional distribution using brute
force. But there is simpler (and instructive way) to sample.</p>
</div>
</div>
<div id="section-how-to-simulate-this-data" class="section level3">
<h3>How to simulate this data</h3>
<p>It is instructive to take a step back and ask ourselves how to
generate the data. From the description of the data:</p>
<ul>
<li><p>For each household <span class="math inline">\(i\)</span>,
generate a 0-1 random variable <span class="math inline">\(A_i\)</span>,
where <span class="math inline">\(A_i=1\)</span> with probability <span
class="math inline">\(q\)</span>. That variable indicates if household
<span class="math inline">\(i\)</span> contains an infectious index
case.</p></li>
<li><p>If <span class="math inline">\(A_i=1\)</span>, generate a
Binomial random variable <span class="math inline">\(Z_i\)</span> with
size <span class="math inline">\(N_i-1\)</span> and probability <span
class="math inline">\(p\)</span>. That random variable represents the
number of secondary infections.</p></li>
</ul>
</div>
<div id="section-missing-observations" class="section level3">
<h3>Missing observations</h3>
<p>Our data does not include the indicators <span
class="math inline">\(A_1,\ldots,A_n\)</span>. We can consider that we
are missing that information. The strength of a Bayesian analysis is
that we can model the generative process (see above). Such a model has
unknowns the vector of random variables <span
class="math inline">\((p,q,A_1,\ldots,A_n)\)</span>.</p>
<p>Let us explore writing the conditional distributions of each
individual random variable given the others and the data:</p>
<p><span class="math display">\[\begin{eqnarray*}
q | p, A_1,\ldots, A_n, \mbox{ Data } &amp;\sim&amp; q^{\sum_{i=1}^n
A_i} (1-q)^{n-\sum_{i=1}^n (1-A_i)}\\
&amp;\sim&amp; \mbox{Beta} \left (1+\sum_{i=1}^n A_i, n+1-\sum_{i=1}^n
A_i
\right )\\
p | q, A_1,\ldots, A_n, \mbox{ Data } &amp;\sim&amp; \prod_{i : A_i=1 }
{N_i -1 \choose z_i}
p^{z_i} (1-p)^{N_i-1-z_i}\\
&amp;\sim&amp; \mbox{Beta} \left (1+\sum_{i=1}^n A_iz_i, 1+\sum_{i=1}^n
A_i(N_i-z_i-1)
\right )
\end{eqnarray*}\]</span> and <span class="math display">\[
{\mathbb P}[A_i=1 | A^{-i}, p ,q, \mbox{ Data }] =
\left \{
\begin{array}{ll}
1 &amp; z_i &gt; 0 \\ \frac{q(1-p)^{N_i-1}}{((1-q)+q(1-p)^{N_i-1}} &amp;
z_i=0
\end{array}
\right .
\]</span></p>
<p>These conditional distributions are easy to sample from. So let us
use the Gibbs sampler to draw from our extended set of random
variables.</p>
</div>
<div id="section-numerical-example-2" class="section level3">
<h3>Numerical Example</h3>
<div class="tutorial-exercise" data-label="gibbs" data-completion="1"
data-diagnostics="1" data-startover="1" data-lines="0"
data-pipe="|&gt;">
<pre class="text"><code># generate synthetic data

# set the parameters for simulating the data
p &lt;- 0.15
q &lt;- 0.4
n &lt;- 40

# generate the sample, using the auxiliary variables A
N &lt;- sample(seq(2,6,by=1),n,replace=TRUE)
A &lt;- rbinom(n,1,q)
Z &lt;- rep(0,n)
for ( k in 1:n ){
  if ( A[k] == 1 ) Z[k] &lt;- rbinom(1,N[k]-1,p)
}

#  Initialize Gibbs sampler
niter &lt;- 5000

pp &lt;- rep(0,niter)
qq &lt;- rep(0,niter)
AA &lt;- matrix(0,niter,n)

pp[1] &lt;- 0.5
qq[1] &lt;- 0.5
AA[1,] &lt;- sample(c(0,1),n,replace = TRUE)

for ( k in 2:niter ){
  # conditional on p and q and the probability A_i=1 is
  rA &lt;- Z &gt; 0
  for ( j in 1:n ){
    if ( Z[j] == 0 ){
      p.num &lt;- qq[k-1]*exp( (N[j]-1)*log(1-pp[k-1]) )
      p.dem &lt;- p.num + (1-qq[k-1])
      pA &lt;- p.num/p.dem
      rA[j] &lt;- runif(1) &lt; pA
    }
  }
  AA[k,] &lt;- rA
  
  # draw Beta for q
  aa &lt;- sum(AA[k,])+1
  bb &lt;- n-sum(AA[k,])+1
  qq[k] &lt;- rbeta(1,aa,bb)
  
  # draw Beta for p
  aa &lt;- sum(AA[k,]*Z) + 1
  bb &lt;- sum(AA[k,]*(N-1-Z)) + 1
  pp[k] &lt;- rbeta(1,aa,bb)
}

hist(pp,nclass=100,xlim=c(0,1),
     sub=&quot;histogram of infection probability&quot;,
     xlab=&quot;probability&quot;,
     main=&quot;&quot;)
abline(v=p,lwd=2,col=2)

hist(qq,nclass=100,xlim=c(0,1),
     sub=&quot;histogram of household with index&quot;,
     xlab=&quot;probability&quot;,
     main=&quot;&quot;)
abline(v=q,lwd=2,col=2)

jd &lt;- kde2d(pp,qq,n=100)
contour(jd,xlab=&quot;p&quot;,ylab=&quot;q&quot;,
        lwd=2, nlevels = 15,
        sub=&quot;joint posterior distribtuion&quot;,
        col=hcl.colors(15, &quot;Spectral&quot;))
points(pp[(niter-4000):niter],qq[(niter-4000):niter],pch=20,cex=0.3)</code></pre>
<script type="application/json" data-ui-opts="1">{"engine":"r","has_checker":false,"caption":"<span data-i18n=\"text.enginecap\" data-i18n-opts=\"{&quot;engine&quot;:&quot;R&quot;}\">R Code<\/span>"}</script>
</div>
</div>
<div id="section-lesson-learned" class="section level3">
<h3>Lesson learned</h3>
<p>An important feature of Bayesian analysis, is that we can model the
data generation process.</p>
<ul>
<li><p>Our analysis can introduce and exploit random variables
associated with the data generation process but that are not directly
observed. We call this technique <em>Data Augmentation</em></p></li>
<li><p>The Gibbs sampler generates a Markov chain for all the random
variables.<br />
Marginalization over the augmented random variables is done by dropping
these variable.</p></li>
<li><p>Posterior distributions are not always tight. This happens if the
data does not constrain well the parameter (think process associated
with the parameter).</p></li>
<li><p>Can compute/visualize joint posterior distributions</p></li>
<li><p>Downside: we need to have easy to sample conditional
distributions. This may require user time to derive them. So this method
is not turn key and requires some mathematical skills.</p></li>
</ul>
</div>
<div id="section-open-questions" class="section level3">
<h3>Open questions</h3>
<p>We generate a Markov chain to sample the posterior distribuion.</p>
<ul>
<li><p>How fast does the Markov chain converge?</p></li>
<li><p>Consecutive draws are correlated. Does that matter?</p></li>
</ul>
</div>
</div>
<div
id="section-example-3-post-epidemic-estimation-of-the-basic-reproductive-number"
class="section level2">
<h2>Example 3: Post-epidemic estimation of the basic reproductive
number</h2>
<div id="section-basic-reproductive-number" class="section level3">
<h3>Basic reproductive number</h3>
<p>The basic reproductive number <span
class="math inline">\(\varrho_0\)</span> is a useful characterization of
an epidemic. Formally it is defined as</p>
<p><em>The basic reproductive number is the expected number of secondary
cases associated with an idex case in a fully susceptible
population</em></p>
<ul>
<li><p>If the basic reproductive number is larger than one, the outbreak
has non-zero epidemic potential. If it is less than one, the outbreak
will die out.</p></li>
<li><p>For the SIR models, the basic reproductive number is <span
class="math display">\[
R_0 = \frac{\beta}{\gamma}
\]</span></p></li>
</ul>
<p>How can we estimate that parameter from disease incidence outbreak
data?</p>
</div>
<div id="section-disease-incidence-data" class="section level3">
<h3>Disease incidence data</h3>
<p>Consider daily incidence data from five Maryland counties during the
1918 influenza (Spanish flu) pandemic.</p>
<p><strong>Disease incidence</strong> is the number of new infections
per unit of time. For example, the daily number of new infections during
an outbreak.</p>
<p><img src="lecture_files/figure-html/epi-influenza-1.png" width="624" /></p>
<pre><code>##            incidence population
## Baltimore       7489      74817
## Cumberland      2085      29837
## Lonaconing      1093       7000
## Frederick        750      11066
## Salisbury        765       7553</code></pre>
</div>
<div id="section-total-fraction-infected" class="section level3">
<h3>Total fraction infected</h3>
<p>As a first example of a Bayesian MCMC analysis, let us model the
total number of infected individuals in each county.</p>
<p>Algebraic manipulations of the SIR differential equations and their
solutions reveals that the fraction of infected individuals at the
conclusion of an outbreak is <span class="math inline">\(N \pi\)</span>,
with the fraction <span class="math inline">\(\pi\)</span> satisfying
the implicit equation</p>
<p><span class="math display">\[
\pi = 1 - \exp( -R_0 \pi ),
\]</span></p>
<p>where <span class="math inline">\(R_0 = \beta/\gamma\)</span> is the
basic reproductive number. Reference: <span
class="citation">@Miller2012</span>.</p>
</div>
<div id="section-a-probabilistic-derivation" class="section level3">
<h3>A probabilistic derivation</h3>
<p>The fraction infected can be interpreted as the probability that a
randomly selected individual will become infected. To derive that
probability, assume that</p>
<ul>
<li><p>Every individual is equally likely to be infected</p></li>
<li><p>The expected number of infections from the index case is <span
class="math inline">\(R_0\)</span></p></li>
<li><p>The fraction of infections at the end of an outbreak <span
class="math inline">\(X/N \approx \pi\)</span>.</p></li>
</ul>
<p>Let <span class="math inline">\(u\)</span> be a particular individual
subjected to, but not driving the epidemic outbreak. The probability
that it becomes infected from a particular infected individual <span
class="math inline">\(i\)</span> is <span class="math display">\[
{\mathbb P}[u \mbox{ infected by } i] = p.
\]</span> The number of infections <span
class="math inline">\(Z\)</span> attributable to <span
class="math inline">\(i\)</span> (when <span
class="math inline">\(i\)</span> is the index case) is a Binomial<span
class="math inline">\((N,p)\)</span>, and by definition <span
class="math display">\[
{\mathbb E}[Z] = Np = R_0.
\]</span> This implies that <span
class="math inline">\(p=R_0/N\)</span>.</p>
<p>The probability that individual <span
class="math inline">\(u\)</span> <em>is infected during the
outbreak</em> is <span class="math display">\[\begin{eqnarray*}
\pi &amp;=&amp; {\mathbb P}[Bin(X,p) &gt; 0]\\
&amp;\approx&amp; 1 - \exp(-X p)  = 1 - \exp \left ( -\frac{X R_0}{N}
\right )\\
&amp;\approx&amp; 1 - \exp(-\pi R_0).
\end{eqnarray*}\]</span></p>
<p>The approximations become equality when the population size <span
class="math inline">\(N\)</span> tends to infinity.</p>
</div>
<div id="section-a-model-for-the-total-number-of-infected"
class="section level3">
<h3>A model for the total number of infected</h3>
<p>We can we estimate the basic reproductive number <span
class="math inline">\(R_0\)</span> by estimating the fraction infected,
and solving the implicit equation <span class="math display">\[
\pi = 1-exp(-R_0 \pi).
\]</span></p>
<p>Since the solution is unique, we can parametrize <span
class="math inline">\(\pi=\pi(R_0)\)</span>. Bayesian inference allows
us to make inference on <span class="math inline">\(R_0\)</span>.</p>
<p>Our derivation reveals that the total expected number of infections
is <span class="math display">\[
{\mathbb E}[X] = N \pi.
\]</span> We posit that the distribution of the total number infected
<span class="math inline">\(X\)</span> is a negative binomial with
parameters <span class="math inline">\((s,q)\)</span>, a convenient
model for <em>overdispersed Poisson</em>.</p>
<p>The negative binomial has probability mass function <span
class="math display">\[
{\mathbb P}[X=k] = {k+s-1 \choose r-1} (1-q)^k q^s \qquad k=0,1,2,\ldots
\]</span></p>
<p>We can use expressions for the expectation and variance to fix the
parameters <span class="math inline">\(s,q\)</span>: <span
class="math display">\[
{\mathbb E}[X] = s \frac{1-q}{q} \mbox{ and } V(X) = s \frac{(1-q)}{q^2}
\geq {\mathbb E}[X].
\]</span></p>
<p>The R <code>[x]nbinom</code> function can be called with parameters
the expectation <span class="math inline">\(\mu\)</span> (we want <span
class="math inline">\(\mu=N\pi\)</span>) and dispersion (or shape)
parameter <span class="math inline">\(s\)</span>, and <span
class="math display">\[
q  = \frac{s}{s+\mu}.
\]</span></p>
<p><img src="lecture_files/figure-html/plot-negative-binomial-1.png" width="624" /></p>
</div>
<div id="section-posterior-for-r_0-for-fixed-shape-s."
class="section level3">
<h3>Posterior for <span class="math inline">\(R_0\)</span> for fixed
shape <span class="math inline">\(s\)</span>.</h3>
<p>Given total infection counts <span
class="math inline">\(X_1,\ldots,X_n\)</span> in populations of
respective sizes <span class="math inline">\(N_1,\ldots,N_n\)</span>,
the likelihood for <span class="math inline">\(R_0\)</span>
<strong>given the shape parameter <span
class="math inline">\(s\)</span></strong> in our negative binomial model
is</p>
<p><span class="math display">\[\begin{eqnarray*}
L(R_0,s) \propto \prod_{i=1}^n  
\left ( \frac{s}{s+N_i\pi(R_0)} \right )^{X_i}
\left ( 1 - \frac{s}{s+N_i\pi(R_0)} \right )^s.
\end{eqnarray*}\]</span> where <span class="math display">\[
\pi(R_0) = 1 - \exp(-R_0 \pi)
\]</span></p>
<p>Again we have a complicated likelihood to sample from. Here we
present a powerful algorithm that can sample from any (multivariate)
distribution.</p>
</div>
<div id="section-the-metropolis-hastings-algorithm"
class="section level3">
<h3>The Metropolis-Hastings algorithm</h3>
<p>Algorithm first proposed by Metropolis (1953, Los Alamos) with
Arianna and Marchall Rosenbluth, and Augusta and Edward Teller. Hastings
generalized it in 1970 and made it widedly applicable.</p>
<p>The aim is to sample from a probability distribution proportional to
<span class="math inline">\(f(x)\)</span>. The strategy is to construct
a Markov chain (like for the Gibbs sampler) by proposing new values
<span class="math inline">\(x^\prime\)</span> and move to that proposed
value with suitable probability.</p>
<div id="section-ingredients" class="section level4">
<h4>Ingredients</h4>
<ol style="list-style-type: decimal">
<li><p>A positive (integrable) function <span
class="math inline">\(f(x)\)</span> to sample from</p></li>
<li><p>A proposal distribution (strategy to propose the next value)
<span class="math inline">\(k(x^\prime|x)\)</span>. For
<strong>Metropolis</strong>, <span
class="math inline">\(k(x^\prime|x)=k(x|x^{\prime})\)</span>.</p></li>
</ol>
</div>
<div id="section-metropolis-algorithm" class="section level4">
<h4>Metropolis Algorithm</h4>
<ol style="list-style-type: decimal">
<li><p>Initalize <span class="math inline">\(x^{(0)}\)</span>.</p></li>
<li><p>Given current value <span class="math inline">\(x^{(k)}\)</span>,
drawn a proposal <span class="math inline">\(x^\prime\)</span> from the
proposal distribution <span
class="math inline">\(k(x^\prime|x)\)</span></p></li>
<li><p>Calculate the ratio <span class="math display">\[
R = \min \left ( 1, \frac{f(x^\prime)}{f(x)} \right )
\]</span></p></li>
<li><p>Draw <span class="math inline">\(U\)</span>, a uniform random
variable</p></li>
<li><p>Update the state of Markov chain <span class="math display">\[
x^{(k+1)} = \left \{
\begin{array}{ll} x^\prime &amp; U \leq R \\ x^{(k)} &amp; U &gt; R
\end{array} \right .
\]</span></p></li>
</ol>
</div>
</div>
<div
id="section-example-draw-sample-from-posterior-for-r_0-for-fixed-s5."
class="section level3">
<h3>Example: Draw sample from posterior for <span
class="math inline">\(R_0\)</span> for fixed <span
class="math inline">\(s=5\)</span>.</h3>
<p>Assume a uniform prior distribution (strictly speaking not a true
prior. Why?). The posterior we want to sample from is</p>
<p><span class="math display">\[
L(R_0) =  \prod_{i=1}^n  
\left ( \frac{5}{5+N_i\pi(R_0)} \right )^{X_i}
\left ( 1 - \frac{5}{5+N_i\pi(R_0)} \right )^5
\]</span></p>
<p>Let us use the Metropolis-Hastings algorithm to sample from the
posterior distribution of <span
class="math inline">\(\pi\)</span>.<br />
Its implementation is greatly simplified by considering the following
transformation of the parameters:</p>
<p><span class="math display">\[
\theta = \log \left ( \frac{\pi}{1-\pi} \right )
\]</span> the logit transform of <span
class="math inline">\(\pi\)</span> (why?).</p>
<p>The range of the transformed variables range is <span
class="math inline">\({\mathbb R}\)</span>, allowing us to use simple
random walks to generate proposed parameter values.</p>
<p>Here below is R-code to sample the posterior distribution. The two
parameter that control this sampler are</p>
<ul>
<li><p><code>n.iter</code>, the number of iterations of the
algorithm</p></li>
<li><p><code>sdd</code>, the standard deviation of the Gaussian random
variable used to generate proposals. Proposal are produced using a
random walk <span class="math display">\[
\theta^\prime = \theta^{(k)} + \sigma \xi
\]</span> where <span class="math inline">\(\xi\)</span> is a standard
Gaussian random variable and <span class="math inline">\(\sigma\)</span>
is the step size.</p></li>
</ul>
<pre class="r"><code>flu.data &lt;- read.table(&quot;Maryland_incidence.csv&quot;, 
                       sep=&quot;,&quot;, header=TRUE )
flu.data[,1] &lt;- as.Date(flu.data[,1],format = &quot;%d/%m/%Y&quot;)
pop.maryland &lt;- scan(&quot;pop_Maryland_1920.csv&quot;,
                           sep=&quot;,&quot;, skip=1, what=0)
names(pop.maryland) &lt;- scan(&quot;pop_Maryland_1920.csv&quot;, n=5, what=&quot;&quot;, sep=&quot;,&quot;)

tot.infected &lt;- apply(flu.data[,-1],2,sum)

n.iter &lt;- 3000
logit.pi &lt;- rep( 0, n.iter )
LL &lt;- rep( 0,n.iter )
AA &lt;- rep(0, n.iter )

#. initialize variables
sdd &lt;- 0.1
logit.pi[1] &lt;- 0

ssize &lt;- 5

mu &lt;- pop.maryland * exp( logit.pi[1])/(1+exp( logit.pi[1]) )
LL[1] &lt;- sum( dnbinom(tot.infected, ssize, mu=mu, log=TRUE) )

for ( k in 2:n.iter ){
  
  #. propose a new value
  new.logit.pi &lt;- logit.pi[k-1] + rnorm(1,mean=0,sd=sdd )

  #. evaluate the loglikelihood
  new.mu &lt;- pop.maryland * exp( new.logit.pi )/(1+exp( new.logit.pi ) )
  new.LL &lt;- sum( dnbinom(tot.infected, ssize, mu=new.mu, log=TRUE) )
  
  RR &lt;- exp( min( new.LL - LL[k-1], 1 ) )
  UU &lt;- runif(1)
  
  if ( UU &lt; RR ){
    AA[k] &lt;- 1
    LL[k] &lt;- new.LL
    logit.pi[k] &lt;- new.logit.pi
  } else {
    LL[k] &lt;- LL[k-1]
    logit.pi[k] &lt;- logit.pi[k-1]
  }
}

#. transform into a distribution for varrho
ppi &lt;- exp(logit.pi)/(1 + exp(logit.pi) )
varrho &lt;- -log( 1-ppi )/ppi

#. make histogram of value after burn in
hist( varrho[1001:n.iter], nclass=100, xlim=c(1,1.2),
      xlab=&quot;basic reproductive number&quot;,
      main=&quot;histogram of estimated reproductive number&quot;)</code></pre>
<p><img src="lecture_files/figure-html/mcmc-negative-binomial-1.png" width="624" /></p>
</div>
<div id="section-sampling-from-a-markov-chain" class="section level3">
<h3>Sampling from a Markov chain</h3>
<p>The MCMC generates samples by running from a Markov Chain.<br />
The chain is constructed so that its stationary distribution is the what
we want to sample from. But one may need to run the chain for a while to
get the chain to converge.</p>
<p><img src="lecture_files/figure-html/example-burnin-1.png" width="624" /></p>
<p>Even once we converge to the stationary distribtuion, we expect
consecutive draws to be correlated. The autocorrelation function of the
draws from the above example is</p>
<p><img src="lecture_files/figure-html/example-acf-1.png" width="624" /></p>
<p>Another ‘feature’ of the chain is the acceptance ratio, the fraction
of times that the chain accepts to move to the new proposed value.</p>
<p><img src="lecture_files/figure-html/example-acceptance-1.png" width="624" /></p>
</div>
<div id="section-selecting-proposals" class="section level3">
<h3>Selecting proposals</h3>
<p>The behavior of the chain is controlled by the parameter
<code>sdd</code> that determines how close proposals are to the current
value.</p>
<p>Our discussion here below assumes that the likelihood is somewhat
peaked about its maximum. This happens when we have enough data.</p>
<p>If that parameter is selected very small, the likelihood at the
parameter proposal value may be similar to the likelihood of the current
likelihood. This results in general to larger acceptance ratios, but the
accepted steps will be small. This typically, would increase the serial
correlation (acf) and lengthen the time it takes for the chain to reach
stationary.</p>
<p>Conversely, consider larger steps size leading to proposed parameter
values far away from the current value. If the likelihood is
concentrated around its maximum, then the likelihood at the proposals
can be significantly smaller, leading to low acceptance ratio. Again,
this will increase the serial correlation of the chain and the time for
it to reach stationary.</p>
</div>
<div id="section-bayesian-predictions" class="section level3">
<h3>Bayesian predictions</h3>
<p>It is useful/important to assess model fit by comparing data to model
fit. One way to do this is to compute the posterior predictive
distribution for the observations. Formally, if <span
class="math inline">\({\mathbb P}[\theta|Data]\)</span> denotes the
posterior and <span class="math inline">\({\mathbb P}[X|\theta]\)</span>
represents the model for an observation <span
class="math inline">\(X\)</span> given the parameter, the Bayesian
posterior predictive distribution for the data is <span
class="math display">\[
{\mathbb P}^\star[X|Data] = \int {\mathbb P}[X|\theta] \cdot d{\mathbb
P}[\theta|Data]
\]</span></p>
<p>The evaluation of the integral might present a computational
challenge. By now, you might guess that we will address that challenge
through sampling. Specifically, we can draw samples from the posterior
predictive using the following algorithm:</p>
<div id="section-posterior-predictive-distribution-sampling"
class="section level4">
<h4>Posterior Predictive Distribution Sampling</h4>
<ul>
<li><p>Draw <span class="math inline">\(\theta\)</span> from the
posterior distribtuion (say using MCMC)</p></li>
<li><p>Given <span class="math inline">\(\theta\)</span>, draw a
realization from <span class="math inline">\(X|\theta\)</span> from the
distribution <span class="math inline">\({\mathbb
P}[X|\theta]\)</span>.</p></li>
</ul>
</div>
</div>
<div id="section-example-continued-2" class="section level3">
<h3>Example (continued)</h3>
<p>Let us generate samples from the posterior distribution for the total
outbreak attack sizes.</p>
<pre class="r"><code># transform logit to probability for the negative binomial
# 1-q=s/(s+Npi), pi=exp(p)/1+exp(p)

p1 &lt;- exp(logit.pi)/(1+exp(logit.pi))

#. first 499 values are burn in
n.county &lt;- length( pop.maryland )
nburn &lt;- 500

X &lt;- matrix(0, length(p1)-nburn, n.county )
for ( k in 1:(length(p1)-nburn) ){
  r &lt;- ssize/(ssize + pop.maryland*p1[k+nburn])
  X[k,] &lt;- rnbinom( n.county, ssize, r)
}

par(mfrow=c(2,3))
for ( k in 1:n.county){
  hist(X[,k],nclass=100,
       xlab=&quot;total infection&quot;,
       sub=names(pop.maryland)[k],
       main=&quot;predictive distribtuion&quot;)
  abline(v=tot.infected[k], lwd=3, col=2 )
}
par(mfrow=c(1,1))</code></pre>
<p><img src="lecture_files/figure-html/mcmc-predictive-1.png" width="624" /></p>
<p>Is the data in agreement with the model?</p>
<p>Discussion?</p>
</div>
<div id="section-exercises" class="section level3">
<h3>Exercises</h3>
<ul>
<li>Using the previous example, use the previous code to compare mcmc
samples obtained using <code>sdd=0.01</code> and <code>sdd=5</code>. The
results are to be compared and contrasted with our previous results that
used <code>sdd=0.1</code>. You can load the file ‘runMCMC_1.R’ to save
time.</li>
</ul>
<div id="section-question-1" class="section level4">
<h4>Question</h4>
<p>Which chain would you prefer?</p>
<p>Why?</p>
<p>Can you tell if the chain converged?</p>
<ul>
<li>Adapt the previous code to sample from a posterior of both <span
class="math inline">\(pi\)</span> and <span
class="math inline">\(k\)</span>, the shape parameter. Computer the
Bayesian predictive distribution.</li>
</ul>
</div>
<div id="section-questions-1" class="section level4">
<h4>Questions</h4>
<ul>
<li><p>Compare and contrast with the distribution we calculated for a
fixed size.</p></li>
<li><p>This visualization works because we have a small number of
observations. Propose alternative visualization approaches for larger
datasets</p></li>
</ul>
</div>
</div>
<div id="section-example-1-revisited" class="section level3">
<h3>Example 1 revisited</h3>
<p>Consider again the problem of drawing from the posterior discussed in
Example 1: We know that in a population of 53 individuals, <span
class="math inline">\(m=3\)</span> are infected and <span
class="math inline">\(N=50\)</span> are susceptible. We observe <span
class="math inline">\(Z=8\)</span> new infections. What is the
probability of infection, assuming each infected individual can infect
independently each susceptible individual.</p>
<p>Our solution in Example 1 was to use importance sampling. Here we
show how to use the Metropolis algorithm to draw a sample.</p>
<div id="section-posterior-2" class="section level4">
<h4>Posterior</h4>
<p>Recall that the posterior was proportional to <span
class="math display">\[
{\mathbb P}(p|Z)  \propto  p^{z+a-1}(1-p)^{3(N-z)+b-1} \times \left ( 3
- 3p + p^2 \right )^z.
\]</span></p>
<p>Here below is an implementation of the metropolis algorithm. It is
useful to sample the logit transform of the probability <span
class="math display">\[
\theta = \log \left ( \frac{p}{1-p} \right )
\]</span> The transformed probability <span
class="math inline">\(\theta\)</span> lies in <span
class="math inline">\({\mathbb R}\)</span>. Proposal will be generated
using a <em>random walk</em> in <span
class="math inline">\(\theta\)</span>, that is <span
class="math display">\[
\theta^\prime = \theta^{(k)} + \sigma \xi
\]</span> where <span class="math inline">\(\xi\)</span> is a standard
Gaussian random variable, and <span
class="math inline">\(\sigma\)</span> the step size.</p>
<div class="tutorial-exercise" data-label="metropolis-example-1"
data-completion="1" data-diagnostics="1" data-startover="1"
data-lines="0" data-pipe="|&gt;">
<pre class="text"><code># data
N &lt;- 50
Z &lt;- 8
m &lt;- 3

# parameter of prior
a &lt;- 2
b &lt;- 3

# number of samples
n.smp &lt;- 10000
sigma &lt;- 0.1 # standard deviation (step size)
logitP &lt;- rep( 0, n.smp ) # value of the parameter
LL &lt;- rep(0, n.smp ) # loglikelihood

pp &lt;- exp( logitP[1] )/(1+exp(logitP[1]))
LL[1] &lt;- (Z+a-1)*log(pp) + (m*(N-Z) + b - 1)*log(1-pp) + Z*log(m-m*pp+pp*pp)

for ( k in 2:n.smp ){
  theta.new &lt;- logitP[k-1] + sigma*rnorm(1) # proposal
  pp.new &lt;- exp( theta.new )/( 1+exp( theta.new ) ) # proposed probability
  # loglikelihood of proposal
  LL.new &lt;- (Z+a-1)*log(pp.new) + (m*(N-Z) + b - 1)*log(1-pp.new) + Z*log(m-m*pp.new+pp.new*pp.new)
  R &lt;- exp( min(LL.new - LL[k-1],0) ) # ratio
  U &lt;- runif(1) # random uniform
  # move
  if ( U &lt; R ){
    # go to proposal
    logitP[k] &lt;- theta.new
    LL[k] &lt;- LL.new
  } else {
    # stay where you are
    logitP[k] &lt;- logitP[k-1]
    LL[k] &lt;- LL[k-1]
  }
}

# plot Markov chain
plot(logitP, xlab=&quot;iteration&quot;, ylab=&quot;logit&quot;,
     pch=20, cex=0.2)

# histogram of sample
burn.in &lt;- 1000
P &lt;- exp(logitP[burn.in:n.smp])/(1+exp(logitP[burn.in:n.smp]))
hist(P,nclass=100, xlab=&quot;infection probability&quot;, ylab=&quot;frequency&quot;,xlim=c(0,0.3))</code></pre>
<script type="application/json" data-ui-opts="1">{"engine":"r","has_checker":false,"caption":"<span data-i18n=\"text.enginecap\" data-i18n-opts=\"{&quot;engine&quot;:&quot;R&quot;}\">R Code<\/span>"}</script>
</div>
</div>
</div>
<div id="section-guided-execise" class="section level3">
<h3>Guided Execise</h3>
<p>Let us revisit the CCHV example, this time with the full dataset that
contains pooling of up to 5 ticks. Our previous work shows that the
logarithm of the likelihood is <span class="math display">\[
L(p) = \sum_{i=1}^n Z_i \log(1-(1-p)^{m_i}) + m_i(1-Z_i)\log(1-p).
\]</span> For simplicity, let us use a Beta<span
class="math inline">\((a,b)\)</span> prior. That prior is not a
conjugate prior, but that is ok. The full data is in the file
<code>ticks.RDS</code>.</p>
<p>Use the above example and your prior work to construct a Metropolis
sampler for the prevalence of CCHV infected ticks.</p>
<p>If you need help, you can upload the R script
<code>tickAnalysisMCMC.r</code>.</p>
</div>
<div id="section-metropolis-for-bivariate-multivariate-distributions"
class="section level3">
<h3>Metropolis for bivariate (multivariate) distributions</h3>
<p>Nothing in the Metropolis-Hastings algorithm restricts it being used
for univariate random variable. In fact, a strength of the algorithm is
that it works with little to no modification for multivariate
problems.</p>
<p>Consider the problem in Example 2. We have seen that the likelihood
of the data is <span class="math display">\[\begin{eqnarray*}
L(p,q) &amp;\propto&amp; \prod_{i: z_i=0} \left ( (1-q) +
q(1-p)^{N_i-1}\right ) \times \prod_{i : z_i &gt; 0} q
p^{z_i}(1-p)^{N_i-z_i-1}
\end{eqnarray*}\]</span></p>
<p>Using the previous examples, modify the code to build a Metropolis
sampler for that likelihood. The trick is to suggest updates for both
variables.</p>
<p>If you are stuck, look at the file <code>mcmc_Example2.R</code>.</p>
</div>
<div id="section-posterior-3" class="section level3">
<h3>Posterior</h3>
<div id="section-questions-2" class="section level4">
<h4>Questions</h4>
<ul>
<li><p>Which method is easier to implement?</p></li>
<li><p>Discuss positives and negatives of both methods</p></li>
</ul>
<p><img src="lecture_files/figure-html/show-results-1.png" width="624" /><img src="lecture_files/figure-html/show-results-2.png" width="624" /><img src="lecture_files/figure-html/show-results-3.png" width="624" /></p>
</div>
</div>
<div id="section-the-art-of-bayesian-analysis" class="section level3">
<h3>The art of Bayesian analysis</h3>
<p>Tuning the MCMC algorithm so that it produces reasonable answers is
an art. Many modern methods attempt to be “smart” about how to select
the proposal values.</p>
<p>As a rule of thumb, the acceptance fraction should range between 0.45
(for one variable) to 0.22 for five of more parameters.</p>
<p>Learning locally the likelihood can also improve proposals.</p>
<p>The Metropolis-Hastings works well when the posterior is unimodel.
But when that distribution has several modes (bumps), then the sampler
can have difficulties to transition from to the other.</p>
</div>
<div id="section-conclusions" class="section level3">
<h3>Conclusions</h3>
<p>The realization that it is possible to sample from the posterior
distribution without explicit knowledge of the normalizing constant was
essential to the rapid expansion and adoption of Bayesian inference over
the past 25 years.</p>
<p>The Metropolis-Hastings algorithm is a general all-purpose algorithm
that “trades” mathematical derivations for computations</p>
<p>While the algorithm is easy to implement, care is needed for</p>
<ul>
<li><p>ensure convergence and get good performance</p></li>
<li><p>will always give a result, please be critical about the
results</p></li>
</ul>
</div>
</div>
<div id="section-part-2-bayesian-analysis-of-epidemic-incidence-data"
class="section level2">
<h2>Part 2: Bayesian Analysis of Epidemic Incidence Data</h2>
<ol style="list-style-type: decimal">
<li><p>Review of basic epidemic contagion models</p>
<ol style="list-style-type: decimal">
<li><p>SIR and SEIR models</p></li>
<li><p>Stochastic Epidemic models</p></li>
</ol></li>
<li><p>Bayesian estimation of incidence data</p>
<ol style="list-style-type: decimal">
<li><p>Data augmentation and MCMC parameter estimation</p></li>
<li><p>Model Validation</p></li>
</ol></li>
</ol>
</div>
<div id="section-basic-epidemic-contagion-model" class="section level2">
<h2>Basic Epidemic Contagion model</h2>
<div id="section-suscepticle-infected-removed-model"
class="section level3">
<h3>Suscepticle-Infected-Removed model</h3>
<p>The simplest epidemic model summarizes the health status at time
<span class="math inline">\(t\)</span> of each individual in a
population of size <span class="math inline">\(N(t)\)</span> by counting
the number of Susceptible <span class="math inline">\(S(t)\)</span>,
Infected <span class="math inline">\(I(t)\)</span> and recovered <span
class="math inline">\(R(t)\)</span> individuals, where by construction
<span class="math display">\[
S(t) + I(t) + R(t) = N(t).
\]</span></p>
<p>How these quantities change over time is part of the model
specification. A popular model, dating back to the 1920s, describes
their evolution<br />
through a set of coupled differential equations <span
class="math display">\[\begin{eqnarray}
S^\prime(t) &amp;=&amp; - \frac{\beta}{N(t)} S(t) I(t)\\
I^\prime(t) &amp;=&amp; \frac{\beta}{N(t)} S(t) I(t) - \gamma I(t)\\
R^\prime(t) &amp;=&amp; \gamma I(t),
\end{eqnarray}\]</span> with initial conditions <span
class="math inline">\(S(0)=N(0)-I(0)\)</span> and <span
class="math inline">\(I(0)=i_0\)</span>.</p>
</div>
<div id="section-interpretation" class="section level3">
<h3>Interpretation</h3>
<ul>
<li><p><span class="math inline">\(\beta\)</span> the per contact
infection rate</p></li>
<li><p><span class="math inline">\(I(t)/N(t)\)</span> the fraction of
contacts that are infectious</p></li>
<li><p><span class="math inline">\(\gamma\)</span> is the per individual
recovery rate</p></li>
<li><p><em>Basic reproductive number</em> <span
class="math inline">\(R_0\)</span>, the expected number of secondary
cases from the index case in a fully naive population. In an SIR, one
has that <span class="math inline">\(R_0 =
\beta/\gamma\)</span>.</p></li>
</ul>
</div>
<div id="section-numerical-example-3" class="section level3">
<h3>Numerical example</h3>
<p>Here is some R code that solves the system of differential equations
describing the SIR dynamics. Try changing the parameters <span
class="math inline">\(\beta\)</span>, <span
class="math inline">\(\gamma\)</span> to generate different
dynamics.</p>
<div class="tutorial-exercise" data-label="SIR" data-completion="1"
data-diagnostics="1" data-startover="1" data-lines="0"
data-pipe="|&gt;">
<pre class="text"><code>#. set-up variables

parameters.sir &lt;- c( beta=0.3, gamma=0.1, N=1001 )
state &lt;- c( S=1000, I=1, R=0 )

#. define SIR differential equation
SIR &lt;- function( t, state, parameters ){
  
  with( as.list( c(state, parameters )), {
    
    # differential equations
    dS &lt;- -beta * S * I/N
    dI &lt;- beta * S * I/N - gamma * I
    dR &lt;- gamma * I
    
    # return result
    list( c(dS=dS, dI=dI, dR=dR ) )
  })
  
}

#. numerically solve the system of differential equations

dtime &lt;- 0.01
times &lt;- seq(0, 100, by = dtime )

sir &lt;- ode( y = state, times = times, func = SIR, parms = parameters.sir )

plot( times, sir[,&quot;I&quot;], type=&quot;l&quot;, xlab=&quot;time&quot;, ylab=&quot;infections&quot;)</code></pre>
<script type="application/json" data-ui-opts="1">{"engine":"r","has_checker":false,"caption":"<span data-i18n=\"text.enginecap\" data-i18n-opts=\"{&quot;engine&quot;:&quot;R&quot;}\">R Code<\/span>"}</script>
</div>
</div>
<div id="section-more-general-sir-models" class="section level3">
<h3>More general SIR models</h3>
<p>While the Susceptible-Infected-Recovered (SIR) model is conceptually
easy to explain, it is often considered overly simple because it fails
to account for important epidemiological features, such as</p>
<ul>
<li><p>incubation period of the disease</p></li>
<li><p>presence of asymptomatic (or sub-clinical) infections</p></li>
<li><p>multiple evolution of the disease (e.g., some individuals recover
while other die)</p></li>
<li><p>impact of treatment and vaccination</p></li>
<li><p>impact of non-pharmeceutical interventions</p></li>
</ul>
<p>To model these important features, mathematicians have developed
disease dynamic models that explicitly account these features by adding
<em>states</em> (boxes) to the basic SIR model. For example, the model
from Castana et al. displays such an epidemic model that adds
asymptomatic, exposed, hospitalized and deaths categories to the basic
SIR model.</p>
<!---    
Reference:  
Antonio Rafael Selva Castañeda, Erick Eduardo Ramirez-Torres, Luis Eugenio Valdés-García, Hilda María Morandeira-Padrón, Diana Sedal Yanez, Juan I. Montijano, Luis Enrique Bergues Cabrales,
Modified SEIR epidemic model including asymptomatic and hospitalized cases with correct demographic evolution,
Applied Mathematics and Computation,
Volume 456,
2023,

--->
<p><img src="SEIHR.jpg" /><!-- --></p>
</div>
<div id="section-data-streams" class="section level3">
<h3>Data streams</h3>
<p>The SIR model provides a description for the temporal evolution of
the state vector <span class="math inline">\((S(t),I(t),R(t))\)</span>.
In the real world, we often only to record the number of new cases, or
<em>incidence</em>, accumulated within a day or week. The resulting time
series of counts <span
class="math inline">\(Y_1,Y_2,Y_3,\ldots,Y_T\)</span> is the most common
type of epidemiological data considered when modeling disease
dynamics.</p>
<p>There are additional data sources that are sometimes available:</p>
<ul>
<li><p>Additional public health related data streams. This may include
time series of hospitalizations and death. We will need to expand our
basic SIR epidemic model to take advantage of these types of
data.</p></li>
<li><p>Serology data: This data records if individuals have (or not) a
specific antibody indicating prior infection. This data provides
information about who has been infected by the pathogen, but without the
time of infection. This can be useful to inform <em>disease
prevalence</em> but it is challenging to use this data to model disease
dynamics.</p></li>
<li><p>Environmental samples: Instead of sampling humans, we may sample
the environment to detect the presence of pathogen. In some cases, we
can measure time series of how much virus is present. For example, we
can measure daily viral load in waste water or on air-filters. But
relating this kind of data to SIR-type models for the number of infected
individuals requires careful modeling of how environmental viral load is
related to dynamics of infected individuals.</p></li>
</ul>
<p>A question that we will partially address in these lectures, is how
to combine data from multiple sources.</p>
</div>
<div id="section-goal-estimate-model-parameters-from-incidence-data"
class="section level3">
<h3>Goal: estimate model parameters from incidence data</h3>
<p>In this course, we will develop and illustrate the computational
tools required to estimate the model parameters of disease dynamic
models from incidence time series data <span
class="math inline">\(Y_1,Y_2,\ldots,Y_T\)</span>.</p>
<p>Epidemiologists and public health officials are particularly
interested in:</p>
<ul>
<li><p>The basic reproductive number as it characterizes the magnitude
of the outbreak</p></li>
<li><p>The time dependent reproductive number — defined as the expected
number of secondary cases attributable to an individual who gets
infected at time <span class="math inline">\(t\)</span>. That quantity
is useful to evaluate the effectiveness of interventions and mitigation
strategies.</p></li>
<li><p>Fitted epidemic models with which they can forecast the future
dynamic of the epidemic</p></li>
</ul>
<p>In all these applications, we do need to provide
<em>uncertainties</em> for the estimated quantities and forecasts.</p>
</div>
</div>
<div id="section-bayesian-analysis-of-disease-incidence-data"
class="section level2">
<h2>Bayesian analysis of disease incidence data</h2>
<div id="section-a-first-model" class="section level3">
<h3>A first model</h3>
<p>A Bayesian analysis of incidence data requires us to specify a
likelihood. One could imagine using the SIR model to describe the
average (expectation) of incidences. For example, we can model the
number of new cases in a time interval <span
class="math inline">\((t,t+Delta)\)</span> by specifying the mean number
of cases</p>
<p><span class="math display">\[
\mu = \int_{t}^{t+\Delta} -S^\prime(v;\beta,\gamma) dv
\]</span></p>
<p>and assume that <span class="math inline">\(X|\mu\)</span> has a
negative binomial distribution with shape parameter <span
class="math inline">\(s\)</span> and expectation <span
class="math inline">\(\mu\)</span>. For that model, the data has
distribution <span class="math display">\[
{\mathbb P}[X=x|\mu,s] = {x+s-1 \choose s-1}
\left ( \frac{\mu}{s+\mu} \right )^x \left ( \frac{s}{s+\mu} \right )^s.
\]</span></p>
<div id="section-comment" class="section level4">
<h4>Comment:</h4>
<p>This model assumes that all the errors arise from measurement
uncertainties. This model does not capture the impact of randomness in
the infection and recovery processes.</p>
</div>
</div>
<div id="section-an-stochastic-discrete-time-sir-model"
class="section level3">
<h3>An stochastic discrete time SIR model</h3>
<p>A simple stochastic analogue of the deterministic SIR model is the
discrete time Markov chain for the state variables <span
class="math inline">\((S_k,I_k,R_k)\)</span>, observed at times <span
class="math inline">\(0,\Delta,2\Delta,\ldots\)</span> i.e., <span
class="math inline">\(t_k=k\cdot \Delta\)</span>, defined by the dynamic
<span class="math display">\[\begin{eqnarray}
S_{k+1} &amp;=&amp; S_k - Z_{k+1} \\
I_{k+1} &amp;=&amp; I_k + Z_{k+1} - V_{k+1} \\
R_{k+1} &amp;=&amp; R_k + V_{k+1},
\end{eqnarray}\]</span> where <span
class="math inline">\((Z_{k+1},V_{k+1})\)</span> are conditionally
independent given the state of the system <span
class="math inline">\((S_k,I_k,R_k)\)</span> with conditional
distributions <span class="math display">\[\begin{eqnarray}
&amp;&amp; Z_{k+1} | (S_k,I_k,R_k) \sim Binom(S_k,1-(1-\pi)^{I_k})\\
&amp;&amp; V_{k+1} | (S_k,I_k,R_k) \sim Binom(I_k,q).
\end{eqnarray}\]</span></p>
</div>
<div id="section-parameters-and-interpretation" class="section level3">
<h3>Parameters and interpretation</h3>
<ul>
<li><p><span class="math inline">\(\pi\)</span> is the probability that
a contact between a susceptible and infected individual results in an
infection</p></li>
<li><p><span class="math inline">\(1-p_k=(1-\pi)^{I_k}\)</span> is the
probability that a susceptible individual escapes infection given that
there are <span class="math inline">\(I_k\)</span> infected individuals
in the population. This assumes that the population is <em>homogeneously
mixing</em>, that is, everyone is equally likely to be in contact with
one another.</p></li>
<li><p><span class="math inline">\(q\)</span> is the probability that an
infected individual recovers in a given time period</p></li>
<li><p>The time to recovery is a Geometric distribution with parameter
<span class="math inline">\(q\)</span></p></li>
</ul>
</div>
<div id="section-example-of-realizations" class="section level3">
<h3>Example of realizations</h3>
<p>Here below is R code that simulates realizations for the described
stochastic epidemic model. Change the model parameters <span
class="math inline">\(\pi\)</span> and <span
class="math inline">\(q\)</span> to get different outbreak dynamics.</p>
<div class="tutorial-exercise" data-label="sSIR" data-completion="1"
data-diagnostics="1" data-startover="1" data-lines="0"
data-pipe="|&gt;">
<pre class="text"><code>#. set-up variables
parameters.ssir &lt;- data.frame( pi = 0.0003, q = 0.15 )

Evolution &lt;- function(state, parameters ){
    pk &lt;- as.numeric( 1 - exp( state$I * log(1-parameters$pi ) ) )
    Z &lt;- rbinom( 1, state$S, pk )
    V &lt;- rbinom( 1, state$I, parameters$q )
    
    # return result
    return( list( Z=Z, V=V ) )
}


#. simulate evolution

ntime &lt;- 130
plot( c(0,ntime), c(0,225), type=&quot;n&quot;, 
      xlab =&quot;time&quot;, ylab=&quot;number infected&quot;)

#  simulate 20 realizations of process 
ff &lt;- 0
for ( kk in 1:20 ){
  ssir &lt;- data.frame( S = rep( 0, ntime+1 ),
                      I = rep( 0, ntime+1 ),
                      R = rep( 0, ntime+1 ) )

  ssir[1,] &lt;- c(1000,1,0)

  for ( k in 1:ntime ){
    D &lt;- Evolution( ssir[k,], parameters.ssir )
    ssir[k+1,]$S &lt;- ssir[k,]$S - D$Z
    ssir[k+1,]$I &lt;- ssir[k,]$I + D$Z - D$V
    ssir[k+1,]$R &lt;- ssir[k,]$R + D$V
  }

  if ( ssir[40,]$I &gt; 0 ){
    ff &lt;- ff + 1
    points(1:ntime, ssir$I[1:ntime], pch=20, cex=0.5)
    lines(1:ntime, ssir$I[1:ntime], pch=20)
  }
}

text( 100, 160,
      paste( &quot;fraction = &quot;,round(ff/20,3)))

## equivalent deterministic SIR model
parameters.sir &lt;- c( beta =  -sum(ssir[1,])*log(1-parameters.ssir$pi),
                     gamma = -log(1-parameters.ssir$q),
                     N = sum(ssir[1,]) )
state &lt;- unlist( ssir[1,] )

#. calculate equivalent deterministic SIR
#. define SIR differential equation
SIR &lt;- function( t, state, parameters ){
  
  with( as.list( c(state, parameters )), {
    
    # differential equations
    dS &lt;- -beta * S * I/N
    dI &lt;- beta * S * I/N - gamma * I
    dR &lt;- gamma * I
    
    # return result
    list( c(dS=dS, dI=dI, dR=dR ) )
  })
}

dtime &lt;- 0.01
times &lt;- seq(0, ntime, by = dtime )

sir &lt;- ode( y = state, times = times, func = SIR, parms = parameters.sir )
lines(times, sir[,&quot;I&quot;],lwd=4,col=&quot;red&quot;)</code></pre>
<script type="application/json" data-ui-opts="1">{"engine":"r","has_checker":false,"caption":"<span data-i18n=\"text.enginecap\" data-i18n-opts=\"{&quot;engine&quot;:&quot;R&quot;}\">R Code<\/span>"}</script>
</div>
</div>
<div id="section-features-of-stochastic-realizations"
class="section level3">
<h3>Features of stochastic realizations:</h3>
<ul>
<li><p>Not every epidemic takes off, with a fraction of outbreaks dying
out early. Possible observational bias if we consider studying only
“successful” outbreaks</p></li>
<li><p>Shapes of outbreak are similar, but the time of <em>onset</em>
varies.</p></li>
<li><p>limited number of observations, even as the time horizon
increases</p></li>
<li><p>Additive error models not well suited to relate stochastic model
with time step <span class="math inline">\(\Delta\)</span> and the
related deterministic SIR model with parameters</p>
<ul>
<li><p>Recovery rate: <span class="math inline">\(\gamma =
-\log(1-q)/\Delta\)</span></p></li>
<li><p>Infection rate: <span class="math inline">\(\beta = N
\log(1-\pi)/\Delta\)</span></p></li>
</ul></li>
<li><p><span class="math inline">\(I_k=0\)</span> is an absorbing state.
That is, if <span class="math inline">\(I_k=0\)</span>, then <span
class="math inline">\(I_{k^\prime}=0\)</span> for all <span
class="math inline">\(k^{\prime} \geq k\)</span>.</p></li>
</ul>
</div>
<div id="section-likelihood-of-the-full-data" class="section level3">
<h3>Likelihood of the full data</h3>
<p>As a first step, consider the (unrealistic) case where we observe the
full state vector <span class="math inline">\(X_k=(S_k,I_k,R_k)\)</span>
of the Markov chain.</p>
<p>Using the Markov property, we get that the likelihood is <span
class="math display">\[\begin{eqnarray}
P(X_1,\ldots,X_n|\theta) &amp;=&amp; P(X_1|\theta) P(X_2|X_1, \theta)
\dots P(X_n|X_1,\ldots,X_{n-1},\theta)\\
&amp;=&amp; \prod_{k=2}^n P(X_k|X_{k-1},\theta) P(X_1|\theta).
\end{eqnarray}\]</span></p>
<p>Note that the conditional distribution of <span
class="math inline">\(X_{k+1}|X_k\)</span> can be calculated from the
conditional distribution of the pair of new infections and recoveries
<span class="math inline">\((Z_{k+1},V_{k+1})\)</span> given the state
of the epidemic <span
class="math inline">\(X_k=(S_k,I_k,R_k)\)</span>.</p>
<p>Notice that we resolved the issue of how to initialize the process by
conditioning on <span class="math inline">\(X_1\)</span>.</p>
</div>
<div id="section-likelihood-of-the-incidence-data"
class="section level3">
<h3>Likelihood of the incidence data</h3>
<p>We often just get to observe the incidence, the number of new
infections. In our stochastic model, this corresponds to the time series
<span class="math inline">\(Z_1,Z_2,\ldots\)</span>.</p>
<p>The Bayesian paradigm applies to that data. It requires that we
derive its distribution. This is challenging because that time series is
no longer Markovian. This means that the joint distribution of <span
class="math inline">\(P[Z_1,\ldots,Z_n|\pi,q]\)</span> does not have a
nice analytically closed form.</p>
<div id="section-data-augmentation" class="section level4">
<h4>Data Augmentation</h4>
<p>The Bayesian framework makes it easy to describe the full data
generative process. When observations are missing, we can behave as they
are an additional unknown.<br />
This is like in Example 2, where we introduced the ideas of data
augmentation. In the current case, if we knew the time series of
recovered individuals <span
class="math inline">\(V_1,V_2,\ldots\)</span>, we could readily
calculate the likelihood and estimate the model parameters.</p>
<p>Thus our data augmentation approach is to write the likelihood in
terms of the full data <span
class="math inline">\((S_k,I_k,R_k)\)</span>, <span
class="math inline">\(k=1,\ldots,n\)</span>, or equivalently in terms of
<span class="math inline">\((Z_k,V_k)\)</span>, <span
class="math inline">\(k=1,\ldots\)</span>, and then compute the
conditional distribution of <span class="math display">\[
(\pi,q,V_1,\ldots,V_n) | Z_1,\ldots,Z_n
\]</span></p>
<p>Our discussion of the Gibbs sampler says that we can do that by
sampling <span class="math display">\[
V^{(k+1)}_j|(\pi^{(k)},q^{(k)}),V^{(k+1)}_1,\ldots,V_{j-1}^{(k+1)},
V_{j+1}^{(k)},\ldots,V_n^{(k)},Z_1,\ldots,Z_n
\]</span> and <span class="math display">\[
(\pi^{(k+1)},q^{(k+1)}) | V_1^{(k+1)},\ldots,V_n^{(k+1)},Z_1,\ldots,Z_n.
\]</span> To sample from the latter distribution, we can use the
Metropolis algorithm.</p>
</div>
</div>
<div id="section-the-general-metropolis-hastings-algorithm"
class="section level3">
<h3>The General Metropolis-Hastings Algorithm</h3>
<div id="section-goal." class="section level4">
<h4>Goal.</h4>
<p>The goal is to generate a Markov chain whose stationary distribution
is proportional to a given function <span
class="math inline">\(f\)</span>. Given the current state <span
class="math inline">\(X_n=x\)</span> of the Markov chain, do the
following steps to determine the next term in the chain:</p>
</div>
<div id="section-propose-a-move." class="section level4">
<h4>1. Propose a move.</h4>
<p>Draw a possible candidate value for the Markov chain <span
class="math display">\[
X^\star \sim h(\cdot|x)
\]</span> Conditional distribution <span
class="math inline">\(h(\cdot|x)\)</span> is known.</p>
</div>
<div id="section-calculate-the-adjusted-acceptance-probability"
class="section level4">
<h4>2. Calculate the (adjusted) acceptance probability</h4>
<p><span class="math display">\[
R = \min \left ( 1, \frac{f(X^\star)}{f(X_n)} \times
\frac{h(X_n|X^\star)}{h(X^\star|X_n)} \right )
\]</span></p>
</div>
<div id="section-update-chain" class="section level4">
<h4>3. Update chain</h4>
<p>Draw <span class="math inline">\(U\)</span> from a Uniform <span
class="math inline">\((0,1)\)</span> and set <span
class="math display">\[
X_{n+1} = X^\star \mbox{ if } U \leq R
\]</span> and <span class="math display">\[
X_{n+1} = X_n \mbox{ if } U &gt; R.
\]</span></p>
</div>
</div>
<div id="section-selecting-the-proposal-distribution"
class="section level3">
<h3>Selecting the proposal distribution</h3>
<ol style="list-style-type: decimal">
<li><p>The Metropolis-Hasting algorithm constructs a Markov chain whose
stationary distribution is proportional to <span
class="math inline">\(f(x)\)</span>. Starting at a given value <span
class="math inline">\(X_0\)</span>, we may ask how fast that chain
converges to its stationary distribution, and how this depends on the
distribution of candidates.</p>
<ol style="list-style-type: decimal">
<li><p>If the candidate is picked at random over the whole sample space,
it is likely that the acceptance ratio is small. Small acceptance ratios
imply that the chain stays put most of the time, and thus convergence to
stationarity can be slow.</p></li>
<li><p>If the candidate is picked to be very close to the current state,
then the acceptance ratio will likely be close to one. Thus while the
chain will move, the moves will be very small. As a result, the chain
will take a long time to explore the outcome space. Intuitively, this
leads to slow convergence of the chain.</p></li>
<li><p>Theoretical and practical considerations suggest that we should
aim to have an acceptance ratio be between 10% and 40%.</p></li>
</ol></li>
</ol>
</div>
<div id="section-reversable-proposal-distribtution"
class="section level3">
<h3>Reversable proposal distribtution</h3>
<ol style="list-style-type: decimal">
<li><p>The <em>adjustment</em> term <span class="math display">\[
\frac{h(X_n|X^\star)}{h(X^\star|X_n)}
\]</span> in the Metropolis-Hastings algorithm ensures that the Markov
chain satisfies the detailed balance equation <span
class="math display">\[
f(x_{n+1}) {\mathbb P}[X_n=x_n|X_{n+1}=x_{n+1}] = f(x_n) {\mathbb
P}[X_{n+1}=x_{n+1}|X_{n}=x_{n}].
\]</span> This implies that the chain is <em>time reversible</em> and
the distribution <span class="math display">\[
g(x) = \frac{f(x)}{\int f(u) du}
\]</span> is invariant and hence the stationary distribution</p></li>
<li><p>For the random walk sampler, we choose <span
class="math inline">\(h(x^\star|x_n) = h(x^\star-x_n)\)</span>, where
<span class="math inline">\(h\)</span> is a symmetric density <span
class="math inline">\(h(-u)=h(u)\)</span>. With this choice, the
adjustment term is always one. This simplifies the
implementation.</p></li>
</ol>
</div>
<div id="section-example-and-exercise" class="section level3">
<h3>Example and exercise</h3>
<p>The Metropolis sampler is very flexible about how proposals are
generated. If we believe our prior, why not use that distribution to
generate proposals?</p>
<p>You need to use the general Metropolis-Hastings to construct such a
chain. Modify suitably the Metropolis sampler code for Example 1.</p>
<p>If you are stuck, look at the file <code>mcmc_Example1.R</code>.</p>
<div id="section-discussion-1" class="section level4">
<h4>Discussion</h4>
<ul>
<li><p>Is this a better way to sample the posterior?</p></li>
<li><p>Why would you want, or not, use this sampler?</p></li>
</ul>
</div>
</div>
<div id="section-answer-1" class="section level3">
<h3>Answer</h3>
<p><img src="lecture_files/figure-html/mcmc-example1-v2-1.png" width="624" /><img src="lecture_files/figure-html/mcmc-example1-v2-2.png" width="624" /><img src="lecture_files/figure-html/mcmc-example1-v2-3.png" width="624" /></p>
</div>
<div id="section-implementation" class="section level3">
<h3>Implementation</h3>
<p>Let us work on implementing a Bayesian analysis for our influenza
data. We simplify the implementation by assuming uniform priors. In
practice, one would want to use a prior that better reflects our prior
knowledge.</p>
<p>Again, we will run our sampler on logit transformed parameters. This
allows us to use a random walk to propose new parameter values without
worrying getting outside the range the parameter is defined.</p>
<p>Here, we will demonstrate the method assuming that we know the
recovery rate to be <span class="math inline">\(q=0.14\)</span>. The
latter value was selected to to give an expected number of days to
recovery of 6.1 .</p>
<p>Our analysis will focus on analyzing data from the first 21 weeks.
The code is readily changed to study longer times.</p>
<pre class="r"><code># 
n.days &lt;- 22        # consider only the first three weeks of data
SS &lt;- rep(0,n.days) # susceptible
II &lt;- rep(0,n.days) # infected

# S depends only on population size and incidence, and is observed
Z &lt;-flu.data[1:n.days,2]
SS &lt;- pop.maryland[1] - cumsum(Z)
II[1] &lt;- Z[1]

# set-up variables
n.iter &lt;- 20000

# fix q=0.14
qq &lt;- 0.14
logit.pi &lt;- rep(0,n.iter)
VV &lt;- matrix(0,n.iter,n.days)
LL &lt;- rep(0,n.iter)

# initialize logit pi
logit.pi[1] &lt;- -5

# calculate loglikelihood to initialize the chain
for ( j in 2:n.days ){
  VV[1,j] &lt;- rbinom(1,II[j-1],qq)
  II[j] &lt;- II[j-1]-VV[1,j]+Z[j]
}

ppi &lt;- exp(logit.pi[1])/(1+exp(logit.pi[1]) )
pp  &lt;- 1 - exp( II[-n.days] * log( 1 - ppi ) )

# loglikelihood
ll &lt;- sum( Z[-1]*log(pp) + ( SS[-n.days]-Z[-1] )*log(1-pp) )
LL[1] &lt;- ll 

# step size
sdp &lt;- 0.001

# mcmc

for ( k in 2:n.iter ){
  
  # sample recovery (data augmentation step)
  for ( j in 2:n.days ){
    VV[k,j] &lt;- rbinom(1,II[j-1],qq)
    II[j] &lt;- II[j-1]-VV[k,j]+Z[j]
  }
  
  #. Metropolis proposal
  logit.pi.new &lt;- logit.pi[k-1] + rnorm(1,mean=0,sd=sdp)
  pi.new &lt;- exp( logit.pi.new )/( 1 + exp( logit.pi.new ) )
  
  # Calculate likelihood of full data
  pp.new &lt;- 1-exp( II[-n.days]*log(1-pi.new) )
  LL.new &lt;- sum( Z[-1]*log(pp.new) + (SS[-n.days]-Z[-1])*log(1-pp.new) )

  # make move
  R &lt;- exp( min(LL.new-LL[k-1],0) )
  U &lt;- runif(1)
  if ( U &lt; R ){
    # accepts
    logit.pi[k] &lt;- logit.pi.new
    LL[k] &lt;- LL.new
  } else {
    # reject 
    logit.pi[k] &lt;- logit.pi[k-1]
    LL[k] &lt;- LL[k-1]
  }
}

plot(logit.pi,pch=20,cex=0.2,
     xlab=&quot;itertaion&quot;,ylab=&quot;logit of infection&quot;,
     sub=&quot;Trace of parameter&quot;)</code></pre>
<p><img src="lecture_files/figure-html/mcmc-incidence-1.png" width="624" /></p>
<pre class="r"><code>plot(LL[1000:n.iter],pch=20,cex=0.2,
     xlab=&quot;index&quot;,ylab=&quot;loglikelihood&quot;,
     sub=&quot;Trace of loglikelihood&quot;)</code></pre>
<p><img src="lecture_files/figure-html/mcmc-incidence-2.png" width="624" /></p>
</div>
<div id="section-exercise-3" class="section level3">
<h3>Exercise</h3>
<p>Run the above MCMC code and investigate its convergence. (Copy paste
code into a R script file and modify it).</p>
<ul>
<li><p>Did the Markov chain converge?</p></li>
<li><p>Describe what is going on?</p></li>
<li><p>Would you change the Markov chain? How?</p></li>
</ul>
</div>
<div id="section-answer-2" class="section level3">
<h3>Answer</h3>
<p>Change the standard deviation controlling the step size to 0.05</p>
<p><img src="lecture_files/figure-html/mcmc-incidence-solution-1.png" width="624" /><img src="lecture_files/figure-html/mcmc-incidence-solution-2.png" width="624" /></p>
</div>
<div id="section-model-validation" class="section level3">
<h3>Model validation</h3>
<p>To investigate how well the model predicts the data, we use the
posterior predictive distribution of the data.</p>
<p>Here we have options:</p>
<ul>
<li><p>Simulate the entire path</p></li>
<li><p>Predict the number of infections one step ahead</p></li>
</ul>
<p>We will do the latter for simplicity. The former is useful as a test
of the overall model (which is unlikely to be very good)</p>
<pre class="r"><code># set burn in size (to be discarded)
burn.in &lt;- 1000

# initialize a matrix of predicted values
XX &lt;- matrix(0,n.iter-burn.in, n.days-1)
V  &lt;- rep(0,n.days)
II &lt;- rep(0,n.days)
II[1] &lt;- Z[1]

# for every logit.pi in the Markov chain, sample from the 
# conditional distribution of Z|p

for ( k in 1:(n.iter-burn.in) ){
  
  # calculate p
  pi &lt;- exp(logit.pi[k+burn.in])/(1+exp(logit.pi[k+burn.in]))
  
  for ( j in 2:n.days ){
    
      pp &lt;- 1-exp(II[j-1]*log(1-pi))
      
      # calculate recovered individuals (needed to get I[k]
      V[j] &lt;- rbinom(1,II[j-1],qq)
      
      # calculate new infections
      XX[k,j-1] &lt;- rbinom(1,SS[j-1],pp)
      
      # calculate number of infected 
      II[j] &lt;- II[j-1]-V[j]+Z[j]
      
      if ( II[j] == 0 ) break
  }
}

# show results as boxplots
# We use as.data.frames to tell R to make a boxplopt for each column
# This is a hack...
boxplot(as.data.frame(XX),xlab=&quot;&quot;)

points(1:21,Z[-1],pch=20,col=2)</code></pre>
<p><img src="lecture_files/figure-html/mcmc-incidence-predictive-1.png" width="624" /></p>
<p>Do you think this model fits well the data?</p>
<p>How would you modify the model to improve the fit?</p>
</div>
<div id="section-exercise-continued" class="section level3">
<h3>Exercise: Continued</h3>
<p>re-use the code to implement a MCMC to sample both the infection
probability and the recovery probability. This should be similar to the
example for sampling from two parameters we did for Example 1.</p>
<p>For extra credit, construct predictive confidence intervals. Explore
how do the results change as you use more data from the outbreak?</p>
</div>
<div id="section-results" class="section level3">
<h3>Results</h3>
<p><img src="lecture_files/figure-html/bivariate-mcmc-1.png" width="624" /><img src="lecture_files/figure-html/bivariate-mcmc-2.png" width="624" /><img src="lecture_files/figure-html/bivariate-mcmc-3.png" width="624" /><img src="lecture_files/figure-html/bivariate-mcmc-4.png" width="624" /></p>
</div>
<div id="section-modeling-the-observational-process"
class="section level3">
<h3>Modeling the observational process</h3>
<p>A strength of the Bayesian paradigm is that it forces us to think
about how the data was produced. Try to model that process using random
variables. This is a useful to help understand and interpret the model
and the data. This also points towards seeking various datasets to help
constrain different parts of the model. Some aspects (think random
variable) may not be directly observed. This is ok, and including such
variables in the model remains helpful — see previous example.</p>
<p>As an example, consider adding the mechanism of how we observe the
data to our model. For example, let us assume that each infected
individual is detected and recorded with probability <span
class="math inline">\(r\)</span> each day. In such a model, we have two
types of infected individuals: Those that we detected and those that we
have not. Lets denote by <span class="math inline">\(I^1\)</span> the
former and <span class="math inline">\(I^0\)</span> the latter.</p>
<p>The complete state variable for the epidemic will now be <span
class="math inline">\(X_k=(S_k,I^0_k,I^1_k,R_k)\)</span>. We extend our
stochastic epidemic model to incorporate this additional process as
follows: <span class="math display">\[\begin{eqnarray*}
S_{k+1} &amp;=&amp; S_k - Z_{k+1}\\
I^0_{k+1} &amp;=&amp; I^0_k + Z_{k+1} - W_{k+1} - V^0_{k+1}\\
I^1_{k+1} &amp;=&amp; I^1_k + W_{k+1} - V^1_{k+1}\\
R_{k+1} &amp;=&amp; R_{k} + V^0_{k+1} + V^1_{k+1}
\end{eqnarray*}\]</span> where <span
class="math display">\[\begin{eqnarray*}
Z_{k+1} | X_k &amp; \sim &amp; \mbox{Binomial}(S_k,
1-(1-p)^{I^0_k+I^1_k})\\
W_{k+1} | X_k &amp; \sim &amp; \mbox{Binomial}(I^0_k, r)\\
V^0_{k+1} | X_k &amp; \sim &amp; \mbox{Binomial}(I^0_k, q)\\
V^1_{k+1} | X_k &amp; \sim &amp; \mbox{Binomial}(I^1_k, q).
\end{eqnarray*}\]</span></p>
<p>We can ask if the observations (incidence data) can constrain both
parameters. What do you think?</p>
<div id="section-implementation-1" class="section level4">
<h4>Implementation</h4>
<p>Implementation of an MCMC for this problem is possible but beyond the
scope of this course. Before you start coding, ask yourself which are
the observed variables, and which will be the augmented variables.</p>
<p>Caution: In this problem, the probability of infection are the
probability of observing an infection are linearly related (with a
negative slope).</p>
</div>
</div>
<div id="section-a-cautionary-word-about-identifiability"
class="section level3">
<h3>A cautionary word about identifiability</h3>
<p>The above example shows while a Bayesian model can incorporate all
relevant processes, not all the parameter are constrained by data. By
including all the processes into the model, it can happen that not all
the parameters are well constrained. That is, we observe “extreme”
dependence between estimated parameters. When this happens, we say that
the parameters are no identifiable.</p>
<p>We are not saying that the model is wrong/bad. Rather, that the data
does not constrain the parameters. The same model could become
identifiable with additional information. For example, do you think we
could identify (constrain) the parameters if we could test everyone a
few times during the epidemic outbreak?</p>
</div>
<div id="section-discussion-2" class="section level3">
<h3>Discussion</h3>
<ul>
<li><p>It is useful to think of incidence data as missing data</p></li>
<li><p>The Bayesian paradigm provides an ideal framework to handle such
missing data, and estimate the parameters using Monte-Carlo
sampling</p></li>
<li><p>This is a numerical method. The computer will always give you an
answer. It is up to you to validate the inference</p>
<ul>
<li><p>Run diagnostics</p></li>
<li><p>Change parameter values to see how output changes (sensitivity
analysis)</p></li>
<li><p>Compare model prediction and data</p></li>
<li><p>Be aware of identifiability issues</p></li>
</ul></li>
</ul>
</div>
</div>
<div id="section-part-3-self-learn" class="section level2">
<h2>Part 3: Self learn</h2>
<div id="section-metropolis" class="section level3">
<h3>Metropolis</h3>
<p>The Metropolis-Hastings algorithm allows one to use any distribution
to propose the next value. In particular, you could use the prior
distribution to make proposals.</p>
<p>Modify the continuation of Example 1 (in the Metropolis example) to
draw from the prior Beta<span class="math inline">\((2,3)\)</span> to
propose new values.</p>
<p>Describe how this chain behaves. Is this a good idea?</p>
</div>
<div id="section-hierarchical-modeling" class="section level3">
<h3>Hierarchical modeling</h3>
<p>A strength of the Bayesian formulation is the possibility of
combining multiple datasets. Here, let us consider combining the
incidence data from the various Maryland counties.</p>
<p>While it is reasonable to assume that recovery from infection is
similar in all the counties, we may think that the infection rate could
vary, within reason, from one county to the next. Why?</p>
<p>If we assume that the infection probability are arbitrary (no
relationship between counties), then combining the data provides limited
additional insights (we can better learn their common probability of
recovery), but combining the data will not improve our estimates for the
infection rate.</p>
<p>Hierarchical models provide us with a modeling tool to link datasets
by making the following assumption:</p>
<p>Let <span class="math inline">\(\theta_\ell =
\log(\pi_\ell/(1-\pi_\ell))\)</span> the logistic transform of the
probability of infection <span class="math inline">\(\pi_\ell\)</span>
in each county. We now assume that <span class="math display">\[
\theta_\ell = \bar \theta + \xi_\ell,
\]</span> where <span class="math inline">\(\bar \theta\)</span> is the
overall mean logistic transformed infection probability, and independent
<span class="math inline">\(\xi_\ell\)</span> are mean zero random
variable with known distribution. For example, we could assume that
<span class="math inline">\(\xi_\ell\)</span> iid Gaussian random
variables with known variance <span
class="math inline">\(\tau^2\)</span>.</p>
<p>In hierarchical modeling, one would estimate the variance <span
class="math inline">\(\tau^2\)</span>. Here, let us implement a poor
man’s hiearchical model.</p>
</div>
<div
id="section-poor-mans-hiearchical-model-put-the-information-into-the-priors"
class="section level3">
<h3>Poor man’s hiearchical model: Put the information into the
priors</h3>
<p>The description in the previous section provides us with the means to
construct an informative prior for the vector of logit transforms of the
infection probability. Specifically, consider the vector <span
class="math inline">\((\theta_1,\ldots,\theta_m)\)</span> for each of
the <span class="math inline">\(m\)</span> counties. We assume that
<span class="math display">\[
\theta_j|\bar \theta = \bar \theta + \xi_j.
\]</span> If <span class="math inline">\(\bar \theta\)</span> is itself
Gaussian with mean zero and variance <span
class="math inline">\(\sigma^2\)</span> (this is our prior of
convenience), then we know that the vector <span
class="math inline">\((\theta_1,\ldots,\theta_m)^t\)</span> has a mean
zero Gaussian distribution with covariance function <span
class="math display">\[
\left ( \begin{array}{ccccc}
\sigma^2 + \tau^2 &amp; \sigma^2 &amp; \sigma^2 &amp; \dots &amp;
\sigma^2 \\
\sigma^2 &amp; \sigma^2 + \tau^2 &amp; \sigma^2 &amp; \dots &amp;
\sigma^2 \\
\sigma^2 &amp; \sigma^2 &amp; \sigma^2 + \tau^2 &amp; \dots &amp;
\sigma^2 \\
\vdots &amp; \vdots &amp; &amp; \ddots &amp; \vdots \\
\sigma^2 &amp; \sigma^2 &amp; \sigma^2 &amp; \dots &amp; \sigma^2 +
\tau^2
\end{array} \right )
\]</span></p>
<p>That is, relating the parameter across data sets can be achieved by
constructing informative priors!</p>
<p>A full hierarchical model would put priors on the variances <span
class="math inline">\(\sigma^2\)</span> and <span
class="math inline">\(\tau^2\)</span>. For us, we will fix their
values.</p>
<div id="section-implementation-2" class="section level4">
<h4>Implementation</h4>
<p>Take the <code>mcmcSIR.R</code> script as a starting point and
construct a Metropolis sampler that combines the data from two or more
counties.</p>
</div>
</div>
<div id="section-stability-of-markov-chains" class="section level3">
<h3>Stability of Markov chains</h3>
<p>Monte-Carlo simulations can sometimes be delicate. Explore how the
results for the two parameter estimate from example 2
<code>mcmc_Example2.R</code> varies if you change the initial condition,
seed, and/or step size.</p>
<p>Can you suggest a reason (numeric or otherwise) for what is
happening?</p>
<p>
<script type="application/shiny-prerendered" data-context="server-start">
# load packages we need
library(learnr)
library(tidyverse)
library(knitr)
library(zoo)
library(MASS)
library(dplyr)

#....
require(deSolve)

#....
# set options
tutorial_options(
  exercise.timelimit = 60,
  # A simple checker function that just returns the message in the check chunk
  exercise.checker = function(check_code, ...) {
    list(
      message = eval(parse(text = check_code)),
      correct = logical(0),
      type = "info",
      location = "append"
    )
  }
)
knitr::opts_chunk$set(error = TRUE)

# set random seed. --- useful for reproducing results
set.seed(709)

# Set local directory
# SET PATH OF DIRECTORY
setwd("~/Lecture/Epi_MCMC")

# Path to directory where the figures are located
# SET PATH OF FIGURES
figure.path <- "~/Lecture/Epi_MCMC"
</script>
 
<script type="application/shiny-prerendered" data-context="server">
learnr:::register_http_handlers(session, metadata = NULL)
</script>


<script type="application/shiny-prerendered" data-context="server">
learnr:::prepare_tutorial_state(session)
</script>
 
<script type="application/shiny-prerendered" data-context="server">
learnr:::i18n_observe_tutorial_language(input, session)
</script>


<script type="application/shiny-prerendered" data-context="server">
session$onSessionEnded(function() {
        learnr:::event_trigger(session, "session_stop")
      })
</script>
 
<script type="application/shiny-prerendered" data-context="server">
`tutorial-exercise-negative-binomial-result` <- learnr:::setup_exercise_handler(reactive(req(input$`tutorial-exercise-negative-binomial-code-editor`)), session)
output$`tutorial-exercise-negative-binomial-output` <- renderUI({
  `tutorial-exercise-negative-binomial-result`()
})
</script>


<script type="application/shiny-prerendered" data-context="server">
learnr:::store_exercise_cache(structure(list(label = "negative-binomial", global_setup = structure(c("# load packages we need", 
"library(learnr)", "library(tidyverse)", "library(knitr)", "library(zoo)", 
"library(MASS)", "library(dplyr)", "", "#....", "require(deSolve)", 
"", "#....", "# set options", "tutorial_options(", "  exercise.timelimit = 60,", 
"  # A simple checker function that just returns the message in the check chunk", 
"  exercise.checker = function(check_code, ...) {", "    list(", 
"      message = eval(parse(text = check_code)),", "      correct = logical(0),", 
"      type = \"info\",", "      location = \"append\"", "    )", 
"  }", ")", "knitr::opts_chunk$set(error = TRUE)", "", "# set random seed. --- useful for reproducing results", 
"set.seed(709)", "", "# Set local directory", "# SET PATH OF DIRECTORY", 
"setwd(\"~/Lecture/Epi_MCMC\")", "", "# Path to directory where the figures are located", 
"# SET PATH OF FIGURES", "figure.path <- \"~/Lecture/Epi_MCMC\""
), chunk_opts = list(label = "setup", echo = FALSE, include = FALSE)), 
    setup = NULL, chunks = list(list(label = "negative-binomial", 
        code = "# set value for random variable Z and size s=3\n# in R, you assign values to variables with the <- or ->\nZ <- 7\ns <- 3\n\n# build vector of values for p, ranging from 0 to 1\ndp <- 0.001  # set increment size\np <- seq( from=dp/2, to=1,by=dp)  # generates a sequence\n\n# use dnbinom to calculate probability \nloglik <- dnbinom(Z,s,p,log = TRUE)  # log useful when we have small numbers\n\n# plot the loglikelihood \nplot(p, loglik,  type=\"l\", lwd=3, # type=\"l\" draws lines, lwd= line width\n     xlab=\"p\",ylab=\"loglikelihood\")", 
        opts = list(label = "\"negative-binomial\"", exercise = "TRUE"), 
        engine = "r")), code_check = NULL, error_check = NULL, 
    check = NULL, solution = NULL, tests = NULL, options = list(
        eval = FALSE, echo = TRUE, results = "markup", tidy = FALSE, 
        tidy.opts = NULL, collapse = FALSE, prompt = FALSE, comment = NA, 
        highlight = FALSE, size = "normalsize", background = "#F7F7F7", 
        strip.white = TRUE, cache = 0, cache.path = "lecture_cache/html/", 
        cache.vars = NULL, cache.lazy = TRUE, dependson = NULL, 
        autodep = FALSE, cache.rebuild = FALSE, fig.keep = "high", 
        fig.show = "asis", fig.align = "default", fig.path = "lecture_files/figure-html/", 
        dev = "png", dev.args = NULL, dpi = 192, fig.ext = "png", 
        fig.width = 6.5, fig.height = 4, fig.env = "figure", 
        fig.cap = NULL, fig.scap = NULL, fig.lp = "fig:", fig.subcap = NULL, 
        fig.pos = "", out.width = 624, out.height = NULL, out.extra = NULL, 
        fig.retina = 2, external = TRUE, sanitize = FALSE, interval = 1, 
        aniopts = "controls,loop", warning = TRUE, error = TRUE, 
        message = TRUE, render = NULL, ref.label = NULL, child = NULL, 
        engine = "r", split = FALSE, include = TRUE, purl = TRUE, 
        max.print = 1000, exercise.timelimit = 60, exercise.checker = "function (check_code, ...) \n{\n    list(message = eval(parse(text = check_code)), correct = logical(0), \n        type = \"info\", location = \"append\")\n}", 
        label = "negative-binomial", exercise = TRUE, code = c("# set value for random variable Z and size s=3", 
        "# in R, you assign values to variables with the <- or ->", 
        "Z <- 7", "s <- 3", "", "# build vector of values for p, ranging from 0 to 1", 
        "dp <- 0.001  # set increment size", "p <- seq( from=dp/2, to=1,by=dp)  # generates a sequence", 
        "", "# use dnbinom to calculate probability ", "loglik <- dnbinom(Z,s,p,log = TRUE)  # log useful when we have small numbers", 
        "", "# plot the loglikelihood ", "plot(p, loglik,  type=\"l\", lwd=3, # type=\"l\" draws lines, lwd= line width", 
        "     xlab=\"p\",ylab=\"loglikelihood\")"), out.width.px = 624, 
        out.height.px = 384, params.src = "negative-binomial, exercise = TRUE", 
        fig.num = 0, exercise.df_print = "paged"), engine = "r", 
    version = "4"), class = c("r", "tutorial_exercise")))
</script>
 
<script type="application/shiny-prerendered" data-context="server">
`tutorial-exercise-binomial-result` <- learnr:::setup_exercise_handler(reactive(req(input$`tutorial-exercise-binomial-code-editor`)), session)
output$`tutorial-exercise-binomial-output` <- renderUI({
  `tutorial-exercise-binomial-result`()
})
</script>


<script type="application/shiny-prerendered" data-context="server">
learnr:::store_exercise_cache(structure(list(label = "binomial", global_setup = structure(c("# load packages we need", 
"library(learnr)", "library(tidyverse)", "library(knitr)", "library(zoo)", 
"library(MASS)", "library(dplyr)", "", "#....", "require(deSolve)", 
"", "#....", "# set options", "tutorial_options(", "  exercise.timelimit = 60,", 
"  # A simple checker function that just returns the message in the check chunk", 
"  exercise.checker = function(check_code, ...) {", "    list(", 
"      message = eval(parse(text = check_code)),", "      correct = logical(0),", 
"      type = \"info\",", "      location = \"append\"", "    )", 
"  }", ")", "knitr::opts_chunk$set(error = TRUE)", "", "# set random seed. --- useful for reproducing results", 
"set.seed(709)", "", "# Set local directory", "# SET PATH OF DIRECTORY", 
"setwd(\"~/Lecture/Epi_MCMC\")", "", "# Path to directory where the figures are located", 
"# SET PATH OF FIGURES", "figure.path <- \"~/Lecture/Epi_MCMC\""
), chunk_opts = list(label = "setup", echo = FALSE, include = FALSE)), 
    setup = NULL, chunks = list(list(label = "binomial", code = "# set up a grid a the probability of success\npp <- seq( 0, 1, by = 0.001 )\n\n# Data\n# number of trials\nN <- 50 # In R, you can use = or <- to assign values to variables\n\nZ <- 6\n\n# parameter of prior\na <- 2\nb <- 3\n\n# dbeta is a function that calculates the density of a beta distribution\n# evaluated at values pp (can be a vector), and parameters a and b\n\nPrior <- dbeta(pp,a,b)\n\n# To get help about functions in R, use either\n# help(\"dbeta\") \n# ?dbeta\n\n# beta is conjugate prior for binomial.  So we *KNOW* that\n# the posterior is a beta with parameters a+z, b+N-z\n# again, I evaluate density on a grid of values of p\nPosterior <- dbeta(pp,a+Z,b+N-Z)\n\n# Now I want to make a plot\n# Useful to calculate the maximum to set axis...\nmmax <- max(Prior,Posterior)\n\nplot(c(0,1), c(0,mmax), type=\"n\",       # type=\"n\" just sets up thje axis\n          xlab=\"prob\", ylab=\"density\")  # xlab, ylab used for the labels\n\nlines(pp,Prior,col=1,lwd=2)\nlines(pp,Posterior,col=2,lwd=2)\n\n#. calculate confidence interval\n\nCI <- function(p,posterior,L){\n  idx <- posterior > L\n  coverage <- mean( posterior*idx )\n  CI <- range( p[idx] )\n  return( list( interval=CI, coverage=coverage ) )\n}\n\nabline(h=1,lty=3)\nCI(pp,Posterior,1)\n", 
        opts = list(label = "\"binomial\"", eval = "TRUE", exercise = "TRUE", 
            exercise.eval = "FALSE"), engine = "r")), code_check = NULL, 
    error_check = NULL, check = NULL, solution = NULL, tests = NULL, 
    options = list(eval = FALSE, echo = TRUE, results = "markup", 
        tidy = FALSE, tidy.opts = NULL, collapse = FALSE, prompt = FALSE, 
        comment = NA, highlight = FALSE, size = "normalsize", 
        background = "#F7F7F7", strip.white = TRUE, cache = 0, 
        cache.path = "lecture_cache/html/", cache.vars = NULL, 
        cache.lazy = TRUE, dependson = NULL, autodep = FALSE, 
        cache.rebuild = FALSE, fig.keep = "high", fig.show = "asis", 
        fig.align = "default", fig.path = "lecture_files/figure-html/", 
        dev = "png", dev.args = NULL, dpi = 192, fig.ext = "png", 
        fig.width = 6.5, fig.height = 4, fig.env = "figure", 
        fig.cap = NULL, fig.scap = NULL, fig.lp = "fig:", fig.subcap = NULL, 
        fig.pos = "", out.width = 624, out.height = NULL, out.extra = NULL, 
        fig.retina = 2, external = TRUE, sanitize = FALSE, interval = 1, 
        aniopts = "controls,loop", warning = TRUE, error = TRUE, 
        message = TRUE, render = NULL, ref.label = NULL, child = NULL, 
        engine = "r", split = FALSE, include = TRUE, purl = TRUE, 
        max.print = 1000, exercise.timelimit = 60, exercise.checker = "function (check_code, ...) \n{\n    list(message = eval(parse(text = check_code)), correct = logical(0), \n        type = \"info\", location = \"append\")\n}", 
        label = "binomial", exercise = TRUE, exercise.eval = FALSE, 
        code = c("# set up a grid a the probability of success", 
        "pp <- seq( 0, 1, by = 0.001 )", "", "# Data", "# number of trials", 
        "N <- 50 # In R, you can use = or <- to assign values to variables", 
        "", "Z <- 6", "", "# parameter of prior", "a <- 2", "b <- 3", 
        "", "# dbeta is a function that calculates the density of a beta distribution", 
        "# evaluated at values pp (can be a vector), and parameters a and b", 
        "", "Prior <- dbeta(pp,a,b)", "", "# To get help about functions in R, use either", 
        "# help(\"dbeta\") ", "# ?dbeta", "", "# beta is conjugate prior for binomial.  So we *KNOW* that", 
        "# the posterior is a beta with parameters a+z, b+N-z", 
        "# again, I evaluate density on a grid of values of p", 
        "Posterior <- dbeta(pp,a+Z,b+N-Z)", "", "# Now I want to make a plot", 
        "# Useful to calculate the maximum to set axis...", "mmax <- max(Prior,Posterior)", 
        "", "plot(c(0,1), c(0,mmax), type=\"n\",       # type=\"n\" just sets up thje axis", 
        "          xlab=\"prob\", ylab=\"density\")  # xlab, ylab used for the labels", 
        "", "lines(pp,Prior,col=1,lwd=2)", "lines(pp,Posterior,col=2,lwd=2)", 
        "", "#. calculate confidence interval", "", "CI <- function(p,posterior,L){", 
        "  idx <- posterior > L", "  coverage <- mean( posterior*idx )", 
        "  CI <- range( p[idx] )", "  return( list( interval=CI, coverage=coverage ) )", 
        "}", "", "abline(h=1,lty=3)", "CI(pp,Posterior,1)", ""
        ), out.width.px = 624, out.height.px = 384, params.src = "binomial, eval = TRUE, exercise = TRUE, exercise.eval = FALSE", 
        fig.num = 0, exercise.df_print = "paged"), engine = "r", 
    version = "4"), class = c("r", "tutorial_exercise")))
</script>
 
<script type="application/shiny-prerendered" data-context="server">
`tutorial-exercise-inverse-sampling-result` <- learnr:::setup_exercise_handler(reactive(req(input$`tutorial-exercise-inverse-sampling-code-editor`)), session)
output$`tutorial-exercise-inverse-sampling-output` <- renderUI({
  `tutorial-exercise-inverse-sampling-result`()
})
</script>


<script type="application/shiny-prerendered" data-context="server">
learnr:::store_exercise_cache(structure(list(label = "inverse-sampling", global_setup = structure(c("# load packages we need", 
"library(learnr)", "library(tidyverse)", "library(knitr)", "library(zoo)", 
"library(MASS)", "library(dplyr)", "", "#....", "require(deSolve)", 
"", "#....", "# set options", "tutorial_options(", "  exercise.timelimit = 60,", 
"  # A simple checker function that just returns the message in the check chunk", 
"  exercise.checker = function(check_code, ...) {", "    list(", 
"      message = eval(parse(text = check_code)),", "      correct = logical(0),", 
"      type = \"info\",", "      location = \"append\"", "    )", 
"  }", ")", "knitr::opts_chunk$set(error = TRUE)", "", "# set random seed. --- useful for reproducing results", 
"set.seed(709)", "", "# Set local directory", "# SET PATH OF DIRECTORY", 
"setwd(\"~/Lecture/Epi_MCMC\")", "", "# Path to directory where the figures are located", 
"# SET PATH OF FIGURES", "figure.path <- \"~/Lecture/Epi_MCMC\""
), chunk_opts = list(label = "setup", echo = FALSE, include = FALSE)), 
    setup = NULL, chunks = list(list(label = "inverse-sampling", 
        code = "# data\nN <- 50\nZ <- 8\nm <- 3\n\n# parameters for the prior\na <- 2\nb <- 4\n\n# set-up the numerical approximation by creating a grid of \n# values p\ndp <- 0.05 # grid size\np <- seq(dp/2, by=dp)\n\n# calculate the probability (up to numerical integration)\nP <- c(0, exp( (Z+a-1)*log(p) + (3*(N-Z)+b-1)*log(1-p) + Z*log(3-3*p+p*p) ) )\n\n# calculate the approcimate CDF\ncdf <- cumsum(P)/sum(P)\n\n# sample from that distribution using the inverse probability transform\n# You can define custom functions with the function(...) command\n# The ... are the input variables (locally defined)\n\nFinv <- function(x,cdf,u){\n  idx <- cdf < u                # generate a vector of T-F of the same length as cdf\n  x.smp <- max( x[ cdf < u ] )  # select entries with T, and take the max  \n  return(x.smp)                 # return result\n}\n\nn.smp <- 5000       # number of samples to be drawn\nX <- rep(0,n.smp)   # create vector of zeros of length n.smp\n\n# loop to generate random samples \nfor ( k in 1:n.smp ){\n  X[k] <- Finv( p,cdf,runif(1) ) # [] are used to address component of vector\n                                 # () used for functions\n}\n\n# make a histogram of the results\n# nclass = number of bins\nhist(X,nclass=100,\n     main=\"histogram of posterior\",\n     xlim=c(0,0.3)) # set range of x-axis", 
        opts = list(label = "\"inverse-sampling\"", echo = "TRUE", 
            exercise = "TRUE"), engine = "r")), code_check = NULL, 
    error_check = NULL, check = NULL, solution = NULL, tests = NULL, 
    options = list(eval = FALSE, echo = TRUE, results = "markup", 
        tidy = FALSE, tidy.opts = NULL, collapse = FALSE, prompt = FALSE, 
        comment = NA, highlight = FALSE, size = "normalsize", 
        background = "#F7F7F7", strip.white = TRUE, cache = 0, 
        cache.path = "lecture_cache/html/", cache.vars = NULL, 
        cache.lazy = TRUE, dependson = NULL, autodep = FALSE, 
        cache.rebuild = FALSE, fig.keep = "high", fig.show = "asis", 
        fig.align = "default", fig.path = "lecture_files/figure-html/", 
        dev = "png", dev.args = NULL, dpi = 192, fig.ext = "png", 
        fig.width = 6.5, fig.height = 4, fig.env = "figure", 
        fig.cap = NULL, fig.scap = NULL, fig.lp = "fig:", fig.subcap = NULL, 
        fig.pos = "", out.width = 624, out.height = NULL, out.extra = NULL, 
        fig.retina = 2, external = TRUE, sanitize = FALSE, interval = 1, 
        aniopts = "controls,loop", warning = TRUE, error = TRUE, 
        message = TRUE, render = NULL, ref.label = NULL, child = NULL, 
        engine = "r", split = FALSE, include = TRUE, purl = TRUE, 
        max.print = 1000, exercise.timelimit = 60, exercise.checker = "function (check_code, ...) \n{\n    list(message = eval(parse(text = check_code)), correct = logical(0), \n        type = \"info\", location = \"append\")\n}", 
        label = "inverse-sampling", exercise = TRUE, code = c("# data", 
        "N <- 50", "Z <- 8", "m <- 3", "", "# parameters for the prior", 
        "a <- 2", "b <- 4", "", "# set-up the numerical approximation by creating a grid of ", 
        "# values p", "dp <- 0.05 # grid size", "p <- seq(dp/2, by=dp)", 
        "", "# calculate the probability (up to numerical integration)", 
        "P <- c(0, exp( (Z+a-1)*log(p) + (3*(N-Z)+b-1)*log(1-p) + Z*log(3-3*p+p*p) ) )", 
        "", "# calculate the approcimate CDF", "cdf <- cumsum(P)/sum(P)", 
        "", "# sample from that distribution using the inverse probability transform", 
        "# You can define custom functions with the function(...) command", 
        "# The ... are the input variables (locally defined)", 
        "", "Finv <- function(x,cdf,u){", "  idx <- cdf < u                # generate a vector of T-F of the same length as cdf", 
        "  x.smp <- max( x[ cdf < u ] )  # select entries with T, and take the max  ", 
        "  return(x.smp)                 # return result", "}", 
        "", "n.smp <- 5000       # number of samples to be drawn", 
        "X <- rep(0,n.smp)   # create vector of zeros of length n.smp", 
        "", "# loop to generate random samples ", "for ( k in 1:n.smp ){", 
        "  X[k] <- Finv( p,cdf,runif(1) ) # [] are used to address component of vector", 
        "                                 # () used for functions", 
        "}", "", "# make a histogram of the results", "# nclass = number of bins", 
        "hist(X,nclass=100,", "     main=\"histogram of posterior\",", 
        "     xlim=c(0,0.3)) # set range of x-axis"), out.width.px = 624, 
        out.height.px = 384, params.src = "inverse-sampling, echo=TRUE, exercise = TRUE", 
        fig.num = 0, exercise.df_print = "paged"), engine = "r", 
    version = "4"), class = c("r", "tutorial_exercise")))
</script>
 
<script type="application/shiny-prerendered" data-context="server">
`tutorial-exercise-importance_example-result` <- learnr:::setup_exercise_handler(reactive(req(input$`tutorial-exercise-importance_example-code-editor`)), session)
output$`tutorial-exercise-importance_example-output` <- renderUI({
  `tutorial-exercise-importance_example-result`()
})
</script>


<script type="application/shiny-prerendered" data-context="server">
learnr:::store_exercise_cache(structure(list(label = "importance_example", global_setup = structure(c("# load packages we need", 
"library(learnr)", "library(tidyverse)", "library(knitr)", "library(zoo)", 
"library(MASS)", "library(dplyr)", "", "#....", "require(deSolve)", 
"", "#....", "# set options", "tutorial_options(", "  exercise.timelimit = 60,", 
"  # A simple checker function that just returns the message in the check chunk", 
"  exercise.checker = function(check_code, ...) {", "    list(", 
"      message = eval(parse(text = check_code)),", "      correct = logical(0),", 
"      type = \"info\",", "      location = \"append\"", "    )", 
"  }", ")", "knitr::opts_chunk$set(error = TRUE)", "", "# set random seed. --- useful for reproducing results", 
"set.seed(709)", "", "# Set local directory", "# SET PATH OF DIRECTORY", 
"setwd(\"~/Lecture/Epi_MCMC\")", "", "# Path to directory where the figures are located", 
"# SET PATH OF FIGURES", "figure.path <- \"~/Lecture/Epi_MCMC\""
), chunk_opts = list(label = "setup", echo = FALSE, include = FALSE)), 
    setup = NULL, chunks = list(list(label = "importance_example", 
        code = "# data\nN <- 50\nZ <- 8\nm <- 3\n\n# parameter of prior\na <- 2\nb <- 3\n\n# number of samples\nn.smp <- 10000\n\n# get a sample from a Beta distribution\npp <- rbeta(n.smp, Z+a, m*(N-Z)+b)\n\n# calculate the logarithm of the weights\nww.log <-  Z*( log(1-(1-pp)^m ) - log( pp ) )\nww.log <- ww.log - mean( ww.log ) - log(n.smp)  # get better numerical stability is values do not explode\n\n# normalize weights\nww.normalized <- exp( ww.log - log( sum( exp( ww.log ) ) ) )\n\n# plot weights\nplot(ww.normalized, xlab=\"index\", ylab=\"weight\", pch=20, cex=0.5)\nabline(h=0.001, lty=1, lwd=3)\n\n#. Lets calculate the histogram\nnbins <- 200 # number of bins\nhistogram.breaks <- seq(0,0.5,length=nbins+1)\niidx <- cut( pp, histogram.breaks )\nsplit( ww.normalized, iidx ) %>%\n  sapply(., sum) -> histogram.hight \nhistogram.hight <- histogram.hight * nbins  # normalization \n\nplot(histogram.breaks[-(nbins+1)],histogram.hight,type=\"s\",\n     xlab=\"probability\",ylab=\"histogram\",\n     sub=\"histogram of posterior distribution\")", 
        opts = list(label = "\"importance_example\"", echo = "FALSE", 
            exercise = "TRUE"), engine = "r")), code_check = NULL, 
    error_check = NULL, check = NULL, solution = NULL, tests = NULL, 
    options = list(eval = FALSE, echo = TRUE, results = "markup", 
        tidy = FALSE, tidy.opts = NULL, collapse = FALSE, prompt = FALSE, 
        comment = NA, highlight = FALSE, size = "normalsize", 
        background = "#F7F7F7", strip.white = TRUE, cache = 0, 
        cache.path = "lecture_cache/html/", cache.vars = NULL, 
        cache.lazy = TRUE, dependson = NULL, autodep = FALSE, 
        cache.rebuild = FALSE, fig.keep = "high", fig.show = "asis", 
        fig.align = "default", fig.path = "lecture_files/figure-html/", 
        dev = "png", dev.args = NULL, dpi = 192, fig.ext = "png", 
        fig.width = 6.5, fig.height = 4, fig.env = "figure", 
        fig.cap = NULL, fig.scap = NULL, fig.lp = "fig:", fig.subcap = NULL, 
        fig.pos = "", out.width = 624, out.height = NULL, out.extra = NULL, 
        fig.retina = 2, external = TRUE, sanitize = FALSE, interval = 1, 
        aniopts = "controls,loop", warning = TRUE, error = TRUE, 
        message = TRUE, render = NULL, ref.label = NULL, child = NULL, 
        engine = "r", split = FALSE, include = TRUE, purl = TRUE, 
        max.print = 1000, exercise.timelimit = 60, exercise.checker = "function (check_code, ...) \n{\n    list(message = eval(parse(text = check_code)), correct = logical(0), \n        type = \"info\", location = \"append\")\n}", 
        label = "importance_example", exercise = TRUE, code = c("# data", 
        "N <- 50", "Z <- 8", "m <- 3", "", "# parameter of prior", 
        "a <- 2", "b <- 3", "", "# number of samples", "n.smp <- 10000", 
        "", "# get a sample from a Beta distribution", "pp <- rbeta(n.smp, Z+a, m*(N-Z)+b)", 
        "", "# calculate the logarithm of the weights", "ww.log <-  Z*( log(1-(1-pp)^m ) - log( pp ) )", 
        "ww.log <- ww.log - mean( ww.log ) - log(n.smp)  # get better numerical stability is values do not explode", 
        "", "# normalize weights", "ww.normalized <- exp( ww.log - log( sum( exp( ww.log ) ) ) )", 
        "", "# plot weights", "plot(ww.normalized, xlab=\"index\", ylab=\"weight\", pch=20, cex=0.5)", 
        "abline(h=0.001, lty=1, lwd=3)", "", "#. Lets calculate the histogram", 
        "nbins <- 200 # number of bins", "histogram.breaks <- seq(0,0.5,length=nbins+1)", 
        "iidx <- cut( pp, histogram.breaks )", "split( ww.normalized, iidx ) %>%", 
        "  sapply(., sum) -> histogram.hight ", "histogram.hight <- histogram.hight * nbins  # normalization ", 
        "", "plot(histogram.breaks[-(nbins+1)],histogram.hight,type=\"s\",", 
        "     xlab=\"probability\",ylab=\"histogram\",", "     sub=\"histogram of posterior distribution\")"
        ), out.width.px = 624, out.height.px = 384, params.src = "importance_example, echo=FALSE, exercise = TRUE", 
        fig.num = 0, exercise.df_print = "paged"), engine = "r", 
    version = "4"), class = c("r", "tutorial_exercise")))
</script>
 
<script type="application/shiny-prerendered" data-context="server">
`tutorial-exercise-importance_sampling_summary-result` <- learnr:::setup_exercise_handler(reactive(req(input$`tutorial-exercise-importance_sampling_summary-code-editor`)), session)
output$`tutorial-exercise-importance_sampling_summary-output` <- renderUI({
  `tutorial-exercise-importance_sampling_summary-result`()
})
</script>


<script type="application/shiny-prerendered" data-context="server">
learnr:::store_exercise_cache(structure(list(label = "importance_sampling_summary", global_setup = structure(c("# load packages we need", 
"library(learnr)", "library(tidyverse)", "library(knitr)", "library(zoo)", 
"library(MASS)", "library(dplyr)", "", "#....", "require(deSolve)", 
"", "#....", "# set options", "tutorial_options(", "  exercise.timelimit = 60,", 
"  # A simple checker function that just returns the message in the check chunk", 
"  exercise.checker = function(check_code, ...) {", "    list(", 
"      message = eval(parse(text = check_code)),", "      correct = logical(0),", 
"      type = \"info\",", "      location = \"append\"", "    )", 
"  }", ")", "knitr::opts_chunk$set(error = TRUE)", "", "# set random seed. --- useful for reproducing results", 
"set.seed(709)", "", "# Set local directory", "# SET PATH OF DIRECTORY", 
"setwd(\"~/Lecture/Epi_MCMC\")", "", "# Path to directory where the figures are located", 
"# SET PATH OF FIGURES", "figure.path <- \"~/Lecture/Epi_MCMC\""
), chunk_opts = list(label = "setup", echo = FALSE, include = FALSE)), 
    setup = "# data\nN <- 50\nZ <- 8\nm <- 3\n\n# parameter of prior\na <- 2\nb <- 3\n\n# number of samples\nn.smp <- 10000\n\n# get a sample from a Beta distribution\npp <- rbeta(n.smp, Z+a, m*(N-Z)+b)\n\n# calculate the logarithm of the weights\nww.log <-  Z*( log(1-(1-pp)^m ) - log( pp ) )\nww.log <- ww.log - mean( ww.log ) - log(n.smp)  # get better numerical stability is values do not explode\n\n# normalize weights\nww.normalized <- exp( ww.log - log( sum( exp( ww.log ) ) ) )\n\n# plot weights\nplot(ww.normalized, xlab=\"index\", ylab=\"weight\", pch=20, cex=0.5)\nabline(h=0.001, lty=1, lwd=3)\n\n#. Lets calculate the histogram\nnbins <- 200 # number of bins\nhistogram.breaks <- seq(0,0.5,length=nbins+1)\niidx <- cut( pp, histogram.breaks )\nsplit( ww.normalized, iidx ) %>%\n  sapply(., sum) -> histogram.hight \nhistogram.hight <- histogram.hight * nbins  # normalization \n\nplot(histogram.breaks[-(nbins+1)],histogram.hight,type=\"s\",\n     xlab=\"probability\",ylab=\"histogram\",\n     sub=\"histogram of posterior distribution\")", 
    chunks = list(list(label = "importance_example", code = "# data\nN <- 50\nZ <- 8\nm <- 3\n\n# parameter of prior\na <- 2\nb <- 3\n\n# number of samples\nn.smp <- 10000\n\n# get a sample from a Beta distribution\npp <- rbeta(n.smp, Z+a, m*(N-Z)+b)\n\n# calculate the logarithm of the weights\nww.log <-  Z*( log(1-(1-pp)^m ) - log( pp ) )\nww.log <- ww.log - mean( ww.log ) - log(n.smp)  # get better numerical stability is values do not explode\n\n# normalize weights\nww.normalized <- exp( ww.log - log( sum( exp( ww.log ) ) ) )\n\n# plot weights\nplot(ww.normalized, xlab=\"index\", ylab=\"weight\", pch=20, cex=0.5)\nabline(h=0.001, lty=1, lwd=3)\n\n#. Lets calculate the histogram\nnbins <- 200 # number of bins\nhistogram.breaks <- seq(0,0.5,length=nbins+1)\niidx <- cut( pp, histogram.breaks )\nsplit( ww.normalized, iidx ) %>%\n  sapply(., sum) -> histogram.hight \nhistogram.hight <- histogram.hight * nbins  # normalization \n\nplot(histogram.breaks[-(nbins+1)],histogram.hight,type=\"s\",\n     xlab=\"probability\",ylab=\"histogram\",\n     sub=\"histogram of posterior distribution\")", 
        opts = list(label = "\"importance_example\"", echo = "FALSE", 
            exercise = "TRUE"), engine = "r"), list(label = "importance_sampling_summary", 
        code = "# sort sampled values\nidx <- sort.list(pp)\npp.sort <- pp[idx]\nww.normalized.sort <- ww.normalized[idx]\n\n# cumulative distribution\npp.cdf <- cumsum(ww.normalized.sort) \n\n# summary statistics of the posterior\nsum.stat <- list(\n  mean=sum(ww.normalized.sort*pp.sort), # mean\n  q10=max( pp.sort[ pp.cdf < 0.1] ),  # lower 10% quantile\n  q50=max( pp.sort[ pp.cdf < 0.5] ),  # median\n  q90=max( pp.sort[ pp.cdf < 0.9] ) ) # upper 10% quantile\n\nsapply(sum.stat, round,4)", 
        opts = list(label = "\"importance_sampling_summary\"", 
            exercise.setup = "\"importance_example\"", exercise = "TRUE"), 
        engine = "r")), code_check = NULL, error_check = NULL, 
    check = NULL, solution = NULL, tests = NULL, options = list(
        eval = FALSE, echo = TRUE, results = "markup", tidy = FALSE, 
        tidy.opts = NULL, collapse = FALSE, prompt = FALSE, comment = NA, 
        highlight = FALSE, size = "normalsize", background = "#F7F7F7", 
        strip.white = TRUE, cache = 0, cache.path = "lecture_cache/html/", 
        cache.vars = NULL, cache.lazy = TRUE, dependson = NULL, 
        autodep = FALSE, cache.rebuild = FALSE, fig.keep = "high", 
        fig.show = "asis", fig.align = "default", fig.path = "lecture_files/figure-html/", 
        dev = "png", dev.args = NULL, dpi = 192, fig.ext = "png", 
        fig.width = 6.5, fig.height = 4, fig.env = "figure", 
        fig.cap = NULL, fig.scap = NULL, fig.lp = "fig:", fig.subcap = NULL, 
        fig.pos = "", out.width = 624, out.height = NULL, out.extra = NULL, 
        fig.retina = 2, external = TRUE, sanitize = FALSE, interval = 1, 
        aniopts = "controls,loop", warning = TRUE, error = TRUE, 
        message = TRUE, render = NULL, ref.label = NULL, child = NULL, 
        engine = "r", split = FALSE, include = TRUE, purl = TRUE, 
        max.print = 1000, exercise.timelimit = 60, exercise.checker = "function (check_code, ...) \n{\n    list(message = eval(parse(text = check_code)), correct = logical(0), \n        type = \"info\", location = \"append\")\n}", 
        label = "importance_sampling_summary", exercise.setup = "importance_example", 
        exercise = TRUE, code = c("# sort sampled values", "idx <- sort.list(pp)", 
        "pp.sort <- pp[idx]", "ww.normalized.sort <- ww.normalized[idx]", 
        "", "# cumulative distribution", "pp.cdf <- cumsum(ww.normalized.sort) ", 
        "", "# summary statistics of the posterior", "sum.stat <- list(", 
        "  mean=sum(ww.normalized.sort*pp.sort), # mean", "  q10=max( pp.sort[ pp.cdf < 0.1] ),  # lower 10% quantile", 
        "  q50=max( pp.sort[ pp.cdf < 0.5] ),  # median", "  q90=max( pp.sort[ pp.cdf < 0.9] ) ) # upper 10% quantile", 
        "", "sapply(sum.stat, round,4)"), out.width.px = 624, 
        out.height.px = 384, params.src = "importance_sampling_summary, exercise.setup = \"importance_example\", exercise=TRUE", 
        fig.num = 0, exercise.df_print = "paged"), engine = "r", 
    version = "4"), class = c("r", "tutorial_exercise")))
</script>
 
<script type="application/shiny-prerendered" data-context="server">
`tutorial-exercise-example-bivariate-result` <- learnr:::setup_exercise_handler(reactive(req(input$`tutorial-exercise-example-bivariate-code-editor`)), session)
output$`tutorial-exercise-example-bivariate-output` <- renderUI({
  `tutorial-exercise-example-bivariate-result`()
})
</script>


<script type="application/shiny-prerendered" data-context="server">
learnr:::store_exercise_cache(structure(list(label = "example-bivariate", global_setup = structure(c("# load packages we need", 
"library(learnr)", "library(tidyverse)", "library(knitr)", "library(zoo)", 
"library(MASS)", "library(dplyr)", "", "#....", "require(deSolve)", 
"", "#....", "# set options", "tutorial_options(", "  exercise.timelimit = 60,", 
"  # A simple checker function that just returns the message in the check chunk", 
"  exercise.checker = function(check_code, ...) {", "    list(", 
"      message = eval(parse(text = check_code)),", "      correct = logical(0),", 
"      type = \"info\",", "      location = \"append\"", "    )", 
"  }", ")", "knitr::opts_chunk$set(error = TRUE)", "", "# set random seed. --- useful for reproducing results", 
"set.seed(709)", "", "# Set local directory", "# SET PATH OF DIRECTORY", 
"setwd(\"~/Lecture/Epi_MCMC\")", "", "# Path to directory where the figures are located", 
"# SET PATH OF FIGURES", "figure.path <- \"~/Lecture/Epi_MCMC\""
), chunk_opts = list(label = "setup", echo = FALSE, include = FALSE)), 
    setup = NULL, chunks = list(list(label = "example-bivariate", 
        code = "# sample size\nn.smp <- 50000\n\n# draw X from the desired Poisson\nmu <- 50\nX <- rpois(n.smp, mu)\n\n# draw Y form the conditional distribtuion\np <- 1/2\nY <- rbinom(n.smp,X,p)\n\n# get joint contingency table\nT <- table(X,Y)\n\n# make a heatplot\nimage(as.numeric(rownames(T)), as.numeric(colnames(T)), T,\n      xlab=\"X\", ylab=\"Y\")", 
        opts = list(label = "\"example-bivariate\"", echo = "TRUE", 
            exercise = "TRUE"), engine = "r")), code_check = NULL, 
    error_check = NULL, check = NULL, solution = NULL, tests = NULL, 
    options = list(eval = FALSE, echo = TRUE, results = "markup", 
        tidy = FALSE, tidy.opts = NULL, collapse = FALSE, prompt = FALSE, 
        comment = NA, highlight = FALSE, size = "normalsize", 
        background = "#F7F7F7", strip.white = TRUE, cache = 0, 
        cache.path = "lecture_cache/html/", cache.vars = NULL, 
        cache.lazy = TRUE, dependson = NULL, autodep = FALSE, 
        cache.rebuild = FALSE, fig.keep = "high", fig.show = "asis", 
        fig.align = "default", fig.path = "lecture_files/figure-html/", 
        dev = "png", dev.args = NULL, dpi = 192, fig.ext = "png", 
        fig.width = 6.5, fig.height = 4, fig.env = "figure", 
        fig.cap = NULL, fig.scap = NULL, fig.lp = "fig:", fig.subcap = NULL, 
        fig.pos = "", out.width = 624, out.height = NULL, out.extra = NULL, 
        fig.retina = 2, external = TRUE, sanitize = FALSE, interval = 1, 
        aniopts = "controls,loop", warning = TRUE, error = TRUE, 
        message = TRUE, render = NULL, ref.label = NULL, child = NULL, 
        engine = "r", split = FALSE, include = TRUE, purl = TRUE, 
        max.print = 1000, exercise.timelimit = 60, exercise.checker = "function (check_code, ...) \n{\n    list(message = eval(parse(text = check_code)), correct = logical(0), \n        type = \"info\", location = \"append\")\n}", 
        label = "example-bivariate", exercise = TRUE, code = c("# sample size", 
        "n.smp <- 50000", "", "# draw X from the desired Poisson", 
        "mu <- 50", "X <- rpois(n.smp, mu)", "", "# draw Y form the conditional distribtuion", 
        "p <- 1/2", "Y <- rbinom(n.smp,X,p)", "", "# get joint contingency table", 
        "T <- table(X,Y)", "", "# make a heatplot", "image(as.numeric(rownames(T)), as.numeric(colnames(T)), T,", 
        "      xlab=\"X\", ylab=\"Y\")"), out.width.px = 624, 
        out.height.px = 384, params.src = "example-bivariate, echo=TRUE, exercise=TRUE", 
        fig.num = 0, exercise.df_print = "paged"), engine = "r", 
    version = "4"), class = c("r", "tutorial_exercise")))
</script>
 
<script type="application/shiny-prerendered" data-context="server">
`tutorial-exercise-example-markov-result` <- learnr:::setup_exercise_handler(reactive(req(input$`tutorial-exercise-example-markov-code-editor`)), session)
output$`tutorial-exercise-example-markov-output` <- renderUI({
  `tutorial-exercise-example-markov-result`()
})
</script>


<script type="application/shiny-prerendered" data-context="server">
learnr:::store_exercise_cache(structure(list(label = "example-markov", global_setup = structure(c("# load packages we need", 
"library(learnr)", "library(tidyverse)", "library(knitr)", "library(zoo)", 
"library(MASS)", "library(dplyr)", "", "#....", "require(deSolve)", 
"", "#....", "# set options", "tutorial_options(", "  exercise.timelimit = 60,", 
"  # A simple checker function that just returns the message in the check chunk", 
"  exercise.checker = function(check_code, ...) {", "    list(", 
"      message = eval(parse(text = check_code)),", "      correct = logical(0),", 
"      type = \"info\",", "      location = \"append\"", "    )", 
"  }", ")", "knitr::opts_chunk$set(error = TRUE)", "", "# set random seed. --- useful for reproducing results", 
"set.seed(709)", "", "# Set local directory", "# SET PATH OF DIRECTORY", 
"setwd(\"~/Lecture/Epi_MCMC\")", "", "# Path to directory where the figures are located", 
"# SET PATH OF FIGURES", "figure.path <- \"~/Lecture/Epi_MCMC\""
), chunk_opts = list(label = "setup", echo = FALSE, include = FALSE)), 
    setup = NULL, chunks = list(list(label = "example-markov", 
        code = "# build transition matrix\nP <- matrix( c(.1,.8,.1,0,0,.1,.2,.5,.2,0,0,.1,.2,.4,.3,0,0,.2,.3,.5,.2,0,.1,.7,0),\n             5,5,byrow=TRUE)\n\nstates <- as.character(1:5)\ncolnames(P) <- states\nrownames(P) <- states\nP\n\n# each row sums to one\napply(P,1,sum)\n\n# example of realizations \nn.smp <- 10000\n\nZ    <- rep(\"\",n.smp)\n\n# initialize the chain.  Start in state 3\nZ[1] <- \"3\"\n\nfor ( k in 2:n.smp ){\n  Z[k] <- sample(states,1,prob=P[Z[k-1],]) # sample function \n}\n\n# long run frequency\ntable(Z)/n.smp\n\nplot( as.numeric(Z)[1:100],  # select a subset of the chain (first 100 elements)\n      xlab=\"index\", ylab=\"state\", \n      pch=20, cex=0.5, type=\"b\") # type=\"b\" plots both points and lines", 
        opts = list(label = "\"example-markov\"", echo = "TRUE", 
            exercise = "TRUE"), engine = "r")), code_check = NULL, 
    error_check = NULL, check = NULL, solution = NULL, tests = NULL, 
    options = list(eval = FALSE, echo = TRUE, results = "markup", 
        tidy = FALSE, tidy.opts = NULL, collapse = FALSE, prompt = FALSE, 
        comment = NA, highlight = FALSE, size = "normalsize", 
        background = "#F7F7F7", strip.white = TRUE, cache = 0, 
        cache.path = "lecture_cache/html/", cache.vars = NULL, 
        cache.lazy = TRUE, dependson = NULL, autodep = FALSE, 
        cache.rebuild = FALSE, fig.keep = "high", fig.show = "asis", 
        fig.align = "default", fig.path = "lecture_files/figure-html/", 
        dev = "png", dev.args = NULL, dpi = 192, fig.ext = "png", 
        fig.width = 6.5, fig.height = 4, fig.env = "figure", 
        fig.cap = NULL, fig.scap = NULL, fig.lp = "fig:", fig.subcap = NULL, 
        fig.pos = "", out.width = 624, out.height = NULL, out.extra = NULL, 
        fig.retina = 2, external = TRUE, sanitize = FALSE, interval = 1, 
        aniopts = "controls,loop", warning = TRUE, error = TRUE, 
        message = TRUE, render = NULL, ref.label = NULL, child = NULL, 
        engine = "r", split = FALSE, include = TRUE, purl = TRUE, 
        max.print = 1000, exercise.timelimit = 60, exercise.checker = "function (check_code, ...) \n{\n    list(message = eval(parse(text = check_code)), correct = logical(0), \n        type = \"info\", location = \"append\")\n}", 
        label = "example-markov", exercise = TRUE, code = c("# build transition matrix", 
        "P <- matrix( c(.1,.8,.1,0,0,.1,.2,.5,.2,0,0,.1,.2,.4,.3,0,0,.2,.3,.5,.2,0,.1,.7,0),", 
        "             5,5,byrow=TRUE)", "", "states <- as.character(1:5)", 
        "colnames(P) <- states", "rownames(P) <- states", "P", 
        "", "# each row sums to one", "apply(P,1,sum)", "", "# example of realizations ", 
        "n.smp <- 10000", "", "Z    <- rep(\"\",n.smp)", "", 
        "# initialize the chain.  Start in state 3", "Z[1] <- \"3\"", 
        "", "for ( k in 2:n.smp ){", "  Z[k] <- sample(states,1,prob=P[Z[k-1],]) # sample function ", 
        "}", "", "# long run frequency", "table(Z)/n.smp", "", 
        "plot( as.numeric(Z)[1:100],  # select a subset of the chain (first 100 elements)", 
        "      xlab=\"index\", ylab=\"state\", ", "      pch=20, cex=0.5, type=\"b\") # type=\"b\" plots both points and lines"
        ), out.width.px = 624, out.height.px = 384, params.src = "example-markov, echo=TRUE, exercise=TRUE", 
        fig.num = 0, exercise.df_print = "paged"), engine = "r", 
    version = "4"), class = c("r", "tutorial_exercise")))
</script>
 
<script type="application/shiny-prerendered" data-context="server">
`tutorial-exercise-example-mcmc-2-result` <- learnr:::setup_exercise_handler(reactive(req(input$`tutorial-exercise-example-mcmc-2-code-editor`)), session)
output$`tutorial-exercise-example-mcmc-2-output` <- renderUI({
  `tutorial-exercise-example-mcmc-2-result`()
})
</script>


<script type="application/shiny-prerendered" data-context="server">
learnr:::store_exercise_cache(structure(list(label = "example-mcmc-2", global_setup = structure(c("# load packages we need", 
"library(learnr)", "library(tidyverse)", "library(knitr)", "library(zoo)", 
"library(MASS)", "library(dplyr)", "", "#....", "require(deSolve)", 
"", "#....", "# set options", "tutorial_options(", "  exercise.timelimit = 60,", 
"  # A simple checker function that just returns the message in the check chunk", 
"  exercise.checker = function(check_code, ...) {", "    list(", 
"      message = eval(parse(text = check_code)),", "      correct = logical(0),", 
"      type = \"info\",", "      location = \"append\"", "    )", 
"  }", ")", "knitr::opts_chunk$set(error = TRUE)", "", "# set random seed. --- useful for reproducing results", 
"set.seed(709)", "", "# Set local directory", "# SET PATH OF DIRECTORY", 
"setwd(\"~/Lecture/Epi_MCMC\")", "", "# Path to directory where the figures are located", 
"# SET PATH OF FIGURES", "figure.path <- \"~/Lecture/Epi_MCMC\""
), chunk_opts = list(label = "setup", echo = FALSE, include = FALSE)), 
    setup = NULL, chunks = list(list(label = "example-mcmc-2", 
        code = "\n# example of gambler's ruin\nn.smp <- 150\nZ <- rep(0,n.smp)\n\nZ[1] <- 10 # initial value\nTot <- 20  # total wealth of both players\np <- 0.5   # prob that player 1 wins\n\n# random walk with biased coin.  Stop when either \n# player runs out of money\n\nfor ( k in 2:n.smp ){\n  if ( Z[k-1] == 0 ) {\n    Z[k] <- 0\n  } else {\n    if ( Z[k-1] == Tot ){\n      Z[k] <- Tot\n    } else {\n    Z[k] <- Z[k-1] + 2*((runif(1) < p )-0.5)\n    }\n  }\n}\n\nZ", 
        opts = list(label = "\"example-mcmc-2\"", echo = "TRUE", 
            exercise = "TRUE"), engine = "r")), code_check = NULL, 
    error_check = NULL, check = NULL, solution = NULL, tests = NULL, 
    options = list(eval = FALSE, echo = TRUE, results = "markup", 
        tidy = FALSE, tidy.opts = NULL, collapse = FALSE, prompt = FALSE, 
        comment = NA, highlight = FALSE, size = "normalsize", 
        background = "#F7F7F7", strip.white = TRUE, cache = 0, 
        cache.path = "lecture_cache/html/", cache.vars = NULL, 
        cache.lazy = TRUE, dependson = NULL, autodep = FALSE, 
        cache.rebuild = FALSE, fig.keep = "high", fig.show = "asis", 
        fig.align = "default", fig.path = "lecture_files/figure-html/", 
        dev = "png", dev.args = NULL, dpi = 192, fig.ext = "png", 
        fig.width = 6.5, fig.height = 4, fig.env = "figure", 
        fig.cap = NULL, fig.scap = NULL, fig.lp = "fig:", fig.subcap = NULL, 
        fig.pos = "", out.width = 624, out.height = NULL, out.extra = NULL, 
        fig.retina = 2, external = TRUE, sanitize = FALSE, interval = 1, 
        aniopts = "controls,loop", warning = TRUE, error = TRUE, 
        message = TRUE, render = NULL, ref.label = NULL, child = NULL, 
        engine = "r", split = FALSE, include = TRUE, purl = TRUE, 
        max.print = 1000, exercise.timelimit = 60, exercise.checker = "function (check_code, ...) \n{\n    list(message = eval(parse(text = check_code)), correct = logical(0), \n        type = \"info\", location = \"append\")\n}", 
        label = "example-mcmc-2", exercise = TRUE, code = c("", 
        "# example of gambler's ruin", "n.smp <- 150", "Z <- rep(0,n.smp)", 
        "", "Z[1] <- 10 # initial value", "Tot <- 20  # total wealth of both players", 
        "p <- 0.5   # prob that player 1 wins", "", "# random walk with biased coin.  Stop when either ", 
        "# player runs out of money", "", "for ( k in 2:n.smp ){", 
        "  if ( Z[k-1] == 0 ) {", "    Z[k] <- 0", "  } else {", 
        "    if ( Z[k-1] == Tot ){", "      Z[k] <- Tot", "    } else {", 
        "    Z[k] <- Z[k-1] + 2*((runif(1) < p )-0.5)", "    }", 
        "  }", "}", "", "Z"), out.width.px = 624, out.height.px = 384, 
        params.src = "example-mcmc-2,echo=TRUE,exercise=TRUE", 
        fig.num = 0, exercise.df_print = "paged"), engine = "r", 
    version = "4"), class = c("r", "tutorial_exercise")))
</script>
 
<script type="application/shiny-prerendered" data-context="server">
`tutorial-exercise-example-mcmc-3-result` <- learnr:::setup_exercise_handler(reactive(req(input$`tutorial-exercise-example-mcmc-3-code-editor`)), session)
output$`tutorial-exercise-example-mcmc-3-output` <- renderUI({
  `tutorial-exercise-example-mcmc-3-result`()
})
</script>


<script type="application/shiny-prerendered" data-context="server">
learnr:::store_exercise_cache(structure(list(label = "example-mcmc-3", global_setup = structure(c("# load packages we need", 
"library(learnr)", "library(tidyverse)", "library(knitr)", "library(zoo)", 
"library(MASS)", "library(dplyr)", "", "#....", "require(deSolve)", 
"", "#....", "# set options", "tutorial_options(", "  exercise.timelimit = 60,", 
"  # A simple checker function that just returns the message in the check chunk", 
"  exercise.checker = function(check_code, ...) {", "    list(", 
"      message = eval(parse(text = check_code)),", "      correct = logical(0),", 
"      type = \"info\",", "      location = \"append\"", "    )", 
"  }", ")", "knitr::opts_chunk$set(error = TRUE)", "", "# set random seed. --- useful for reproducing results", 
"set.seed(709)", "", "# Set local directory", "# SET PATH OF DIRECTORY", 
"setwd(\"~/Lecture/Epi_MCMC\")", "", "# Path to directory where the figures are located", 
"# SET PATH OF FIGURES", "figure.path <- \"~/Lecture/Epi_MCMC\""
), chunk_opts = list(label = "setup", echo = FALSE, include = FALSE)), 
    setup = NULL, chunks = list(list(label = "example-mcmc-3", 
        code = "# build transition matrix\nP <- matrix( c(.1,.8,.1,0,0,.1,.2,.5,.2,0,0,.1,.2,.4,.3,0,0,.2,.3,.5,.2,0,.1,.7,0),\n             5,5,byrow=TRUE)\n\nstates <- as.character(1:5)\ncolnames(P) <- states\nrownames(P) <- states\n\naa <- 0.5 # mixture fraction\n\nP2 <- (1-aa)*P + aa*diag(5) # diag(5) is the identity matrix\n\n# example of realizations \nn.smp <- 10000\n\nZ    <- rep(\"\",n.smp)\n\n# initialize the chain.  Start in state 3\nZ[1] <- \"3\"\n\nfor ( k in 2:n.smp ){\n  Z[k] <- sample(states,1,prob=P2[Z[k-1],]) # sample function \n}\n\nplot( as.numeric(Z)[1:300],  # select a subset of the chain (first 100 elements)\n      xlab=\"index\", ylab=\"state\", \n      pch=20, cex=0.5, type=\"b\") # type=\"b\" plots both points and lines\n\n# long run frequency\ntable(Z)/n.smp", 
        opts = list(label = "\"example-mcmc-3\"", exercise = "TRUE"), 
        engine = "r")), code_check = NULL, error_check = NULL, 
    check = NULL, solution = NULL, tests = NULL, options = list(
        eval = FALSE, echo = TRUE, results = "markup", tidy = FALSE, 
        tidy.opts = NULL, collapse = FALSE, prompt = FALSE, comment = NA, 
        highlight = FALSE, size = "normalsize", background = "#F7F7F7", 
        strip.white = TRUE, cache = 0, cache.path = "lecture_cache/html/", 
        cache.vars = NULL, cache.lazy = TRUE, dependson = NULL, 
        autodep = FALSE, cache.rebuild = FALSE, fig.keep = "high", 
        fig.show = "asis", fig.align = "default", fig.path = "lecture_files/figure-html/", 
        dev = "png", dev.args = NULL, dpi = 192, fig.ext = "png", 
        fig.width = 6.5, fig.height = 4, fig.env = "figure", 
        fig.cap = NULL, fig.scap = NULL, fig.lp = "fig:", fig.subcap = NULL, 
        fig.pos = "", out.width = 624, out.height = NULL, out.extra = NULL, 
        fig.retina = 2, external = TRUE, sanitize = FALSE, interval = 1, 
        aniopts = "controls,loop", warning = TRUE, error = TRUE, 
        message = TRUE, render = NULL, ref.label = NULL, child = NULL, 
        engine = "r", split = FALSE, include = TRUE, purl = TRUE, 
        max.print = 1000, exercise.timelimit = 60, exercise.checker = "function (check_code, ...) \n{\n    list(message = eval(parse(text = check_code)), correct = logical(0), \n        type = \"info\", location = \"append\")\n}", 
        label = "example-mcmc-3", exercise = TRUE, code = c("# build transition matrix", 
        "P <- matrix( c(.1,.8,.1,0,0,.1,.2,.5,.2,0,0,.1,.2,.4,.3,0,0,.2,.3,.5,.2,0,.1,.7,0),", 
        "             5,5,byrow=TRUE)", "", "states <- as.character(1:5)", 
        "colnames(P) <- states", "rownames(P) <- states", "", 
        "aa <- 0.5 # mixture fraction", "", "P2 <- (1-aa)*P + aa*diag(5) # diag(5) is the identity matrix", 
        "", "# example of realizations ", "n.smp <- 10000", "", 
        "Z    <- rep(\"\",n.smp)", "", "# initialize the chain.  Start in state 3", 
        "Z[1] <- \"3\"", "", "for ( k in 2:n.smp ){", "  Z[k] <- sample(states,1,prob=P2[Z[k-1],]) # sample function ", 
        "}", "", "plot( as.numeric(Z)[1:300],  # select a subset of the chain (first 100 elements)", 
        "      xlab=\"index\", ylab=\"state\", ", "      pch=20, cex=0.5, type=\"b\") # type=\"b\" plots both points and lines", 
        "", "# long run frequency", "table(Z)/n.smp"), out.width.px = 624, 
        out.height.px = 384, params.src = "example-mcmc-3, exercise=TRUE", 
        fig.num = 0, exercise.df_print = "paged"), engine = "r", 
    version = "4"), class = c("r", "tutorial_exercise")))
</script>
 
<script type="application/shiny-prerendered" data-context="server">
`tutorial-exercise-example-sis-result` <- learnr:::setup_exercise_handler(reactive(req(input$`tutorial-exercise-example-sis-code-editor`)), session)
output$`tutorial-exercise-example-sis-output` <- renderUI({
  `tutorial-exercise-example-sis-result`()
})
</script>


<script type="application/shiny-prerendered" data-context="server">
learnr:::store_exercise_cache(structure(list(label = "example-sis", global_setup = structure(c("# load packages we need", 
"library(learnr)", "library(tidyverse)", "library(knitr)", "library(zoo)", 
"library(MASS)", "library(dplyr)", "", "#....", "require(deSolve)", 
"", "#....", "# set options", "tutorial_options(", "  exercise.timelimit = 60,", 
"  # A simple checker function that just returns the message in the check chunk", 
"  exercise.checker = function(check_code, ...) {", "    list(", 
"      message = eval(parse(text = check_code)),", "      correct = logical(0),", 
"      type = \"info\",", "      location = \"append\"", "    )", 
"  }", ")", "knitr::opts_chunk$set(error = TRUE)", "", "# set random seed. --- useful for reproducing results", 
"set.seed(709)", "", "# Set local directory", "# SET PATH OF DIRECTORY", 
"setwd(\"~/Lecture/Epi_MCMC\")", "", "# Path to directory where the figures are located", 
"# SET PATH OF FIGURES", "figure.path <- \"~/Lecture/Epi_MCMC\""
), chunk_opts = list(label = "setup", echo = FALSE, include = FALSE)), 
    setup = NULL, chunks = list(list(label = "example-sis", code = "# set-up\nNpop <- 100     # population size\np0 <- 0.003      # infection probability\nq <- 0.2        # recovery probability\n\nn.times <- 1000 # length of simulation\nZ <- rep(0,n.times)\nZ[1] <- 10      # initial number of infections\n\n# run markov chain\nfor ( k in 2:n.times ){\n  pp <- 1 - exp( Z[k-1]*log(1-p0))\n  U <- rbinom(1,Npop-Z[k-1],pp)\n  V <- rbinom(1,Z[k-1],q)\n  Z[k] <- Z[k-1] + U - V\n}\n\nplot(Z,xlab=\"time\",ylab=\"# infected\",sub=\"SIS\",\n     pch=20,cex=0.75)\n", 
        opts = list(label = "\"example-sis\"", exercise = "TRUE"), 
        engine = "r")), code_check = NULL, error_check = NULL, 
    check = NULL, solution = NULL, tests = NULL, options = list(
        eval = FALSE, echo = TRUE, results = "markup", tidy = FALSE, 
        tidy.opts = NULL, collapse = FALSE, prompt = FALSE, comment = NA, 
        highlight = FALSE, size = "normalsize", background = "#F7F7F7", 
        strip.white = TRUE, cache = 0, cache.path = "lecture_cache/html/", 
        cache.vars = NULL, cache.lazy = TRUE, dependson = NULL, 
        autodep = FALSE, cache.rebuild = FALSE, fig.keep = "high", 
        fig.show = "asis", fig.align = "default", fig.path = "lecture_files/figure-html/", 
        dev = "png", dev.args = NULL, dpi = 192, fig.ext = "png", 
        fig.width = 6.5, fig.height = 4, fig.env = "figure", 
        fig.cap = NULL, fig.scap = NULL, fig.lp = "fig:", fig.subcap = NULL, 
        fig.pos = "", out.width = 624, out.height = NULL, out.extra = NULL, 
        fig.retina = 2, external = TRUE, sanitize = FALSE, interval = 1, 
        aniopts = "controls,loop", warning = TRUE, error = TRUE, 
        message = TRUE, render = NULL, ref.label = NULL, child = NULL, 
        engine = "r", split = FALSE, include = TRUE, purl = TRUE, 
        max.print = 1000, exercise.timelimit = 60, exercise.checker = "function (check_code, ...) \n{\n    list(message = eval(parse(text = check_code)), correct = logical(0), \n        type = \"info\", location = \"append\")\n}", 
        label = "example-sis", exercise = TRUE, code = c("# set-up", 
        "Npop <- 100     # population size", "p0 <- 0.003      # infection probability", 
        "q <- 0.2        # recovery probability", "", "n.times <- 1000 # length of simulation", 
        "Z <- rep(0,n.times)", "Z[1] <- 10      # initial number of infections", 
        "", "# run markov chain", "for ( k in 2:n.times ){", 
        "  pp <- 1 - exp( Z[k-1]*log(1-p0))", "  U <- rbinom(1,Npop-Z[k-1],pp)", 
        "  V <- rbinom(1,Z[k-1],q)", "  Z[k] <- Z[k-1] + U - V", 
        "}", "", "plot(Z,xlab=\"time\",ylab=\"# infected\",sub=\"SIS\",", 
        "     pch=20,cex=0.75)", ""), out.width.px = 624, out.height.px = 384, 
        params.src = "example-sis,exercise=TRUE", fig.num = 0, 
        exercise.df_print = "paged"), engine = "r", version = "4"), class = c("r", 
"tutorial_exercise")))
</script>
 
<script type="application/shiny-prerendered" data-context="server">
`tutorial-exercise-gibbs-ising-result` <- learnr:::setup_exercise_handler(reactive(req(input$`tutorial-exercise-gibbs-ising-code-editor`)), session)
output$`tutorial-exercise-gibbs-ising-output` <- renderUI({
  `tutorial-exercise-gibbs-ising-result`()
})
</script>


<script type="application/shiny-prerendered" data-context="server">
learnr:::store_exercise_cache(structure(list(label = "gibbs-ising", global_setup = structure(c("# load packages we need", 
"library(learnr)", "library(tidyverse)", "library(knitr)", "library(zoo)", 
"library(MASS)", "library(dplyr)", "", "#....", "require(deSolve)", 
"", "#....", "# set options", "tutorial_options(", "  exercise.timelimit = 60,", 
"  # A simple checker function that just returns the message in the check chunk", 
"  exercise.checker = function(check_code, ...) {", "    list(", 
"      message = eval(parse(text = check_code)),", "      correct = logical(0),", 
"      type = \"info\",", "      location = \"append\"", "    )", 
"  }", ")", "knitr::opts_chunk$set(error = TRUE)", "", "# set random seed. --- useful for reproducing results", 
"set.seed(709)", "", "# Set local directory", "# SET PATH OF DIRECTORY", 
"setwd(\"~/Lecture/Epi_MCMC\")", "", "# Path to directory where the figures are located", 
"# SET PATH OF FIGURES", "figure.path <- \"~/Lecture/Epi_MCMC\""
), chunk_opts = list(label = "setup", echo = FALSE, include = FALSE)), 
    setup = NULL, chunks = list(list(label = "gibbs-ising", code = "N <- 20 # size of grid\n\nZ <- matrix(1,N,N) # grid of random variables, initalized to one\n\nindex.p1 <- c(2:N,1) # index shifted to the right\nindex.n1 <- c(N,1:(N-1)) # index shfted to the left \n\nn.sim <- 500 # number of steps in the Gibbs sampler\n\ntheta <- 0.75\n\n# sampling from the conditionals\nfor ( K in 1:n.sim ){\n  for ( k in 1:N ){\n    for ( j in 1:N ){\n      S <- sum( Z[k,c(index.p1[j],index.n1[j])] ) +\n        sum( Z[c(index.n1[k],index.p1[k]),j])\n      P <- exp(theta*S)/(1+exp(theta*S))\n      Z[k,j] <- 2*((runif(1) < P)-0.5)\n    }\n  }\n}\n\nimage(1:N, 1:N, Z)", 
        opts = list(label = "\"gibbs-ising\"", exercise = "TRUE"), 
        engine = "r")), code_check = NULL, error_check = NULL, 
    check = NULL, solution = NULL, tests = NULL, options = list(
        eval = FALSE, echo = TRUE, results = "markup", tidy = FALSE, 
        tidy.opts = NULL, collapse = FALSE, prompt = FALSE, comment = NA, 
        highlight = FALSE, size = "normalsize", background = "#F7F7F7", 
        strip.white = TRUE, cache = 0, cache.path = "lecture_cache/html/", 
        cache.vars = NULL, cache.lazy = TRUE, dependson = NULL, 
        autodep = FALSE, cache.rebuild = FALSE, fig.keep = "high", 
        fig.show = "asis", fig.align = "default", fig.path = "lecture_files/figure-html/", 
        dev = "png", dev.args = NULL, dpi = 192, fig.ext = "png", 
        fig.width = 6.5, fig.height = 4, fig.env = "figure", 
        fig.cap = NULL, fig.scap = NULL, fig.lp = "fig:", fig.subcap = NULL, 
        fig.pos = "", out.width = 624, out.height = NULL, out.extra = NULL, 
        fig.retina = 2, external = TRUE, sanitize = FALSE, interval = 1, 
        aniopts = "controls,loop", warning = TRUE, error = TRUE, 
        message = TRUE, render = NULL, ref.label = NULL, child = NULL, 
        engine = "r", split = FALSE, include = TRUE, purl = TRUE, 
        max.print = 1000, exercise.timelimit = 60, exercise.checker = "function (check_code, ...) \n{\n    list(message = eval(parse(text = check_code)), correct = logical(0), \n        type = \"info\", location = \"append\")\n}", 
        label = "gibbs-ising", exercise = TRUE, code = c("N <- 20 # size of grid", 
        "", "Z <- matrix(1,N,N) # grid of random variables, initalized to one", 
        "", "index.p1 <- c(2:N,1) # index shifted to the right", 
        "index.n1 <- c(N,1:(N-1)) # index shfted to the left ", 
        "", "n.sim <- 500 # number of steps in the Gibbs sampler", 
        "", "theta <- 0.75", "", "# sampling from the conditionals", 
        "for ( K in 1:n.sim ){", "  for ( k in 1:N ){", "    for ( j in 1:N ){", 
        "      S <- sum( Z[k,c(index.p1[j],index.n1[j])] ) +", 
        "        sum( Z[c(index.n1[k],index.p1[k]),j])", "      P <- exp(theta*S)/(1+exp(theta*S))", 
        "      Z[k,j] <- 2*((runif(1) < P)-0.5)", "    }", "  }", 
        "}", "", "image(1:N, 1:N, Z)"), out.width.px = 624, out.height.px = 384, 
        params.src = "gibbs-ising, exercise=TRUE", fig.num = 0, 
        exercise.df_print = "paged"), engine = "r", version = "4"), class = c("r", 
"tutorial_exercise")))
</script>
 
<script type="application/shiny-prerendered" data-context="server">
`tutorial-exercise-gibbs-result` <- learnr:::setup_exercise_handler(reactive(req(input$`tutorial-exercise-gibbs-code-editor`)), session)
output$`tutorial-exercise-gibbs-output` <- renderUI({
  `tutorial-exercise-gibbs-result`()
})
</script>


<script type="application/shiny-prerendered" data-context="server">
learnr:::store_exercise_cache(structure(list(label = "gibbs", global_setup = structure(c("# load packages we need", 
"library(learnr)", "library(tidyverse)", "library(knitr)", "library(zoo)", 
"library(MASS)", "library(dplyr)", "", "#....", "require(deSolve)", 
"", "#....", "# set options", "tutorial_options(", "  exercise.timelimit = 60,", 
"  # A simple checker function that just returns the message in the check chunk", 
"  exercise.checker = function(check_code, ...) {", "    list(", 
"      message = eval(parse(text = check_code)),", "      correct = logical(0),", 
"      type = \"info\",", "      location = \"append\"", "    )", 
"  }", ")", "knitr::opts_chunk$set(error = TRUE)", "", "# set random seed. --- useful for reproducing results", 
"set.seed(709)", "", "# Set local directory", "# SET PATH OF DIRECTORY", 
"setwd(\"~/Lecture/Epi_MCMC\")", "", "# Path to directory where the figures are located", 
"# SET PATH OF FIGURES", "figure.path <- \"~/Lecture/Epi_MCMC\""
), chunk_opts = list(label = "setup", echo = FALSE, include = FALSE)), 
    setup = NULL, chunks = list(list(label = "gibbs", code = "# generate synthetic data\n\n# set the parameters for simulating the data\np <- 0.15\nq <- 0.4\nn <- 40\n\n# generate the sample, using the auxiliary variables A\nN <- sample(seq(2,6,by=1),n,replace=TRUE)\nA <- rbinom(n,1,q)\nZ <- rep(0,n)\nfor ( k in 1:n ){\n  if ( A[k] == 1 ) Z[k] <- rbinom(1,N[k]-1,p)\n}\n\n#  Initialize Gibbs sampler\nniter <- 5000\n\npp <- rep(0,niter)\nqq <- rep(0,niter)\nAA <- matrix(0,niter,n)\n\npp[1] <- 0.5\nqq[1] <- 0.5\nAA[1,] <- sample(c(0,1),n,replace = TRUE)\n\nfor ( k in 2:niter ){\n  # conditional on p and q and the probability A_i=1 is\n  rA <- Z > 0\n  for ( j in 1:n ){\n    if ( Z[j] == 0 ){\n      p.num <- qq[k-1]*exp( (N[j]-1)*log(1-pp[k-1]) )\n      p.dem <- p.num + (1-qq[k-1])\n      pA <- p.num/p.dem\n      rA[j] <- runif(1) < pA\n    }\n  }\n  AA[k,] <- rA\n  \n  # draw Beta for q\n  aa <- sum(AA[k,])+1\n  bb <- n-sum(AA[k,])+1\n  qq[k] <- rbeta(1,aa,bb)\n  \n  # draw Beta for p\n  aa <- sum(AA[k,]*Z) + 1\n  bb <- sum(AA[k,]*(N-1-Z)) + 1\n  pp[k] <- rbeta(1,aa,bb)\n}\n\nhist(pp,nclass=100,xlim=c(0,1),\n     sub=\"histogram of infection probability\",\n     xlab=\"probability\",\n     main=\"\")\nabline(v=p,lwd=2,col=2)\n\nhist(qq,nclass=100,xlim=c(0,1),\n     sub=\"histogram of household with index\",\n     xlab=\"probability\",\n     main=\"\")\nabline(v=q,lwd=2,col=2)\n\njd <- kde2d(pp,qq,n=100)\ncontour(jd,xlab=\"p\",ylab=\"q\",\n        lwd=2, nlevels = 15,\n        sub=\"joint posterior distribtuion\",\n        col=hcl.colors(15, \"Spectral\"))\npoints(pp[(niter-4000):niter],qq[(niter-4000):niter],pch=20,cex=0.3)", 
        opts = list(label = "\"gibbs\"", echo = "FALSE", eval = "TRUE", 
            exercise = "TRUE"), engine = "r")), code_check = NULL, 
    error_check = NULL, check = NULL, solution = NULL, tests = NULL, 
    options = list(eval = FALSE, echo = TRUE, results = "markup", 
        tidy = FALSE, tidy.opts = NULL, collapse = FALSE, prompt = FALSE, 
        comment = NA, highlight = FALSE, size = "normalsize", 
        background = "#F7F7F7", strip.white = TRUE, cache = 0, 
        cache.path = "lecture_cache/html/", cache.vars = NULL, 
        cache.lazy = TRUE, dependson = NULL, autodep = FALSE, 
        cache.rebuild = FALSE, fig.keep = "high", fig.show = "asis", 
        fig.align = "default", fig.path = "lecture_files/figure-html/", 
        dev = "png", dev.args = NULL, dpi = 192, fig.ext = "png", 
        fig.width = 6.5, fig.height = 4, fig.env = "figure", 
        fig.cap = NULL, fig.scap = NULL, fig.lp = "fig:", fig.subcap = NULL, 
        fig.pos = "", out.width = 624, out.height = NULL, out.extra = NULL, 
        fig.retina = 2, external = TRUE, sanitize = FALSE, interval = 1, 
        aniopts = "controls,loop", warning = TRUE, error = TRUE, 
        message = TRUE, render = NULL, ref.label = NULL, child = NULL, 
        engine = "r", split = FALSE, include = TRUE, purl = TRUE, 
        max.print = 1000, exercise.timelimit = 60, exercise.checker = "function (check_code, ...) \n{\n    list(message = eval(parse(text = check_code)), correct = logical(0), \n        type = \"info\", location = \"append\")\n}", 
        label = "gibbs", exercise = TRUE, code = c("# generate synthetic data", 
        "", "# set the parameters for simulating the data", "p <- 0.15", 
        "q <- 0.4", "n <- 40", "", "# generate the sample, using the auxiliary variables A", 
        "N <- sample(seq(2,6,by=1),n,replace=TRUE)", "A <- rbinom(n,1,q)", 
        "Z <- rep(0,n)", "for ( k in 1:n ){", "  if ( A[k] == 1 ) Z[k] <- rbinom(1,N[k]-1,p)", 
        "}", "", "#  Initialize Gibbs sampler", "niter <- 5000", 
        "", "pp <- rep(0,niter)", "qq <- rep(0,niter)", "AA <- matrix(0,niter,n)", 
        "", "pp[1] <- 0.5", "qq[1] <- 0.5", "AA[1,] <- sample(c(0,1),n,replace = TRUE)", 
        "", "for ( k in 2:niter ){", "  # conditional on p and q and the probability A_i=1 is", 
        "  rA <- Z > 0", "  for ( j in 1:n ){", "    if ( Z[j] == 0 ){", 
        "      p.num <- qq[k-1]*exp( (N[j]-1)*log(1-pp[k-1]) )", 
        "      p.dem <- p.num + (1-qq[k-1])", "      pA <- p.num/p.dem", 
        "      rA[j] <- runif(1) < pA", "    }", "  }", "  AA[k,] <- rA", 
        "  ", "  # draw Beta for q", "  aa <- sum(AA[k,])+1", 
        "  bb <- n-sum(AA[k,])+1", "  qq[k] <- rbeta(1,aa,bb)", 
        "  ", "  # draw Beta for p", "  aa <- sum(AA[k,]*Z) + 1", 
        "  bb <- sum(AA[k,]*(N-1-Z)) + 1", "  pp[k] <- rbeta(1,aa,bb)", 
        "}", "", "hist(pp,nclass=100,xlim=c(0,1),", "     sub=\"histogram of infection probability\",", 
        "     xlab=\"probability\",", "     main=\"\")", "abline(v=p,lwd=2,col=2)", 
        "", "hist(qq,nclass=100,xlim=c(0,1),", "     sub=\"histogram of household with index\",", 
        "     xlab=\"probability\",", "     main=\"\")", "abline(v=q,lwd=2,col=2)", 
        "", "jd <- kde2d(pp,qq,n=100)", "contour(jd,xlab=\"p\",ylab=\"q\",", 
        "        lwd=2, nlevels = 15,", "        sub=\"joint posterior distribtuion\",", 
        "        col=hcl.colors(15, \"Spectral\"))", "points(pp[(niter-4000):niter],qq[(niter-4000):niter],pch=20,cex=0.3)"
        ), out.width.px = 624, out.height.px = 384, params.src = "gibbs, echo=FALSE, eval=TRUE, exercise = TRUE", 
        fig.num = 0, exercise.df_print = "paged"), engine = "r", 
    version = "4"), class = c("r", "tutorial_exercise")))
</script>
 
<script type="application/shiny-prerendered" data-context="server">
`tutorial-exercise-metropolis-example-1-result` <- learnr:::setup_exercise_handler(reactive(req(input$`tutorial-exercise-metropolis-example-1-code-editor`)), session)
output$`tutorial-exercise-metropolis-example-1-output` <- renderUI({
  `tutorial-exercise-metropolis-example-1-result`()
})
</script>


<script type="application/shiny-prerendered" data-context="server">
learnr:::store_exercise_cache(structure(list(label = "metropolis-example-1", global_setup = structure(c("# load packages we need", 
"library(learnr)", "library(tidyverse)", "library(knitr)", "library(zoo)", 
"library(MASS)", "library(dplyr)", "", "#....", "require(deSolve)", 
"", "#....", "# set options", "tutorial_options(", "  exercise.timelimit = 60,", 
"  # A simple checker function that just returns the message in the check chunk", 
"  exercise.checker = function(check_code, ...) {", "    list(", 
"      message = eval(parse(text = check_code)),", "      correct = logical(0),", 
"      type = \"info\",", "      location = \"append\"", "    )", 
"  }", ")", "knitr::opts_chunk$set(error = TRUE)", "", "# set random seed. --- useful for reproducing results", 
"set.seed(709)", "", "# Set local directory", "# SET PATH OF DIRECTORY", 
"setwd(\"~/Lecture/Epi_MCMC\")", "", "# Path to directory where the figures are located", 
"# SET PATH OF FIGURES", "figure.path <- \"~/Lecture/Epi_MCMC\""
), chunk_opts = list(label = "setup", echo = FALSE, include = FALSE)), 
    setup = NULL, chunks = list(list(label = "metropolis-example-1", 
        code = "# data\nN <- 50\nZ <- 8\nm <- 3\n\n# parameter of prior\na <- 2\nb <- 3\n\n# number of samples\nn.smp <- 10000\nsigma <- 0.1 # standard deviation (step size)\nlogitP <- rep( 0, n.smp ) # value of the parameter\nLL <- rep(0, n.smp ) # loglikelihood\n\npp <- exp( logitP[1] )/(1+exp(logitP[1]))\nLL[1] <- (Z+a-1)*log(pp) + (m*(N-Z) + b - 1)*log(1-pp) + Z*log(m-m*pp+pp*pp)\n\nfor ( k in 2:n.smp ){\n  theta.new <- logitP[k-1] + sigma*rnorm(1) # proposal\n  pp.new <- exp( theta.new )/( 1+exp( theta.new ) ) # proposed probability\n  # loglikelihood of proposal\n  LL.new <- (Z+a-1)*log(pp.new) + (m*(N-Z) + b - 1)*log(1-pp.new) + Z*log(m-m*pp.new+pp.new*pp.new)\n  R <- exp( min(LL.new - LL[k-1],0) ) # ratio\n  U <- runif(1) # random uniform\n  # move\n  if ( U < R ){\n    # go to proposal\n    logitP[k] <- theta.new\n    LL[k] <- LL.new\n  } else {\n    # stay where you are\n    logitP[k] <- logitP[k-1]\n    LL[k] <- LL[k-1]\n  }\n}\n\n# plot Markov chain\nplot(logitP, xlab=\"iteration\", ylab=\"logit\",\n     pch=20, cex=0.2)\n\n# histogram of sample\nburn.in <- 1000\nP <- exp(logitP[burn.in:n.smp])/(1+exp(logitP[burn.in:n.smp]))\nhist(P,nclass=100, xlab=\"infection probability\", ylab=\"frequency\",xlim=c(0,0.3))", 
        opts = list(label = "\"metropolis-example-1\"", echo = "TRUE", 
            exercise = "TRUE"), engine = "r")), code_check = NULL, 
    error_check = NULL, check = NULL, solution = NULL, tests = NULL, 
    options = list(eval = FALSE, echo = TRUE, results = "markup", 
        tidy = FALSE, tidy.opts = NULL, collapse = FALSE, prompt = FALSE, 
        comment = NA, highlight = FALSE, size = "normalsize", 
        background = "#F7F7F7", strip.white = TRUE, cache = 0, 
        cache.path = "lecture_cache/html/", cache.vars = NULL, 
        cache.lazy = TRUE, dependson = NULL, autodep = FALSE, 
        cache.rebuild = FALSE, fig.keep = "high", fig.show = "asis", 
        fig.align = "default", fig.path = "lecture_files/figure-html/", 
        dev = "png", dev.args = NULL, dpi = 192, fig.ext = "png", 
        fig.width = 6.5, fig.height = 4, fig.env = "figure", 
        fig.cap = NULL, fig.scap = NULL, fig.lp = "fig:", fig.subcap = NULL, 
        fig.pos = "", out.width = 624, out.height = NULL, out.extra = NULL, 
        fig.retina = 2, external = TRUE, sanitize = FALSE, interval = 1, 
        aniopts = "controls,loop", warning = TRUE, error = TRUE, 
        message = TRUE, render = NULL, ref.label = NULL, child = NULL, 
        engine = "r", split = FALSE, include = TRUE, purl = TRUE, 
        max.print = 1000, exercise.timelimit = 60, exercise.checker = "function (check_code, ...) \n{\n    list(message = eval(parse(text = check_code)), correct = logical(0), \n        type = \"info\", location = \"append\")\n}", 
        label = "metropolis-example-1", exercise = TRUE, code = c("# data", 
        "N <- 50", "Z <- 8", "m <- 3", "", "# parameter of prior", 
        "a <- 2", "b <- 3", "", "# number of samples", "n.smp <- 10000", 
        "sigma <- 0.1 # standard deviation (step size)", "logitP <- rep( 0, n.smp ) # value of the parameter", 
        "LL <- rep(0, n.smp ) # loglikelihood", "", "pp <- exp( logitP[1] )/(1+exp(logitP[1]))", 
        "LL[1] <- (Z+a-1)*log(pp) + (m*(N-Z) + b - 1)*log(1-pp) + Z*log(m-m*pp+pp*pp)", 
        "", "for ( k in 2:n.smp ){", "  theta.new <- logitP[k-1] + sigma*rnorm(1) # proposal", 
        "  pp.new <- exp( theta.new )/( 1+exp( theta.new ) ) # proposed probability", 
        "  # loglikelihood of proposal", "  LL.new <- (Z+a-1)*log(pp.new) + (m*(N-Z) + b - 1)*log(1-pp.new) + Z*log(m-m*pp.new+pp.new*pp.new)", 
        "  R <- exp( min(LL.new - LL[k-1],0) ) # ratio", "  U <- runif(1) # random uniform", 
        "  # move", "  if ( U < R ){", "    # go to proposal", 
        "    logitP[k] <- theta.new", "    LL[k] <- LL.new", 
        "  } else {", "    # stay where you are", "    logitP[k] <- logitP[k-1]", 
        "    LL[k] <- LL[k-1]", "  }", "}", "", "# plot Markov chain", 
        "plot(logitP, xlab=\"iteration\", ylab=\"logit\",", "     pch=20, cex=0.2)", 
        "", "# histogram of sample", "burn.in <- 1000", "P <- exp(logitP[burn.in:n.smp])/(1+exp(logitP[burn.in:n.smp]))", 
        "hist(P,nclass=100, xlab=\"infection probability\", ylab=\"frequency\",xlim=c(0,0.3))"
        ), out.width.px = 624, out.height.px = 384, params.src = "metropolis-example-1, echo=TRUE, exercise=TRUE", 
        fig.num = 0, exercise.df_print = "paged"), engine = "r", 
    version = "4"), class = c("r", "tutorial_exercise")))
</script>
 
<script type="application/shiny-prerendered" data-context="server">
`tutorial-exercise-SIR-result` <- learnr:::setup_exercise_handler(reactive(req(input$`tutorial-exercise-SIR-code-editor`)), session)
output$`tutorial-exercise-SIR-output` <- renderUI({
  `tutorial-exercise-SIR-result`()
})
</script>


<script type="application/shiny-prerendered" data-context="server">
learnr:::store_exercise_cache(structure(list(label = "SIR", global_setup = structure(c("# load packages we need", 
"library(learnr)", "library(tidyverse)", "library(knitr)", "library(zoo)", 
"library(MASS)", "library(dplyr)", "", "#....", "require(deSolve)", 
"", "#....", "# set options", "tutorial_options(", "  exercise.timelimit = 60,", 
"  # A simple checker function that just returns the message in the check chunk", 
"  exercise.checker = function(check_code, ...) {", "    list(", 
"      message = eval(parse(text = check_code)),", "      correct = logical(0),", 
"      type = \"info\",", "      location = \"append\"", "    )", 
"  }", ")", "knitr::opts_chunk$set(error = TRUE)", "", "# set random seed. --- useful for reproducing results", 
"set.seed(709)", "", "# Set local directory", "# SET PATH OF DIRECTORY", 
"setwd(\"~/Lecture/Epi_MCMC\")", "", "# Path to directory where the figures are located", 
"# SET PATH OF FIGURES", "figure.path <- \"~/Lecture/Epi_MCMC\""
), chunk_opts = list(label = "setup", echo = FALSE, include = FALSE)), 
    setup = NULL, chunks = list(list(label = "SIR", code = "#. set-up variables\n\nparameters.sir <- c( beta=0.3, gamma=0.1, N=1001 )\nstate <- c( S=1000, I=1, R=0 )\n\n#. define SIR differential equation\nSIR <- function( t, state, parameters ){\n  \n  with( as.list( c(state, parameters )), {\n    \n    # differential equations\n    dS <- -beta * S * I/N\n    dI <- beta * S * I/N - gamma * I\n    dR <- gamma * I\n    \n    # return result\n    list( c(dS=dS, dI=dI, dR=dR ) )\n  })\n  \n}\n\n#. numerically solve the system of differential equations\n\ndtime <- 0.01\ntimes <- seq(0, 100, by = dtime )\n\nsir <- ode( y = state, times = times, func = SIR, parms = parameters.sir )\n\nplot( times, sir[,\"I\"], type=\"l\", xlab=\"time\", ylab=\"infections\")", 
        opts = list(label = "\"SIR\"", eval = "TRUE", include = "TRUE", 
            exercise = "TRUE"), engine = "r")), code_check = NULL, 
    error_check = NULL, check = NULL, solution = NULL, tests = NULL, 
    options = list(eval = FALSE, echo = TRUE, results = "markup", 
        tidy = FALSE, tidy.opts = NULL, collapse = FALSE, prompt = FALSE, 
        comment = NA, highlight = FALSE, size = "normalsize", 
        background = "#F7F7F7", strip.white = TRUE, cache = 0, 
        cache.path = "lecture_cache/html/", cache.vars = NULL, 
        cache.lazy = TRUE, dependson = NULL, autodep = FALSE, 
        cache.rebuild = FALSE, fig.keep = "high", fig.show = "asis", 
        fig.align = "default", fig.path = "lecture_files/figure-html/", 
        dev = "png", dev.args = NULL, dpi = 192, fig.ext = "png", 
        fig.width = 6.5, fig.height = 4, fig.env = "figure", 
        fig.cap = NULL, fig.scap = NULL, fig.lp = "fig:", fig.subcap = NULL, 
        fig.pos = "", out.width = 624, out.height = NULL, out.extra = NULL, 
        fig.retina = 2, external = TRUE, sanitize = FALSE, interval = 1, 
        aniopts = "controls,loop", warning = TRUE, error = TRUE, 
        message = TRUE, render = NULL, ref.label = NULL, child = NULL, 
        engine = "r", split = FALSE, include = TRUE, purl = TRUE, 
        max.print = 1000, exercise.timelimit = 60, exercise.checker = "function (check_code, ...) \n{\n    list(message = eval(parse(text = check_code)), correct = logical(0), \n        type = \"info\", location = \"append\")\n}", 
        label = "SIR", exercise = TRUE, code = c("#. set-up variables", 
        "", "parameters.sir <- c( beta=0.3, gamma=0.1, N=1001 )", 
        "state <- c( S=1000, I=1, R=0 )", "", "#. define SIR differential equation", 
        "SIR <- function( t, state, parameters ){", "  ", "  with( as.list( c(state, parameters )), {", 
        "    ", "    # differential equations", "    dS <- -beta * S * I/N", 
        "    dI <- beta * S * I/N - gamma * I", "    dR <- gamma * I", 
        "    ", "    # return result", "    list( c(dS=dS, dI=dI, dR=dR ) )", 
        "  })", "  ", "}", "", "#. numerically solve the system of differential equations", 
        "", "dtime <- 0.01", "times <- seq(0, 100, by = dtime )", 
        "", "sir <- ode( y = state, times = times, func = SIR, parms = parameters.sir )", 
        "", "plot( times, sir[,\"I\"], type=\"l\", xlab=\"time\", ylab=\"infections\")"
        ), out.width.px = 624, out.height.px = 384, params.src = "SIR, eval = TRUE, include = TRUE, exercise = TRUE", 
        fig.num = 0, exercise.df_print = "paged"), engine = "r", 
    version = "4"), class = c("r", "tutorial_exercise")))
</script>
 
<script type="application/shiny-prerendered" data-context="server">
`tutorial-exercise-sSIR-result` <- learnr:::setup_exercise_handler(reactive(req(input$`tutorial-exercise-sSIR-code-editor`)), session)
output$`tutorial-exercise-sSIR-output` <- renderUI({
  `tutorial-exercise-sSIR-result`()
})
</script>


<script type="application/shiny-prerendered" data-context="server">
learnr:::store_exercise_cache(structure(list(label = "sSIR", global_setup = structure(c("# load packages we need", 
"library(learnr)", "library(tidyverse)", "library(knitr)", "library(zoo)", 
"library(MASS)", "library(dplyr)", "", "#....", "require(deSolve)", 
"", "#....", "# set options", "tutorial_options(", "  exercise.timelimit = 60,", 
"  # A simple checker function that just returns the message in the check chunk", 
"  exercise.checker = function(check_code, ...) {", "    list(", 
"      message = eval(parse(text = check_code)),", "      correct = logical(0),", 
"      type = \"info\",", "      location = \"append\"", "    )", 
"  }", ")", "knitr::opts_chunk$set(error = TRUE)", "", "# set random seed. --- useful for reproducing results", 
"set.seed(709)", "", "# Set local directory", "# SET PATH OF DIRECTORY", 
"setwd(\"~/Lecture/Epi_MCMC\")", "", "# Path to directory where the figures are located", 
"# SET PATH OF FIGURES", "figure.path <- \"~/Lecture/Epi_MCMC\""
), chunk_opts = list(label = "setup", echo = FALSE, include = FALSE)), 
    setup = NULL, chunks = list(list(label = "sSIR", code = "\n#. set-up variables\nparameters.ssir <- data.frame( pi = 0.0003, q = 0.15 )\n\nEvolution <- function(state, parameters ){\n    pk <- as.numeric( 1 - exp( state$I * log(1-parameters$pi ) ) )\n    Z <- rbinom( 1, state$S, pk )\n    V <- rbinom( 1, state$I, parameters$q )\n    \n    # return result\n    return( list( Z=Z, V=V ) )\n}\n\n\n#. simulate evolution\n\nntime <- 130\nplot( c(0,ntime), c(0,225), type=\"n\", \n      xlab =\"time\", ylab=\"number infected\")\n\n#  simulate 20 realizations of process \nff <- 0\nfor ( kk in 1:20 ){\n  ssir <- data.frame( S = rep( 0, ntime+1 ),\n                      I = rep( 0, ntime+1 ),\n                      R = rep( 0, ntime+1 ) )\n\n  ssir[1,] <- c(1000,1,0)\n\n  for ( k in 1:ntime ){\n    D <- Evolution( ssir[k,], parameters.ssir )\n    ssir[k+1,]$S <- ssir[k,]$S - D$Z\n    ssir[k+1,]$I <- ssir[k,]$I + D$Z - D$V\n    ssir[k+1,]$R <- ssir[k,]$R + D$V\n  }\n\n  if ( ssir[40,]$I > 0 ){\n    ff <- ff + 1\n    points(1:ntime, ssir$I[1:ntime], pch=20, cex=0.5)\n    lines(1:ntime, ssir$I[1:ntime], pch=20)\n  }\n}\n\ntext( 100, 160,\n      paste( \"fraction = \",round(ff/20,3)))\n\n## equivalent deterministic SIR model\nparameters.sir <- c( beta =  -sum(ssir[1,])*log(1-parameters.ssir$pi),\n                     gamma = -log(1-parameters.ssir$q),\n                     N = sum(ssir[1,]) )\nstate <- unlist( ssir[1,] )\n\n#. calculate equivalent deterministic SIR\n#. define SIR differential equation\nSIR <- function( t, state, parameters ){\n  \n  with( as.list( c(state, parameters )), {\n    \n    # differential equations\n    dS <- -beta * S * I/N\n    dI <- beta * S * I/N - gamma * I\n    dR <- gamma * I\n    \n    # return result\n    list( c(dS=dS, dI=dI, dR=dR ) )\n  })\n}\n\ndtime <- 0.01\ntimes <- seq(0, ntime, by = dtime )\n\nsir <- ode( y = state, times = times, func = SIR, parms = parameters.sir )\nlines(times, sir[,\"I\"],lwd=4,col=\"red\")", 
        opts = list(label = "\"sSIR\"", eval = "TRUE", include = "TRUE", 
            exercise = "TRUE"), engine = "r")), code_check = NULL, 
    error_check = NULL, check = NULL, solution = NULL, tests = NULL, 
    options = list(eval = FALSE, echo = TRUE, results = "markup", 
        tidy = FALSE, tidy.opts = NULL, collapse = FALSE, prompt = FALSE, 
        comment = NA, highlight = FALSE, size = "normalsize", 
        background = "#F7F7F7", strip.white = TRUE, cache = 0, 
        cache.path = "lecture_cache/html/", cache.vars = NULL, 
        cache.lazy = TRUE, dependson = NULL, autodep = FALSE, 
        cache.rebuild = FALSE, fig.keep = "high", fig.show = "asis", 
        fig.align = "default", fig.path = "lecture_files/figure-html/", 
        dev = "png", dev.args = NULL, dpi = 192, fig.ext = "png", 
        fig.width = 6.5, fig.height = 4, fig.env = "figure", 
        fig.cap = NULL, fig.scap = NULL, fig.lp = "fig:", fig.subcap = NULL, 
        fig.pos = "", out.width = 624, out.height = NULL, out.extra = NULL, 
        fig.retina = 2, external = TRUE, sanitize = FALSE, interval = 1, 
        aniopts = "controls,loop", warning = TRUE, error = TRUE, 
        message = TRUE, render = NULL, ref.label = NULL, child = NULL, 
        engine = "r", split = FALSE, include = TRUE, purl = TRUE, 
        max.print = 1000, exercise.timelimit = 60, exercise.checker = "function (check_code, ...) \n{\n    list(message = eval(parse(text = check_code)), correct = logical(0), \n        type = \"info\", location = \"append\")\n}", 
        label = "sSIR", exercise = TRUE, code = c("", "#. set-up variables", 
        "parameters.ssir <- data.frame( pi = 0.0003, q = 0.15 )", 
        "", "Evolution <- function(state, parameters ){", "    pk <- as.numeric( 1 - exp( state$I * log(1-parameters$pi ) ) )", 
        "    Z <- rbinom( 1, state$S, pk )", "    V <- rbinom( 1, state$I, parameters$q )", 
        "    ", "    # return result", "    return( list( Z=Z, V=V ) )", 
        "}", "", "", "#. simulate evolution", "", "ntime <- 130", 
        "plot( c(0,ntime), c(0,225), type=\"n\", ", "      xlab =\"time\", ylab=\"number infected\")", 
        "", "#  simulate 20 realizations of process ", "ff <- 0", 
        "for ( kk in 1:20 ){", "  ssir <- data.frame( S = rep( 0, ntime+1 ),", 
        "                      I = rep( 0, ntime+1 ),", "                      R = rep( 0, ntime+1 ) )", 
        "", "  ssir[1,] <- c(1000,1,0)", "", "  for ( k in 1:ntime ){", 
        "    D <- Evolution( ssir[k,], parameters.ssir )", "    ssir[k+1,]$S <- ssir[k,]$S - D$Z", 
        "    ssir[k+1,]$I <- ssir[k,]$I + D$Z - D$V", "    ssir[k+1,]$R <- ssir[k,]$R + D$V", 
        "  }", "", "  if ( ssir[40,]$I > 0 ){", "    ff <- ff + 1", 
        "    points(1:ntime, ssir$I[1:ntime], pch=20, cex=0.5)", 
        "    lines(1:ntime, ssir$I[1:ntime], pch=20)", "  }", 
        "}", "", "text( 100, 160,", "      paste( \"fraction = \",round(ff/20,3)))", 
        "", "## equivalent deterministic SIR model", "parameters.sir <- c( beta =  -sum(ssir[1,])*log(1-parameters.ssir$pi),", 
        "                     gamma = -log(1-parameters.ssir$q),", 
        "                     N = sum(ssir[1,]) )", "state <- unlist( ssir[1,] )", 
        "", "#. calculate equivalent deterministic SIR", "#. define SIR differential equation", 
        "SIR <- function( t, state, parameters ){", "  ", "  with( as.list( c(state, parameters )), {", 
        "    ", "    # differential equations", "    dS <- -beta * S * I/N", 
        "    dI <- beta * S * I/N - gamma * I", "    dR <- gamma * I", 
        "    ", "    # return result", "    list( c(dS=dS, dI=dI, dR=dR ) )", 
        "  })", "}", "", "dtime <- 0.01", "times <- seq(0, ntime, by = dtime )", 
        "", "sir <- ode( y = state, times = times, func = SIR, parms = parameters.sir )", 
        "lines(times, sir[,\"I\"],lwd=4,col=\"red\")"), out.width.px = 624, 
        out.height.px = 384, params.src = "sSIR, eval = TRUE, include=TRUE, exercise = TRUE", 
        fig.num = 0, exercise.df_print = "paged"), engine = "r", 
    version = "4"), class = c("r", "tutorial_exercise")))
</script>
</p>
<!--html_preserve-->
<script type="application/shiny-prerendered" data-context="dependencies">
{"type":"list","attributes":{},"value":[{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["name","version","src","meta","script","stylesheet","head","attachment","package","all_files","pkgVersion"]},"class":{"type":"character","attributes":{},"value":["html_dependency"]}},"value":[{"type":"character","attributes":{},"value":["header-attrs"]},{"type":"character","attributes":{},"value":["2.27"]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["file"]}},"value":[{"type":"character","attributes":{},"value":["rmd/h/pandoc"]}]},{"type":"NULL"},{"type":"character","attributes":{},"value":["header-attrs.js"]},{"type":"NULL"},{"type":"NULL"},{"type":"NULL"},{"type":"character","attributes":{},"value":["rmarkdown"]},{"type":"logical","attributes":{},"value":[true]},{"type":"character","attributes":{},"value":["2.27"]}]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["name","version","src","meta","script","stylesheet","head","attachment","package","all_files","pkgVersion"]},"class":{"type":"character","attributes":{},"value":["html_dependency"]}},"value":[{"type":"character","attributes":{},"value":["jquery"]},{"type":"character","attributes":{},"value":["3.6.0"]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["file"]}},"value":[{"type":"character","attributes":{},"value":["lib/3.6.0"]}]},{"type":"NULL"},{"type":"character","attributes":{},"value":["jquery-3.6.0.min.js"]},{"type":"NULL"},{"type":"NULL"},{"type":"NULL"},{"type":"character","attributes":{},"value":["jquerylib"]},{"type":"logical","attributes":{},"value":[true]},{"type":"character","attributes":{},"value":["0.1.4"]}]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["name","version","src","meta","script","stylesheet","head","attachment","package","all_files","pkgVersion"]},"class":{"type":"character","attributes":{},"value":["html_dependency"]}},"value":[{"type":"character","attributes":{},"value":["bootstrap"]},{"type":"character","attributes":{},"value":["3.3.5"]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["file"]}},"value":[{"type":"character","attributes":{},"value":["rmd/h/bootstrap"]}]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["viewport"]}},"value":[{"type":"character","attributes":{},"value":["width=device-width, initial-scale=1"]}]},{"type":"character","attributes":{},"value":["js/bootstrap.min.js","shim/html5shiv.min.js","shim/respond.min.js"]},{"type":"character","attributes":{},"value":["css/cerulean.min.css"]},{"type":"character","attributes":{},"value":["<style>h1 {font-size: 34px;}\n       h1.title {font-size: 38px;}\n       h2 {font-size: 30px;}\n       h3 {font-size: 24px;}\n       h4 {font-size: 18px;}\n       h5 {font-size: 16px;}\n       h6 {font-size: 12px;}\n       code {color: inherit; background-color: rgba(0, 0, 0, 0.04);}\n       pre:not([class]) { background-color: white }<\/style>"]},{"type":"NULL"},{"type":"character","attributes":{},"value":["rmarkdown"]},{"type":"logical","attributes":{},"value":[true]},{"type":"character","attributes":{},"value":["2.27"]}]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["name","version","src","meta","script","stylesheet","head","attachment","package","all_files","pkgVersion"]},"class":{"type":"character","attributes":{},"value":["html_dependency"]}},"value":[{"type":"character","attributes":{},"value":["pagedtable"]},{"type":"character","attributes":{},"value":["1.1"]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["file"]}},"value":[{"type":"character","attributes":{},"value":["rmd/h/pagedtable-1.1"]}]},{"type":"NULL"},{"type":"character","attributes":{},"value":["js/pagedtable.js"]},{"type":"character","attributes":{},"value":["css/pagedtable.css"]},{"type":"NULL"},{"type":"NULL"},{"type":"character","attributes":{},"value":["rmarkdown"]},{"type":"logical","attributes":{},"value":[true]},{"type":"character","attributes":{},"value":["2.27"]}]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["name","version","src","meta","script","stylesheet","head","attachment","package","all_files","pkgVersion"]},"class":{"type":"character","attributes":{},"value":["html_dependency"]}},"value":[{"type":"character","attributes":{},"value":["highlightjs"]},{"type":"character","attributes":{},"value":["9.12.0"]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["file"]}},"value":[{"type":"character","attributes":{},"value":["rmd/h/highlightjs"]}]},{"type":"NULL"},{"type":"character","attributes":{},"value":["highlight.js"]},{"type":"character","attributes":{},"value":["textmate.css"]},{"type":"NULL"},{"type":"NULL"},{"type":"character","attributes":{},"value":["rmarkdown"]},{"type":"logical","attributes":{},"value":[true]},{"type":"character","attributes":{},"value":["2.27"]}]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["name","version","src","meta","script","stylesheet","head","attachment","package","all_files","pkgVersion"]},"class":{"type":"character","attributes":{},"value":["html_dependency"]}},"value":[{"type":"character","attributes":{},"value":["tutorial"]},{"type":"character","attributes":{},"value":["0.11.5"]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["file"]}},"value":[{"type":"character","attributes":{},"value":["lib/tutorial"]}]},{"type":"NULL"},{"type":"character","attributes":{},"value":["tutorial.js"]},{"type":"character","attributes":{},"value":["tutorial.css"]},{"type":"NULL"},{"type":"NULL"},{"type":"character","attributes":{},"value":["learnr"]},{"type":"logical","attributes":{},"value":[true]},{"type":"character","attributes":{},"value":["0.11.5"]}]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["name","version","src","meta","script","stylesheet","head","attachment","package","all_files","pkgVersion"]},"class":{"type":"character","attributes":{},"value":["html_dependency"]}},"value":[{"type":"character","attributes":{},"value":["i18n"]},{"type":"character","attributes":{},"value":["21.6.10"]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["file"]}},"value":[{"type":"character","attributes":{},"value":["lib/i18n"]}]},{"type":"NULL"},{"type":"character","attributes":{},"value":["i18next.min.js","tutorial-i18n-init.js"]},{"type":"NULL"},{"type":"character","attributes":{},"value":["<script id=\"i18n-cstm-trns\" type=\"application/json\">{\"language\":\"en\",\"resources\":{\"en\":{\"translation\":{\"button\":{\"runcode\":\"Run Code\",\"runcodetitle\":\"$t(button.runcode) ({{kbd}})\",\"hint\":\"Hint\",\"hint_plural\":\"Hints\",\"hinttitle\":\"$t(button.hint)\",\"hintnext\":\"Next Hint\",\"hintprev\":\"Previous Hint\",\"solution\":\"Solution\",\"solutiontitle\":\"$t(button.solution)\",\"copyclipboard\":\"Copy to Clipboard\",\"startover\":\"Start Over\",\"startovertitle\":\"$t(button.startover)\",\"continue\":\"Continue\",\"submitanswer\":\"Submit Answer\",\"submitanswertitle\":\"$t(button.submitanswer)\",\"previoustopic\":\"Previous Topic\",\"nexttopic\":\"Next Topic\",\"questionsubmit\":\"$t(button.submitanswer)\",\"questiontryagain\":\"Try Again\"},\"text\":{\"startover\":\"Start Over\",\"areyousure\":\"Are you sure you want to start over? (all exercise progress will be reset)\",\"youmustcomplete\":\"You must complete the\",\"exercise\":\"exercise\",\"exercise_plural\":\"exercises\",\"inthissection\":\"in this section before continuing.\",\"code\":\"Code\",\"enginecap\":\"{{engine}} $t(text.code)\",\"quiz\":\"Quiz\",\"blank\":\"blank\",\"blank_plural\":\"blanks\",\"exercisecontainsblank\":\"This exercise contains {{count}} $t(text.blank).\",\"pleasereplaceblank\":\"Please replace {{blank}} with valid code.\",\"unparsable\":\"It looks like this might not be valid R code. R cannot determine how to turn your text into a complete command. You may have forgotten to fill in a blank, to remove an underscore, to include a comma between arguments, or to close an opening <code>&quot;<\\/code>, <code>'<\\/code>, <code>(<\\/code> or <code>{<\\/code> with a matching <code>&quot;<\\/code>, <code>'<\\/code>, <code>)<\\/code> or <code>}<\\/code>.\\n\",\"unparsablequotes\":\"<p>It looks like your R code contains specially formatted quotation marks or &quot;curly&quot; quotes (<code>{{character}}<\\/code>) around character strings, making your code invalid. R requires character values to be contained in straight quotation marks (<code>&quot;<\\/code> or <code>'<\\/code>).<\\/p> {{code}} <p>Don't worry, this is a common source of errors when you copy code from another app that applies its own formatting to text. You can try replacing the code on that line with the following. There may be other places that need to be fixed, too.<\\/p> {{suggestion}}\\n\",\"unparsableunicode\":\"<p>It looks like your R code contains an unexpected special character (<code>{{character}}<\\/code>) that makes your code invalid.<\\/p> {{code}} <p>Sometimes your code may contain a special character that looks like a regular character, especially if you copy and paste the code from another app. Try deleting the special character from your code and retyping it manually.<\\/p>\\n\",\"unparsableunicodesuggestion\":\"<p>It looks like your R code contains an unexpected special character (<code>{{character}}<\\/code>) that makes your code invalid.<\\/p> {{code}} <p>Sometimes your code may contain a special character that looks like a regular character, especially if you copy and paste the code from another app. You can try replacing the code on that line with the following. There may be other places that need to be fixed, too.<\\/p> {{suggestion}}\\n\",\"and\":\"and\",\"or\":\"or\",\"listcomma\":\", \",\"oxfordcomma\":\",\"}}},\"fr\":{\"translation\":{\"button\":{\"runcode\":\"Lancer le Code\",\"runcodetitle\":\"$t(button.runcode) ({{kbd}})\",\"hint\":\"Indication\",\"hint_plural\":\"Indications\",\"hinttitle\":\"$t(button.hint)\",\"hintnext\":\"Indication Suivante\",\"hintprev\":\"Indication Précédente\",\"solution\":\"Solution\",\"solutiontitle\":\"$t(button.solution)\",\"copyclipboard\":\"Copier dans le Presse-papier\",\"startover\":\"Recommencer\",\"startovertitle\":\"$t(button.startover)\",\"continue\":\"Continuer\",\"submitanswer\":\"Soumettre\",\"submitanswertitle\":\"$t(button.submitanswer)\",\"previoustopic\":\"Chapitre Précédent\",\"nexttopic\":\"Chapitre Suivant\",\"questionsubmit\":\"$t(button.submitanswer)\",\"questiontryagain\":\"Réessayer\"},\"text\":{\"startover\":\"Recommencer\",\"areyousure\":\"Êtes-vous certains de vouloir recommencer? (La progression sera remise à zéro)\",\"youmustcomplete\":\"Vous devez d'abord compléter\",\"exercise\":\"l'exercice\",\"exercise_plural\":\"des exercices\",\"inthissection\":\"de cette section avec de continuer.\",\"code\":\"Code\",\"enginecap\":\"$t(text.code) {{engine}}\",\"quiz\":\"Quiz\",\"and\":\"et\",\"or\":\"ou\",\"oxfordcomma\":\"\"}}},\"es\":{\"translation\":{\"button\":{\"runcode\":\"Ejecutar código\",\"runcodetitle\":\"$t(button.runcode) ({{kbd}})\",\"hint\":\"Pista\",\"hint_plural\":\"Pistas\",\"hinttitle\":\"$t(button.hint)\",\"hintnext\":\"Siguiente pista\",\"hintprev\":\"Pista anterior\",\"solution\":\"Solución\",\"solutiontitle\":\"$t(button.solution)\",\"copyclipboard\":\"Copiar al portapapeles\",\"startover\":\"Reiniciar\",\"startovertitle\":\"$t(button.startover)\",\"continue\":\"Continuar\",\"submitanswer\":\"Enviar respuesta\",\"submitanswertitle\":\"$t(button.submitanswer)\",\"previoustopic\":\"Tema anterior\",\"nexttopic\":\"Tema siguiente\",\"questionsubmit\":\"$t(button.submitanswer)\",\"questiontryagain\":\"Volver a intentar\"},\"text\":{\"startover\":\"Reiniciar\",\"areyousure\":\"¿De verdad quieres empezar de nuevo? (todo el progreso del ejercicio se perderá)\",\"youmustcomplete\":\"Debes completar\",\"exercise\":\"el ejercicio\",\"exercise_plural\":\"los ejercicios\",\"inthissection\":\"en esta sección antes de continuar.\",\"code\":\"Código\",\"enginecap\":\"$t(text.code) {{engine}}\",\"quiz\":\"Cuestionario\",\"and\":\"y\",\"or\":\"o\",\"oxfordcomma\":\"\"}}},\"pt\":{\"translation\":{\"button\":{\"runcode\":\"Executar código\",\"runcodetitle\":\"$t(button.runcode) ({{kbd}})\",\"hint\":\"Dica\",\"hint_plural\":\"Dicas\",\"hinttitle\":\"$t(button.hint)\",\"hintnext\":\"Próxima dica\",\"hintprev\":\"Dica anterior\",\"solution\":\"Solução\",\"solutiontitle\":\"$t(button.solution)\",\"copyclipboard\":\"Copiar para a área de transferência\",\"startover\":\"Reiniciar\",\"startovertitle\":\"$t(button.startover)\",\"continue\":\"Continuar\",\"submitanswer\":\"Enviar resposta\",\"submitanswertitle\":\"$t(button.submitanswer)\",\"previoustopic\":\"Tópico anterior\",\"nexttopic\":\"Próximo tópico\",\"questionsubmit\":\"$t(button.submitanswer)\",\"questiontryagain\":\"Tentar novamente\"},\"text\":{\"startover\":\"Reiniciar\",\"areyousure\":\"Tem certeza que deseja começar novamente? (todo o progresso feito será perdido)\",\"youmustcomplete\":\"Você deve completar\",\"exercise\":\"o exercício\",\"exercise_plural\":\"os exercícios\",\"inthissection\":\"nesta seção antes de continuar.\",\"code\":\"Código\",\"enginecap\":\"$t(text.code) {{engine}}\",\"quiz\":\"Quiz\",\"and\":\"e\",\"or\":\"ou\",\"oxfordcomma\":\"\"}}},\"tr\":{\"translation\":{\"button\":{\"runcode\":\"Çalıştırma Kodu\",\"runcodetitle\":\"$t(button.runcode) ({{kbd}})\",\"hint\":\"Ipucu\",\"hint_plural\":\"İpuçları\",\"hinttitle\":\"$t(button.hint)\",\"hintnext\":\"Sonraki İpucu\",\"hintprev\":\"Önceki İpucu\",\"solution\":\"Çözüm\",\"solutiontitle\":\"$t(button.solution)\",\"copyclipboard\":\"Pano'ya Kopyala\",\"startover\":\"Baştan Başlamak\",\"startovertitle\":\"$t(button.startover)\",\"continue\":\"Devam et\",\"submitanswer\":\"Cevabı onayla\",\"submitanswertitle\":\"$t(button.submitanswer)\",\"previoustopic\":\"Önceki Konu\",\"nexttopic\":\"Sonraki Konu\",\"questionsubmit\":\"$t(button.submitanswer)\",\"questiontryagain\":\"Tekrar Deneyin\"},\"text\":{\"startover\":\"Baştan Başlamak\",\"areyousure\":\"Baştan başlamak istediğinizden emin misiniz? (tüm egzersiz ilerlemesi kaybolacak)\",\"youmustcomplete\":\"Tamamlamalısın\",\"exercise\":\"egzersiz\",\"exercise_plural\":\"egzersizler\",\"inthissection\":\"devam etmeden önce bu bölümde\",\"code\":\"Kod\",\"enginecap\":\"$t(text.code) {{engine}}\",\"quiz\":\"Sınav\",\"oxfordcomma\":\"\"}}},\"emo\":{\"translation\":{\"button\":{\"runcode\":\"🏃\",\"runcodetitle\":\"$t(button.runcode) ({{kbd}})\",\"hint\":\"💡\",\"hint_plural\":\"$t(button.hint)\",\"hinttitle\":\"$t(button.hint)\",\"solution\":\"🎯\",\"solutiontitle\":\"$t(button.solution)\",\"copyclipboard\":\"📋\",\"startover\":\"⏮\",\"startovertitle\":\"Start Over\",\"continue\":\"✅\",\"submitanswer\":\"🆗\",\"submitanswertitle\":\"Submit Answer\",\"previoustopic\":\"⬅\",\"nexttopic\":\"➡\",\"questionsubmit\":\"$t(button.submitanswer)\",\"questiontryagain\":\"🔁\"},\"text\":{\"startover\":\"⏮\",\"areyousure\":\"🤔\",\"youmustcomplete\":\"⚠️ 👉 🧑‍💻\",\"exercise\":\"\",\"exercise_plural\":\"\",\"inthissection\":\"\",\"code\":\"💻\",\"enginecap\":\"$t(text.code) {{engine}}\",\"oxfordcomma\":\"\"}}},\"eu\":{\"translation\":{\"button\":{\"runcode\":\"Kodea egikaritu\",\"runcodetitle\":\"$t(button.runcode) ({{kbd}})\",\"hint\":\"Laguntza\",\"hint_plural\":\"Laguntza\",\"hinttitle\":\"$t(button.hint)\",\"hintnext\":\"Aurreko laguntza\",\"hintprev\":\"Hurrengo laguntza\",\"solution\":\"Ebazpena\",\"solutiontitle\":\"$t(button.solution)\",\"copyclipboard\":\"Arbelean kopiatu\",\"startover\":\"Berrabiarazi\",\"startovertitle\":\"$t(button.startover)\",\"continue\":\"Jarraitu\",\"submitanswer\":\"Erantzuna bidali\",\"submitanswertitle\":\"$t(button.submitanswer)\",\"previoustopic\":\"Aurreko atala\",\"nexttopic\":\"Hurrengo atala\",\"questionsubmit\":\"$t(button.submitanswer)\",\"questiontryagain\":\"Berriro saiatu\"},\"text\":{\"startover\":\"Berrabiarazi\",\"areyousure\":\"Berriro hasi nahi duzu? (egindako lana galdu egingo da)\",\"youmustcomplete\":\"Aurrera egin baino lehen atal honetako\",\"exercise\":\"ariketa egin behar duzu.\",\"exercise_plural\":\"ariketak egin behar dituzu.\",\"inthissection\":\"\",\"code\":\"Kodea\",\"enginecap\":\"$t(text.code) {{engine}}\",\"quiz\":\"Galdetegia\",\"oxfordcomma\":\"\"}}},\"de\":{\"translation\":{\"button\":{\"runcode\":\"Code ausführen\",\"runcodetitle\":\"$t(button.runcode) ({{kbd}})\",\"hint\":\"Tipp\",\"hint_plural\":\"Tipps\",\"hinttitle\":\"$t(button.hint)\",\"hintnext\":\"Nächster Tipp\",\"hintprev\":\"Vorheriger Tipp\",\"solution\":\"Lösung\",\"solutiontitle\":\"$t(button.solution)\",\"copyclipboard\":\"In die Zwischenablage kopieren\",\"startover\":\"Neustart\",\"startovertitle\":\"$t(button.startover)\",\"continue\":\"Weiter\",\"submitanswer\":\"Antwort einreichen\",\"submitanswertitle\":\"$t(button.submitanswer)\",\"previoustopic\":\"Vorheriges Kapitel\",\"nexttopic\":\"Nächstes Kapitel\",\"questionsubmit\":\"$t(button.submitanswer)\",\"questiontryagain\":\"Nochmal versuchen\"},\"text\":{\"startover\":\"Neustart\",\"areyousure\":\"Bist du sicher, dass du neustarten willst? (der gesamte Lernfortschritt wird gelöscht)\",\"youmustcomplete\":\"Vervollstädinge\",\"exercise\":\"die Übung\",\"exercise_plural\":\"die Übungen\",\"inthissection\":\"in diesem Kapitel, bevor du fortfährst.\",\"code\":\"Code\",\"enginecap\":\"$t(text.code) {{engine}}\",\"quiz\":\"Quiz\",\"blank\":\"Lücke\",\"blank_plural\":\"Lücken\",\"pleasereplaceblank\":\"Bitte ersetze {{blank}} mit gültigem Code.\",\"unparsable\":\"Dies scheint kein gültiger R Code zu sein. R kann deinen Text nicht in einen gültigen Befehl übersetzen. Du hast vielleicht vergessen, die Lücke zu füllen, einen Unterstrich zu entfernen, ein Komma zwischen Argumente zu setzen oder ein eröffnendes <code>&quot;<\\/code>, <code>'<\\/code>, <code>(<\\/code> oder <code>{<\\/code> mit einem zugehörigen <code>&quot;<\\/code>, <code>'<\\/code>, <code>)<\\/code> oder <code>}<\\/code> zu schließen.\\n\",\"and\":\"und\",\"or\":\"oder\",\"listcomma\":\", \",\"oxfordcomma\":\",\"}}},\"ko\":{\"translation\":{\"button\":{\"runcode\":\"코드 실행\",\"runcodetitle\":\"$t(button.runcode) ({{kbd}})\",\"hint\":\"힌트\",\"hint_plural\":\"힌트들\",\"hinttitle\":\"$t(button.hint)\",\"hintnext\":\"다음 힌트\",\"hintprev\":\"이전 힌트\",\"solution\":\"솔루션\",\"solutiontitle\":\"$t(button.solution)\",\"copyclipboard\":\"클립보드에 복사\",\"startover\":\"재학습\",\"startovertitle\":\"$t(button.startover)\",\"continue\":\"다음 학습으로\",\"submitanswer\":\"정답 제출\",\"submitanswertitle\":\"$t(button.submitanswer)\",\"previoustopic\":\"이전 토픽\",\"nexttopic\":\"다음 토픽\",\"questionsubmit\":\"$t(button.submitanswer)\",\"questiontryagain\":\"재시도\"},\"text\":{\"startover\":\"재학습\",\"areyousure\":\"다시 시작 하시겠습니까? (모든 예제의 진행 정보가 재설정됩니다)\",\"youmustcomplete\":\"당신은 완료해야 합니다\",\"exercise\":\"연습문제\",\"exercise_plural\":\"연습문제들\",\"inthissection\":\"이 섹션을 실행하기 전에\",\"code\":\"코드\",\"enginecap\":\"$t(text.code) {{engine}}\",\"quiz\":\"퀴즈\",\"blank\":\"공백\",\"blank_plural\":\"공백들\",\"exercisecontainsblank\":\"이 연습문제에는 {{count}}개의 $t(text.blank)이 포함되어 있습니다.\",\"pleasereplaceblank\":\"{{blank}}를 유효한 코드로 바꾸십시오.\",\"unparsable\":\"이것은 유효한 R 코드가 아닐 수 있습니다. R은 텍스트를 완전한 명령으로 변환하는 방법을 결정할 수 없습니다. 당신은 공백이나 밑줄을 대체하여 채우기, 인수를 컴마로 구분하기, 또는 <code>&quot;<\\/code>, <code>'<\\/code>, <code>(<\\/code> , <code>{<\\/code>로 시작하는 구문을 닫는 <code>&quot;<\\/code>, <code>'<\\/code>, <code>)<\\/code>, <code>}<\\/code>을 잊었을 수도 있습니다.\\n\",\"and\":\"그리고\",\"or\":\"혹은\",\"listcomma\":\", \",\"oxfordcomma\":\"\"}}},\"zh\":{\"translation\":{\"button\":{\"runcode\":\"运行代码\",\"runcodetitle\":\"$t(button.runcode) ({{kbd}})\",\"hint\":\"提示\",\"hint_plural\":\"提示\",\"hinttitle\":\"$t(button.hint)\",\"hintnext\":\"下一个提示\",\"hintprev\":\"上一个提示\",\"solution\":\"答案\",\"solutiontitle\":\"$t(button.solution)\",\"copyclipboard\":\"复制到剪切板\",\"startover\":\"重新开始\",\"startovertitle\":\"$t(button.startover)\",\"continue\":\"继续\",\"submitanswer\":\"提交答案\",\"submitanswertitle\":\"$t(button.submitanswer)\",\"previoustopic\":\"上一专题\",\"nexttopic\":\"下一专题\",\"questionsubmit\":\"$t(button.submitanswer)\",\"questiontryagain\":\"再试一次\"},\"text\":{\"startover\":\"重置\",\"areyousure\":\"你确定要重新开始吗? (所有当前进度将被重置)\",\"youmustcomplete\":\"你必须完成\",\"exercise\":\"练习\",\"exercise_plural\":\"练习\",\"inthissection\":\"在进行本节之前\",\"code\":\"代码\",\"enginecap\":\"$t(text.code) {{engine}}\",\"quiz\":\"测试\",\"blank\":\"空\",\"blank_plural\":\"空\",\"exercisecontainsblank\":\"本练习包含{{count}}个$t(text.blank)\",\"pleasereplaceblank\":\"请在{{blank}}内填写恰当的代码\",\"unparsable\":\"这似乎不是有效的R代码。 R不知道如何将您的文本转换为完整的命令。 您是否忘了填空，忘了删除下划线，忘了在参数之间包含逗号，或者是忘了用<code>&quot;<\\/code>, <code>'<\\/code>, <code>)<\\/code>,<code>}<\\/code>来封闭<code>&quot;<\\/code>, <code>'<\\/code>, <code>(<\\/code>。 or <code>{<\\/code>。\\n\",\"unparsablequotes\":\"<p>您的R代码中似乎含有特殊格式的引号，或者弯引号(<code>{{character}}<\\/code>) 在字符串前后，在R中字符串应该被直引号(<code>&quot;<\\/code> 或者 <code>'<\\/code>)包裹。<\\/p> {{code}} <p>别担心，该错误经常在复制粘贴包含格式的代码时遇到， 您可以尝试将该行中的代码替换为以下代码，也许还有其他地方需要修改。<\\/p> {{suggestion}}\\n\",\"unparsableunicode\":\"<p>您的代码中似乎包含有异常字符(<code>{{character}}<\\/code>),导致代码无效。<\\/p> {{code}} <p>有时候你的代码可能含有看似正常字符的特殊字符，特别是当你复制粘贴其他来源代码的时候。 请试着删除这些特殊字符,重新输入<\\/p>\\n\",\"unparsableunicodesuggestion\":\"<p>您的代码中似乎包含有异常字符(<code>{{character}}<\\/code>),导致代码无效。<\\/p> {{code}} <p>有时候你的代码可能含有看似正常字符的特殊字符，特别是当你复制粘贴其他来源代码的时候。 请试着删除这些特殊字符,重新输入<\\/p>\\n\",\"and\":\"且\",\"or\":\"或\",\"listcomma\":\",\",\"oxfordcomma\":\",\"}}},\"pl\":{\"translation\":{\"button\":{\"runcode\":\"Uruchom kod\",\"runcodetitle\":\"$t(button.runcode) ({{kbd}})\",\"hint\":\"Podpowiedź\",\"hint_plural\":\"Podpowiedzi\",\"hinttitle\":\"$t(button.hint)\",\"hintnext\":\"Następna podpowiedź\",\"hintprev\":\"Poprzednia podpowiedź\",\"solution\":\"Rozwiązanie\",\"solutiontitle\":\"$t(button.solution)\",\"copyclipboard\":\"Kopiuj do schowka\",\"startover\":\"Zacznij od początku\",\"startovertitle\":\"$t(button.startover)\",\"continue\":\"Kontynuuj\",\"submitanswer\":\"Wyślij\",\"submitanswertitle\":\"$t(button.submitanswer)\",\"previoustopic\":\"Poprzednia sekcja\",\"nexttopic\":\"Następna sekcja\",\"questionsubmit\":\"$t(button.submitanswer)\",\"questiontryagain\":\"Spróbuj ponownie\"},\"text\":{\"startover\":\"Zacznij od początku\",\"areyousure\":\"Czy na pewno chcesz zacząć od początku? (cały postęp w zadaniu zostanie utracony)\",\"youmustcomplete\":\"Musisz ukończyć\",\"exercise\":\"ćwiczenie\",\"exercise_plural\":\"ćwiczenia\",\"inthissection\":\"w tej sekcji przed kontynuowaniem\",\"code\":\"Kod\",\"enginecap\":\"$t(text.code) {{engine}}\",\"quiz\":\"Quiz\",\"blank\":\"luka\",\"blank_plural\":\"luk(i)\",\"exercisecontainsblank\":\"To ćwiczenie zawiera {{count}} $t(text.blank).\",\"pleasereplaceblank\":\"Proszę uzupełnić {{blank}} prawidłowym kodem.\",\"unparsable\":\"Wygląda na to, że może to nie być prawidłowy kod R. R nie jest w stanie przetworzyć Twojego tekstu na polecenie. Mogłeś(-aś) zapomnieć wypełnić luki, usunąć podkreślnik, umieścić przecinka między argumentami, lub zamknąć znak <code>&quot;<\\/code>, <code>'<\\/code>, <code>(<\\/code> lub <code>{<\\/code> odpowiadającym <code>&quot;<\\/code>, <code>'<\\/code>, <code>)<\\/code> lub <code>}<\\/code>.\\n\",\"unparsablequotes\":\"<p>Wygląda na to, że Twój kod zawiera szczególnie sformatowane cudzysłowy lub cudzysłowy typograficzne (<code>{{character}}<\\/code>) przy ciągach znaków, co sprawia, że kod jest niepoprawny. R wymaga cudzysłowów prostych (<code>&quot;<\\/code> albo <code>'<\\/code>).<\\/p> {{code}} <p>Nie martw się, to powszechne źródło błędów, gdy kopiuje się kod z innego programu, który sam formatuje teskt. Możesz spróbować zastąpić swój kod następującym kodem. Mogą być też inne miejsca, które wymagają poprawienia.<\\/p> {{suggestion}}\\n\",\"unparsableunicode\":\"<p>Wygląda na to, że Twój kod zawiera niespodziewany znak specjalny (<code>{{character}}<\\/code>), co sprawia, że kod jest niepoprawny.<\\/p> {{code}} <p>Czasami Twój kod może zawierać znak specjalny, który wygląda jak zwykły znak, zwłaszcza jeśli kopiujesz kod z innego programu. Spróbuj usunąć znak specjalny i wpisać do ponownie ręcznie.<\\/p>\\n\",\"unparsableunicodesuggestion\":\"<p>Wygląda na to, że Twój kod zawiera niespodziewany znak specjalny (<code>{{character}}<\\/code>), co sprawia, że kod jest niepoprawny.<\\/p> {{code}} <p>Czasami Twój kod może zawierać znak specjalny, który wygląda jak zwykły znak, zwłaszcza jeśli kopiujesz kod z innego programu. Możesz spróbować zastąpić swój kod następującym kodem. Mogą być też inne miejsca, które wymagają poprawienia.<\\/p> {{suggestion}}\\n\",\"and\":\"i\",\"or\":\"lub\",\"listcomma\":\", \",\"oxfordcomma\":\"\"}}}}}<\/script>"]},{"type":"NULL"},{"type":"character","attributes":{},"value":["learnr"]},{"type":"logical","attributes":{},"value":[true]},{"type":"character","attributes":{},"value":["0.11.5"]}]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["name","version","src","meta","script","stylesheet","head","attachment","package","all_files","pkgVersion"]},"class":{"type":"character","attributes":{},"value":["html_dependency"]}},"value":[{"type":"character","attributes":{},"value":["tutorial-format"]},{"type":"character","attributes":{},"value":["0.11.5"]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["file"]}},"value":[{"type":"character","attributes":{},"value":["rmarkdown/templates/tutorial/resources"]}]},{"type":"NULL"},{"type":"character","attributes":{},"value":["tutorial-format.js"]},{"type":"character","attributes":{},"value":["tutorial-format.css","rstudio-theme.css"]},{"type":"NULL"},{"type":"NULL"},{"type":"character","attributes":{},"value":["learnr"]},{"type":"logical","attributes":{},"value":[true]},{"type":"character","attributes":{},"value":["0.11.5"]}]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["name","version","src","meta","script","stylesheet","head","attachment","package","all_files","pkgVersion"]},"class":{"type":"character","attributes":{},"value":["html_dependency"]}},"value":[{"type":"character","attributes":{},"value":["jquery"]},{"type":"character","attributes":{},"value":["3.6.0"]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["file"]}},"value":[{"type":"character","attributes":{},"value":["lib/3.6.0"]}]},{"type":"NULL"},{"type":"character","attributes":{},"value":["jquery-3.6.0.min.js"]},{"type":"NULL"},{"type":"NULL"},{"type":"NULL"},{"type":"character","attributes":{},"value":["jquerylib"]},{"type":"logical","attributes":{},"value":[true]},{"type":"character","attributes":{},"value":["0.1.4"]}]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["name","version","src","meta","script","stylesheet","head","attachment","package","all_files","pkgVersion"]},"class":{"type":"character","attributes":{},"value":["html_dependency"]}},"value":[{"type":"character","attributes":{},"value":["navigation"]},{"type":"character","attributes":{},"value":["1.1"]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["file"]}},"value":[{"type":"character","attributes":{},"value":["rmd/h/navigation-1.1"]}]},{"type":"NULL"},{"type":"character","attributes":{},"value":["tabsets.js"]},{"type":"NULL"},{"type":"NULL"},{"type":"NULL"},{"type":"character","attributes":{},"value":["rmarkdown"]},{"type":"logical","attributes":{},"value":[true]},{"type":"character","attributes":{},"value":["2.27"]}]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["name","version","src","meta","script","stylesheet","head","attachment","package","all_files","pkgVersion"]},"class":{"type":"character","attributes":{},"value":["html_dependency"]}},"value":[{"type":"character","attributes":{},"value":["highlightjs"]},{"type":"character","attributes":{},"value":["9.12.0"]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["file"]}},"value":[{"type":"character","attributes":{},"value":["rmd/h/highlightjs"]}]},{"type":"NULL"},{"type":"character","attributes":{},"value":["highlight.js"]},{"type":"character","attributes":{},"value":["default.css"]},{"type":"NULL"},{"type":"NULL"},{"type":"character","attributes":{},"value":["rmarkdown"]},{"type":"logical","attributes":{},"value":[true]},{"type":"character","attributes":{},"value":["2.27"]}]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["name","version","src","meta","script","stylesheet","head","attachment","package","all_files","pkgVersion"]},"class":{"type":"character","attributes":{},"value":["html_dependency"]}},"value":[{"type":"character","attributes":{},"value":["jquery"]},{"type":"character","attributes":{},"value":["3.6.0"]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["file"]}},"value":[{"type":"character","attributes":{},"value":["lib/3.6.0"]}]},{"type":"NULL"},{"type":"character","attributes":{},"value":["jquery-3.6.0.min.js"]},{"type":"NULL"},{"type":"NULL"},{"type":"NULL"},{"type":"character","attributes":{},"value":["jquerylib"]},{"type":"logical","attributes":{},"value":[true]},{"type":"character","attributes":{},"value":["0.1.4"]}]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["name","version","src","meta","script","stylesheet","head","attachment","package","all_files","pkgVersion"]},"class":{"type":"character","attributes":{},"value":["html_dependency"]}},"value":[{"type":"character","attributes":{},"value":["font-awesome"]},{"type":"character","attributes":{},"value":["6.4.2"]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["file"]}},"value":[{"type":"character","attributes":{},"value":["fontawesome"]}]},{"type":"NULL"},{"type":"NULL"},{"type":"character","attributes":{},"value":["css/all.min.css","css/v4-shims.min.css"]},{"type":"NULL"},{"type":"NULL"},{"type":"character","attributes":{},"value":["fontawesome"]},{"type":"logical","attributes":{},"value":[true]},{"type":"character","attributes":{},"value":["0.5.2"]}]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["name","version","src","meta","script","stylesheet","head","attachment","package","all_files","pkgVersion"]},"class":{"type":"character","attributes":{},"value":["html_dependency"]}},"value":[{"type":"character","attributes":{},"value":["bootbox"]},{"type":"character","attributes":{},"value":["5.5.2"]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["file"]}},"value":[{"type":"character","attributes":{},"value":["lib/bootbox"]}]},{"type":"NULL"},{"type":"character","attributes":{},"value":["bootbox.min.js"]},{"type":"NULL"},{"type":"NULL"},{"type":"NULL"},{"type":"character","attributes":{},"value":["learnr"]},{"type":"logical","attributes":{},"value":[true]},{"type":"character","attributes":{},"value":["0.11.5"]}]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["name","version","src","meta","script","stylesheet","head","attachment","package","all_files","pkgVersion"]},"class":{"type":"character","attributes":{},"value":["html_dependency"]}},"value":[{"type":"character","attributes":{},"value":["idb-keyvalue"]},{"type":"character","attributes":{},"value":["3.2.0"]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["file"]}},"value":[{"type":"character","attributes":{},"value":["lib/idb-keyval"]}]},{"type":"NULL"},{"type":"character","attributes":{},"value":["idb-keyval-iife-compat.min.js"]},{"type":"NULL"},{"type":"NULL"},{"type":"NULL"},{"type":"character","attributes":{},"value":["learnr"]},{"type":"logical","attributes":{},"value":[false]},{"type":"character","attributes":{},"value":["0.11.5"]}]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["name","version","src","meta","script","stylesheet","head","attachment","package","all_files","pkgVersion"]},"class":{"type":"character","attributes":{},"value":["html_dependency"]}},"value":[{"type":"character","attributes":{},"value":["tutorial"]},{"type":"character","attributes":{},"value":["0.11.5"]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["file"]}},"value":[{"type":"character","attributes":{},"value":["lib/tutorial"]}]},{"type":"NULL"},{"type":"character","attributes":{},"value":["tutorial.js"]},{"type":"character","attributes":{},"value":["tutorial.css"]},{"type":"NULL"},{"type":"NULL"},{"type":"character","attributes":{},"value":["learnr"]},{"type":"logical","attributes":{},"value":[true]},{"type":"character","attributes":{},"value":["0.11.5"]}]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["name","version","src","meta","script","stylesheet","head","attachment","package","all_files","pkgVersion"]},"class":{"type":"character","attributes":{},"value":["html_dependency"]}},"value":[{"type":"character","attributes":{},"value":["ace"]},{"type":"character","attributes":{},"value":["1.10.1"]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["file"]}},"value":[{"type":"character","attributes":{},"value":["lib/ace"]}]},{"type":"NULL"},{"type":"character","attributes":{},"value":["ace.js"]},{"type":"NULL"},{"type":"NULL"},{"type":"NULL"},{"type":"character","attributes":{},"value":["learnr"]},{"type":"logical","attributes":{},"value":[true]},{"type":"character","attributes":{},"value":["0.11.5"]}]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["name","version","src","meta","script","stylesheet","head","attachment","package","all_files","pkgVersion"]},"class":{"type":"character","attributes":{},"value":["html_dependency"]}},"value":[{"type":"character","attributes":{},"value":["clipboardjs"]},{"type":"character","attributes":{},"value":["2.0.10"]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["file"]}},"value":[{"type":"character","attributes":{},"value":["lib/clipboardjs"]}]},{"type":"NULL"},{"type":"character","attributes":{},"value":["clipboard.min.js"]},{"type":"NULL"},{"type":"NULL"},{"type":"NULL"},{"type":"character","attributes":{},"value":["learnr"]},{"type":"logical","attributes":{},"value":[true]},{"type":"character","attributes":{},"value":["0.11.5"]}]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["name","version","src","meta","script","stylesheet","head","attachment","package","all_files","pkgVersion"]},"class":{"type":"character","attributes":{},"value":["html_dependency"]}},"value":[{"type":"character","attributes":{},"value":["ace"]},{"type":"character","attributes":{},"value":["1.10.1"]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["file"]}},"value":[{"type":"character","attributes":{},"value":["lib/ace"]}]},{"type":"NULL"},{"type":"character","attributes":{},"value":["ace.js"]},{"type":"NULL"},{"type":"NULL"},{"type":"NULL"},{"type":"character","attributes":{},"value":["learnr"]},{"type":"logical","attributes":{},"value":[true]},{"type":"character","attributes":{},"value":["0.11.5"]}]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["name","version","src","meta","script","stylesheet","head","attachment","package","all_files","pkgVersion"]},"class":{"type":"character","attributes":{},"value":["html_dependency"]}},"value":[{"type":"character","attributes":{},"value":["clipboardjs"]},{"type":"character","attributes":{},"value":["2.0.10"]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["file"]}},"value":[{"type":"character","attributes":{},"value":["lib/clipboardjs"]}]},{"type":"NULL"},{"type":"character","attributes":{},"value":["clipboard.min.js"]},{"type":"NULL"},{"type":"NULL"},{"type":"NULL"},{"type":"character","attributes":{},"value":["learnr"]},{"type":"logical","attributes":{},"value":[true]},{"type":"character","attributes":{},"value":["0.11.5"]}]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["name","version","src","meta","script","stylesheet","head","attachment","package","all_files","pkgVersion"]},"class":{"type":"character","attributes":{},"value":["html_dependency"]}},"value":[{"type":"character","attributes":{},"value":["ace"]},{"type":"character","attributes":{},"value":["1.10.1"]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["file"]}},"value":[{"type":"character","attributes":{},"value":["lib/ace"]}]},{"type":"NULL"},{"type":"character","attributes":{},"value":["ace.js"]},{"type":"NULL"},{"type":"NULL"},{"type":"NULL"},{"type":"character","attributes":{},"value":["learnr"]},{"type":"logical","attributes":{},"value":[true]},{"type":"character","attributes":{},"value":["0.11.5"]}]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["name","version","src","meta","script","stylesheet","head","attachment","package","all_files","pkgVersion"]},"class":{"type":"character","attributes":{},"value":["html_dependency"]}},"value":[{"type":"character","attributes":{},"value":["clipboardjs"]},{"type":"character","attributes":{},"value":["2.0.10"]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["file"]}},"value":[{"type":"character","attributes":{},"value":["lib/clipboardjs"]}]},{"type":"NULL"},{"type":"character","attributes":{},"value":["clipboard.min.js"]},{"type":"NULL"},{"type":"NULL"},{"type":"NULL"},{"type":"character","attributes":{},"value":["learnr"]},{"type":"logical","attributes":{},"value":[true]},{"type":"character","attributes":{},"value":["0.11.5"]}]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["name","version","src","meta","script","stylesheet","head","attachment","package","all_files","pkgVersion"]},"class":{"type":"character","attributes":{},"value":["html_dependency"]}},"value":[{"type":"character","attributes":{},"value":["ace"]},{"type":"character","attributes":{},"value":["1.10.1"]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["file"]}},"value":[{"type":"character","attributes":{},"value":["lib/ace"]}]},{"type":"NULL"},{"type":"character","attributes":{},"value":["ace.js"]},{"type":"NULL"},{"type":"NULL"},{"type":"NULL"},{"type":"character","attributes":{},"value":["learnr"]},{"type":"logical","attributes":{},"value":[true]},{"type":"character","attributes":{},"value":["0.11.5"]}]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["name","version","src","meta","script","stylesheet","head","attachment","package","all_files","pkgVersion"]},"class":{"type":"character","attributes":{},"value":["html_dependency"]}},"value":[{"type":"character","attributes":{},"value":["clipboardjs"]},{"type":"character","attributes":{},"value":["2.0.10"]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["file"]}},"value":[{"type":"character","attributes":{},"value":["lib/clipboardjs"]}]},{"type":"NULL"},{"type":"character","attributes":{},"value":["clipboard.min.js"]},{"type":"NULL"},{"type":"NULL"},{"type":"NULL"},{"type":"character","attributes":{},"value":["learnr"]},{"type":"logical","attributes":{},"value":[true]},{"type":"character","attributes":{},"value":["0.11.5"]}]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["name","version","src","meta","script","stylesheet","head","attachment","package","all_files","pkgVersion"]},"class":{"type":"character","attributes":{},"value":["html_dependency"]}},"value":[{"type":"character","attributes":{},"value":["ace"]},{"type":"character","attributes":{},"value":["1.10.1"]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["file"]}},"value":[{"type":"character","attributes":{},"value":["lib/ace"]}]},{"type":"NULL"},{"type":"character","attributes":{},"value":["ace.js"]},{"type":"NULL"},{"type":"NULL"},{"type":"NULL"},{"type":"character","attributes":{},"value":["learnr"]},{"type":"logical","attributes":{},"value":[true]},{"type":"character","attributes":{},"value":["0.11.5"]}]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["name","version","src","meta","script","stylesheet","head","attachment","package","all_files","pkgVersion"]},"class":{"type":"character","attributes":{},"value":["html_dependency"]}},"value":[{"type":"character","attributes":{},"value":["clipboardjs"]},{"type":"character","attributes":{},"value":["2.0.10"]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["file"]}},"value":[{"type":"character","attributes":{},"value":["lib/clipboardjs"]}]},{"type":"NULL"},{"type":"character","attributes":{},"value":["clipboard.min.js"]},{"type":"NULL"},{"type":"NULL"},{"type":"NULL"},{"type":"character","attributes":{},"value":["learnr"]},{"type":"logical","attributes":{},"value":[true]},{"type":"character","attributes":{},"value":["0.11.5"]}]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["name","version","src","meta","script","stylesheet","head","attachment","package","all_files","pkgVersion"]},"class":{"type":"character","attributes":{},"value":["html_dependency"]}},"value":[{"type":"character","attributes":{},"value":["ace"]},{"type":"character","attributes":{},"value":["1.10.1"]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["file"]}},"value":[{"type":"character","attributes":{},"value":["lib/ace"]}]},{"type":"NULL"},{"type":"character","attributes":{},"value":["ace.js"]},{"type":"NULL"},{"type":"NULL"},{"type":"NULL"},{"type":"character","attributes":{},"value":["learnr"]},{"type":"logical","attributes":{},"value":[true]},{"type":"character","attributes":{},"value":["0.11.5"]}]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["name","version","src","meta","script","stylesheet","head","attachment","package","all_files","pkgVersion"]},"class":{"type":"character","attributes":{},"value":["html_dependency"]}},"value":[{"type":"character","attributes":{},"value":["clipboardjs"]},{"type":"character","attributes":{},"value":["2.0.10"]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["file"]}},"value":[{"type":"character","attributes":{},"value":["lib/clipboardjs"]}]},{"type":"NULL"},{"type":"character","attributes":{},"value":["clipboard.min.js"]},{"type":"NULL"},{"type":"NULL"},{"type":"NULL"},{"type":"character","attributes":{},"value":["learnr"]},{"type":"logical","attributes":{},"value":[true]},{"type":"character","attributes":{},"value":["0.11.5"]}]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["name","version","src","meta","script","stylesheet","head","attachment","package","all_files","pkgVersion"]},"class":{"type":"character","attributes":{},"value":["html_dependency"]}},"value":[{"type":"character","attributes":{},"value":["ace"]},{"type":"character","attributes":{},"value":["1.10.1"]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["file"]}},"value":[{"type":"character","attributes":{},"value":["lib/ace"]}]},{"type":"NULL"},{"type":"character","attributes":{},"value":["ace.js"]},{"type":"NULL"},{"type":"NULL"},{"type":"NULL"},{"type":"character","attributes":{},"value":["learnr"]},{"type":"logical","attributes":{},"value":[true]},{"type":"character","attributes":{},"value":["0.11.5"]}]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["name","version","src","meta","script","stylesheet","head","attachment","package","all_files","pkgVersion"]},"class":{"type":"character","attributes":{},"value":["html_dependency"]}},"value":[{"type":"character","attributes":{},"value":["clipboardjs"]},{"type":"character","attributes":{},"value":["2.0.10"]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["file"]}},"value":[{"type":"character","attributes":{},"value":["lib/clipboardjs"]}]},{"type":"NULL"},{"type":"character","attributes":{},"value":["clipboard.min.js"]},{"type":"NULL"},{"type":"NULL"},{"type":"NULL"},{"type":"character","attributes":{},"value":["learnr"]},{"type":"logical","attributes":{},"value":[true]},{"type":"character","attributes":{},"value":["0.11.5"]}]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["name","version","src","meta","script","stylesheet","head","attachment","package","all_files","pkgVersion"]},"class":{"type":"character","attributes":{},"value":["html_dependency"]}},"value":[{"type":"character","attributes":{},"value":["ace"]},{"type":"character","attributes":{},"value":["1.10.1"]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["file"]}},"value":[{"type":"character","attributes":{},"value":["lib/ace"]}]},{"type":"NULL"},{"type":"character","attributes":{},"value":["ace.js"]},{"type":"NULL"},{"type":"NULL"},{"type":"NULL"},{"type":"character","attributes":{},"value":["learnr"]},{"type":"logical","attributes":{},"value":[true]},{"type":"character","attributes":{},"value":["0.11.5"]}]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["name","version","src","meta","script","stylesheet","head","attachment","package","all_files","pkgVersion"]},"class":{"type":"character","attributes":{},"value":["html_dependency"]}},"value":[{"type":"character","attributes":{},"value":["clipboardjs"]},{"type":"character","attributes":{},"value":["2.0.10"]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["file"]}},"value":[{"type":"character","attributes":{},"value":["lib/clipboardjs"]}]},{"type":"NULL"},{"type":"character","attributes":{},"value":["clipboard.min.js"]},{"type":"NULL"},{"type":"NULL"},{"type":"NULL"},{"type":"character","attributes":{},"value":["learnr"]},{"type":"logical","attributes":{},"value":[true]},{"type":"character","attributes":{},"value":["0.11.5"]}]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["name","version","src","meta","script","stylesheet","head","attachment","package","all_files","pkgVersion"]},"class":{"type":"character","attributes":{},"value":["html_dependency"]}},"value":[{"type":"character","attributes":{},"value":["ace"]},{"type":"character","attributes":{},"value":["1.10.1"]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["file"]}},"value":[{"type":"character","attributes":{},"value":["lib/ace"]}]},{"type":"NULL"},{"type":"character","attributes":{},"value":["ace.js"]},{"type":"NULL"},{"type":"NULL"},{"type":"NULL"},{"type":"character","attributes":{},"value":["learnr"]},{"type":"logical","attributes":{},"value":[true]},{"type":"character","attributes":{},"value":["0.11.5"]}]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["name","version","src","meta","script","stylesheet","head","attachment","package","all_files","pkgVersion"]},"class":{"type":"character","attributes":{},"value":["html_dependency"]}},"value":[{"type":"character","attributes":{},"value":["clipboardjs"]},{"type":"character","attributes":{},"value":["2.0.10"]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["file"]}},"value":[{"type":"character","attributes":{},"value":["lib/clipboardjs"]}]},{"type":"NULL"},{"type":"character","attributes":{},"value":["clipboard.min.js"]},{"type":"NULL"},{"type":"NULL"},{"type":"NULL"},{"type":"character","attributes":{},"value":["learnr"]},{"type":"logical","attributes":{},"value":[true]},{"type":"character","attributes":{},"value":["0.11.5"]}]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["name","version","src","meta","script","stylesheet","head","attachment","package","all_files","pkgVersion"]},"class":{"type":"character","attributes":{},"value":["html_dependency"]}},"value":[{"type":"character","attributes":{},"value":["ace"]},{"type":"character","attributes":{},"value":["1.10.1"]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["file"]}},"value":[{"type":"character","attributes":{},"value":["lib/ace"]}]},{"type":"NULL"},{"type":"character","attributes":{},"value":["ace.js"]},{"type":"NULL"},{"type":"NULL"},{"type":"NULL"},{"type":"character","attributes":{},"value":["learnr"]},{"type":"logical","attributes":{},"value":[true]},{"type":"character","attributes":{},"value":["0.11.5"]}]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["name","version","src","meta","script","stylesheet","head","attachment","package","all_files","pkgVersion"]},"class":{"type":"character","attributes":{},"value":["html_dependency"]}},"value":[{"type":"character","attributes":{},"value":["clipboardjs"]},{"type":"character","attributes":{},"value":["2.0.10"]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["file"]}},"value":[{"type":"character","attributes":{},"value":["lib/clipboardjs"]}]},{"type":"NULL"},{"type":"character","attributes":{},"value":["clipboard.min.js"]},{"type":"NULL"},{"type":"NULL"},{"type":"NULL"},{"type":"character","attributes":{},"value":["learnr"]},{"type":"logical","attributes":{},"value":[true]},{"type":"character","attributes":{},"value":["0.11.5"]}]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["name","version","src","meta","script","stylesheet","head","attachment","package","all_files","pkgVersion"]},"class":{"type":"character","attributes":{},"value":["html_dependency"]}},"value":[{"type":"character","attributes":{},"value":["ace"]},{"type":"character","attributes":{},"value":["1.10.1"]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["file"]}},"value":[{"type":"character","attributes":{},"value":["lib/ace"]}]},{"type":"NULL"},{"type":"character","attributes":{},"value":["ace.js"]},{"type":"NULL"},{"type":"NULL"},{"type":"NULL"},{"type":"character","attributes":{},"value":["learnr"]},{"type":"logical","attributes":{},"value":[true]},{"type":"character","attributes":{},"value":["0.11.5"]}]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["name","version","src","meta","script","stylesheet","head","attachment","package","all_files","pkgVersion"]},"class":{"type":"character","attributes":{},"value":["html_dependency"]}},"value":[{"type":"character","attributes":{},"value":["clipboardjs"]},{"type":"character","attributes":{},"value":["2.0.10"]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["file"]}},"value":[{"type":"character","attributes":{},"value":["lib/clipboardjs"]}]},{"type":"NULL"},{"type":"character","attributes":{},"value":["clipboard.min.js"]},{"type":"NULL"},{"type":"NULL"},{"type":"NULL"},{"type":"character","attributes":{},"value":["learnr"]},{"type":"logical","attributes":{},"value":[true]},{"type":"character","attributes":{},"value":["0.11.5"]}]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["name","version","src","meta","script","stylesheet","head","attachment","package","all_files","pkgVersion"]},"class":{"type":"character","attributes":{},"value":["html_dependency"]}},"value":[{"type":"character","attributes":{},"value":["ace"]},{"type":"character","attributes":{},"value":["1.10.1"]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["file"]}},"value":[{"type":"character","attributes":{},"value":["lib/ace"]}]},{"type":"NULL"},{"type":"character","attributes":{},"value":["ace.js"]},{"type":"NULL"},{"type":"NULL"},{"type":"NULL"},{"type":"character","attributes":{},"value":["learnr"]},{"type":"logical","attributes":{},"value":[true]},{"type":"character","attributes":{},"value":["0.11.5"]}]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["name","version","src","meta","script","stylesheet","head","attachment","package","all_files","pkgVersion"]},"class":{"type":"character","attributes":{},"value":["html_dependency"]}},"value":[{"type":"character","attributes":{},"value":["clipboardjs"]},{"type":"character","attributes":{},"value":["2.0.10"]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["file"]}},"value":[{"type":"character","attributes":{},"value":["lib/clipboardjs"]}]},{"type":"NULL"},{"type":"character","attributes":{},"value":["clipboard.min.js"]},{"type":"NULL"},{"type":"NULL"},{"type":"NULL"},{"type":"character","attributes":{},"value":["learnr"]},{"type":"logical","attributes":{},"value":[true]},{"type":"character","attributes":{},"value":["0.11.5"]}]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["name","version","src","meta","script","stylesheet","head","attachment","package","all_files","pkgVersion"]},"class":{"type":"character","attributes":{},"value":["html_dependency"]}},"value":[{"type":"character","attributes":{},"value":["ace"]},{"type":"character","attributes":{},"value":["1.10.1"]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["file"]}},"value":[{"type":"character","attributes":{},"value":["lib/ace"]}]},{"type":"NULL"},{"type":"character","attributes":{},"value":["ace.js"]},{"type":"NULL"},{"type":"NULL"},{"type":"NULL"},{"type":"character","attributes":{},"value":["learnr"]},{"type":"logical","attributes":{},"value":[true]},{"type":"character","attributes":{},"value":["0.11.5"]}]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["name","version","src","meta","script","stylesheet","head","attachment","package","all_files","pkgVersion"]},"class":{"type":"character","attributes":{},"value":["html_dependency"]}},"value":[{"type":"character","attributes":{},"value":["clipboardjs"]},{"type":"character","attributes":{},"value":["2.0.10"]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["file"]}},"value":[{"type":"character","attributes":{},"value":["lib/clipboardjs"]}]},{"type":"NULL"},{"type":"character","attributes":{},"value":["clipboard.min.js"]},{"type":"NULL"},{"type":"NULL"},{"type":"NULL"},{"type":"character","attributes":{},"value":["learnr"]},{"type":"logical","attributes":{},"value":[true]},{"type":"character","attributes":{},"value":["0.11.5"]}]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["name","version","src","meta","script","stylesheet","head","attachment","package","all_files","pkgVersion"]},"class":{"type":"character","attributes":{},"value":["html_dependency"]}},"value":[{"type":"character","attributes":{},"value":["ace"]},{"type":"character","attributes":{},"value":["1.10.1"]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["file"]}},"value":[{"type":"character","attributes":{},"value":["lib/ace"]}]},{"type":"NULL"},{"type":"character","attributes":{},"value":["ace.js"]},{"type":"NULL"},{"type":"NULL"},{"type":"NULL"},{"type":"character","attributes":{},"value":["learnr"]},{"type":"logical","attributes":{},"value":[true]},{"type":"character","attributes":{},"value":["0.11.5"]}]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["name","version","src","meta","script","stylesheet","head","attachment","package","all_files","pkgVersion"]},"class":{"type":"character","attributes":{},"value":["html_dependency"]}},"value":[{"type":"character","attributes":{},"value":["clipboardjs"]},{"type":"character","attributes":{},"value":["2.0.10"]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["file"]}},"value":[{"type":"character","attributes":{},"value":["lib/clipboardjs"]}]},{"type":"NULL"},{"type":"character","attributes":{},"value":["clipboard.min.js"]},{"type":"NULL"},{"type":"NULL"},{"type":"NULL"},{"type":"character","attributes":{},"value":["learnr"]},{"type":"logical","attributes":{},"value":[true]},{"type":"character","attributes":{},"value":["0.11.5"]}]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["name","version","src","meta","script","stylesheet","head","attachment","package","all_files","pkgVersion"]},"class":{"type":"character","attributes":{},"value":["html_dependency"]}},"value":[{"type":"character","attributes":{},"value":["ace"]},{"type":"character","attributes":{},"value":["1.10.1"]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["file"]}},"value":[{"type":"character","attributes":{},"value":["lib/ace"]}]},{"type":"NULL"},{"type":"character","attributes":{},"value":["ace.js"]},{"type":"NULL"},{"type":"NULL"},{"type":"NULL"},{"type":"character","attributes":{},"value":["learnr"]},{"type":"logical","attributes":{},"value":[true]},{"type":"character","attributes":{},"value":["0.11.5"]}]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["name","version","src","meta","script","stylesheet","head","attachment","package","all_files","pkgVersion"]},"class":{"type":"character","attributes":{},"value":["html_dependency"]}},"value":[{"type":"character","attributes":{},"value":["clipboardjs"]},{"type":"character","attributes":{},"value":["2.0.10"]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["file"]}},"value":[{"type":"character","attributes":{},"value":["lib/clipboardjs"]}]},{"type":"NULL"},{"type":"character","attributes":{},"value":["clipboard.min.js"]},{"type":"NULL"},{"type":"NULL"},{"type":"NULL"},{"type":"character","attributes":{},"value":["learnr"]},{"type":"logical","attributes":{},"value":[true]},{"type":"character","attributes":{},"value":["0.11.5"]}]}]}
</script>
<!--/html_preserve-->
<!--html_preserve-->
<script type="application/shiny-prerendered" data-context="execution_dependencies">
{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["packages"]}},"value":[{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["packages","version"]},"class":{"type":"character","attributes":{},"value":["data.frame"]},"row.names":{"type":"integer","attributes":{},"value":[1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31,32,33,34,35,36,37,38,39,40,41,42,43,44,45,46,47,48,49,50,51,52,53,54,55,56,57,58,59,60,61,62,63,64,65,66,67,68,69,70,71,72,73,74]}},"value":[{"type":"character","attributes":{},"value":["backports","base","bslib","cachem","checkmate","cli","colorspace","compiler","datasets","deSolve","digest","dplyr","evaluate","fansi","fastmap","fontawesome","forcats","generics","ggplot2","glue","graphics","grDevices","grid","gtable","highr","hms","htmltools","htmlwidgets","httpuv","jquerylib","jsonlite","knitr","later","lattice","learnr","lifecycle","lubridate","magrittr","MASS","methods","mime","munsell","pillar","pkgconfig","promises","purrr","R6","Rcpp","readr","rlang","rmarkdown","rprojroot","rstudioapi","sass","scales","shiny","stats","stringi","stringr","tibble","tidyr","tidyselect","tidyverse","timechange","tools","tzdb","utf8","utils","vctrs","withr","xfun","xtable","yaml","zoo"]},{"type":"character","attributes":{},"value":["1.5.0","4.4.1","0.7.0","1.1.0","2.3.1","3.6.3","2.1-0","4.4.1","4.4.1","1.40","0.6.36","1.1.4","0.24.0","1.0.6","1.2.0","0.5.2","1.0.0","0.1.3","3.5.1","1.7.0","4.4.1","4.4.1","4.4.1","0.3.5","0.11","1.1.3","0.5.8.1","1.6.4","1.6.15","0.1.4","1.8.8","1.47","1.3.2","0.22-6","0.11.5","1.0.4","1.9.3","2.0.3","7.3-60.2","4.4.1","0.12","0.5.1","1.9.0","2.0.3","1.3.0","1.0.2","2.5.1","1.0.12","2.1.5","1.1.4","2.27","2.0.4","0.16.0","0.4.9","1.3.0","1.8.1.1","4.4.1","1.8.4","1.5.1","3.2.1","1.3.1","1.2.1","2.0.0","0.3.0","4.4.1","0.4.0","1.2.4","4.4.1","0.6.5","3.0.0","0.45","1.8-4","2.3.8","1.8-12"]}]}]}
</script>
<!--/html_preserve-->
</div>
</div>

</article> <!-- topics -->

<div class="topicsContainer">
<div class="topicsPositioner">
<div class="band">
<div class="bandContent topicsListContainer">

<!-- begin doc-metadata -->
<div id="doc-metadata">
<h1 class="title toc-ignore" style="display:none;">Statistical Modeling
of Epidemic Data</h1>
</div>
<!-- end doc-metadata -->

</div> <!-- bandContent.topicsListContainer -->
</div> <!-- band -->
</div> <!-- topicsPositioner -->
</div> <!-- topicsContainer -->


</main> <!-- bandContent page -->
</div> <!-- pageContent band -->



<!-- Build Tabsets -->
<script>
$(document).ready(function () {
  window.buildTabsets("section-TOC");
});

$(document).ready(function () {
  $('.tabset-dropdown > .nav-tabs > li').click(function () {
    $(this).parent().toggleClass('nav-tabs-open')
  });
});
</script>

<script>
// add bootstrap table styles to pandoc tables
function bootstrapStylePandocTables() {
  $('tr.header').parent('thead').parent('table').addClass('table table-condensed');
}
$(document).ready(function () {
  bootstrapStylePandocTables();
});
</script>


<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    script.src  = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML";
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>


</body>

</html>
